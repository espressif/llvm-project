; NOTE: Assertions have been autogenerated by utils/update_test_checks.py UTC_ARGS: --version 5
; RUN: opt -S -mtriple=riscv32-esp-unknown-elf -passes=riscv-esp32-p4-mem-intrin -riscv-esp32-p4-mem-intrin=true < %s | FileCheck %s

target datalayout = "e-m:e-p:32:32-i64:64-n32-S128"
target triple = "riscv32-esp-unknown-elf"

; src16 dst16
define void @test_src16_dst16_size_1(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dst16_size_1(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = load i8, ptr [[B]], align 1
; CHECK-NEXT:    store i8 [[TMP0]], ptr [[A]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(1) %a, ptr noundef nonnull align 16 dereferenceable(1) %b, i32 1, i1 false)
  ret void
}

define void @test_src16_dst16_size_2(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dst16_size_2(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = load i16, ptr [[B]], align 2
; CHECK-NEXT:    store i16 [[TMP0]], ptr [[A]], align 2
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(2) %a, ptr noundef nonnull align 16 dereferenceable(2) %b, i32 2, i1 false)
  ret void
}

define void @test_src16_dst16_size_3(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dst16_size_3(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = load i16, ptr [[B]], align 2
; CHECK-NEXT:    store i16 [[TMP0]], ptr [[A]], align 2
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[B]], i32 2
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[A]], i32 2
; CHECK-NEXT:    [[TMP3:%.*]] = load i8, ptr [[TMP1]], align 1
; CHECK-NEXT:    store i8 [[TMP3]], ptr [[TMP2]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(3) %a, ptr noundef nonnull align 16 dereferenceable(3) %b, i32 3, i1 false)
  ret void
}

define void @test_src16_dst16_size_4(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dst16_size_4(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = load i32, ptr [[B]], align 4
; CHECK-NEXT:    store i32 [[TMP0]], ptr [[A]], align 4
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(4) %a, ptr noundef nonnull align 16 dereferenceable(4) %b, i32 4, i1 false)
  ret void
}

define void @test_src16_dst16_size_5(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dst16_size_5(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = load i32, ptr [[B]], align 4
; CHECK-NEXT:    store i32 [[TMP0]], ptr [[A]], align 4
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[B]], i32 4
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[A]], i32 4
; CHECK-NEXT:    [[TMP3:%.*]] = load i8, ptr [[TMP1]], align 1
; CHECK-NEXT:    store i8 [[TMP3]], ptr [[TMP2]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(5) %a, ptr noundef nonnull align 16 dereferenceable(5) %b, i32 5, i1 false)
  ret void
}

define void @test_src16_dst16_size_6(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dst16_size_6(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = load i32, ptr [[B]], align 4
; CHECK-NEXT:    store i32 [[TMP0]], ptr [[A]], align 4
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[B]], i32 4
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[A]], i32 4
; CHECK-NEXT:    [[TMP3:%.*]] = load i16, ptr [[TMP1]], align 2
; CHECK-NEXT:    store i16 [[TMP3]], ptr [[TMP2]], align 2
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(6) %a, ptr noundef nonnull align 16 dereferenceable(6) %b, i32 6, i1 false)
  ret void
}

define void @test_src16_dst16_size_7(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dst16_size_7(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = load i32, ptr [[B]], align 4
; CHECK-NEXT:    store i32 [[TMP0]], ptr [[A]], align 4
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[B]], i32 4
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[A]], i32 4
; CHECK-NEXT:    [[TMP3:%.*]] = load i16, ptr [[TMP1]], align 2
; CHECK-NEXT:    store i16 [[TMP3]], ptr [[TMP2]], align 2
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[TMP1]], i32 2
; CHECK-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[TMP2]], i32 2
; CHECK-NEXT:    [[TMP6:%.*]] = load i8, ptr [[TMP4]], align 1
; CHECK-NEXT:    store i8 [[TMP6]], ptr [[TMP5]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(7) %a, ptr noundef nonnull align 16 dereferenceable(7) %b, i32 7, i1 false)
  ret void
}

define void @test_src16_dst16_size_8(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dst16_size_8(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(8) %a, ptr noundef nonnull align 16 dereferenceable(8) %b, i32 8, i1 false)
  ret void
}

define void @test_src16_dst16_size_9(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dst16_size_9(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[B]], i32 8
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[A]], i32 8
; CHECK-NEXT:    [[TMP4:%.*]] = load i8, ptr [[TMP2]], align 1
; CHECK-NEXT:    store i8 [[TMP4]], ptr [[TMP3]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(9) %a, ptr noundef nonnull align 16 dereferenceable(9) %b, i32 9, i1 false)
  ret void
}

define void @test_src16_dst16_size_10(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dst16_size_10(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[B]], i32 8
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[A]], i32 8
; CHECK-NEXT:    [[TMP4:%.*]] = load i16, ptr [[TMP2]], align 2
; CHECK-NEXT:    store i16 [[TMP4]], ptr [[TMP3]], align 2
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(10) %a, ptr noundef nonnull align 16 dereferenceable(10) %b, i32 10, i1 false)
  ret void
}

define void @test_src16_dst16_size_11(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dst16_size_11(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[B]], i32 8
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[A]], i32 8
; CHECK-NEXT:    [[TMP4:%.*]] = load i16, ptr [[TMP2]], align 2
; CHECK-NEXT:    store i16 [[TMP4]], ptr [[TMP3]], align 2
; CHECK-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[TMP2]], i32 2
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[TMP3]], i32 2
; CHECK-NEXT:    [[TMP7:%.*]] = load i8, ptr [[TMP5]], align 1
; CHECK-NEXT:    store i8 [[TMP7]], ptr [[TMP6]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(11) %a, ptr noundef nonnull align 16 dereferenceable(11) %b, i32 11, i1 false)
  ret void
}

define void @test_src16_dst16_size_12(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dst16_size_12(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[B]], i32 8
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[A]], i32 8
; CHECK-NEXT:    [[TMP4:%.*]] = load i32, ptr [[TMP2]], align 4
; CHECK-NEXT:    store i32 [[TMP4]], ptr [[TMP3]], align 4
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(12) %a, ptr noundef nonnull align 16 dereferenceable(12) %b, i32 12, i1 false)
  ret void
}

define void @test_src16_dst16_size_13(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dst16_size_13(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[B]], i32 8
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[A]], i32 8
; CHECK-NEXT:    [[TMP4:%.*]] = load i32, ptr [[TMP2]], align 4
; CHECK-NEXT:    store i32 [[TMP4]], ptr [[TMP3]], align 4
; CHECK-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[TMP2]], i32 4
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[TMP3]], i32 4
; CHECK-NEXT:    [[TMP7:%.*]] = load i8, ptr [[TMP5]], align 1
; CHECK-NEXT:    store i8 [[TMP7]], ptr [[TMP6]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(13) %a, ptr noundef nonnull align 16 dereferenceable(13) %b, i32 13, i1 false)
  ret void
}

define void @test_src16_dst16_size_14(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dst16_size_14(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[B]], i32 8
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[A]], i32 8
; CHECK-NEXT:    [[TMP4:%.*]] = load i32, ptr [[TMP2]], align 4
; CHECK-NEXT:    store i32 [[TMP4]], ptr [[TMP3]], align 4
; CHECK-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[TMP2]], i32 4
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[TMP3]], i32 4
; CHECK-NEXT:    [[TMP7:%.*]] = load i16, ptr [[TMP5]], align 2
; CHECK-NEXT:    store i16 [[TMP7]], ptr [[TMP6]], align 2
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(14) %a, ptr noundef nonnull align 16 dereferenceable(14) %b, i32 14, i1 false)
  ret void
}

define void @test_src16_dst16_size_15(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dst16_size_15(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[B]], i32 8
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[A]], i32 8
; CHECK-NEXT:    [[TMP4:%.*]] = load i32, ptr [[TMP2]], align 4
; CHECK-NEXT:    store i32 [[TMP4]], ptr [[TMP3]], align 4
; CHECK-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[TMP2]], i32 4
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[TMP3]], i32 4
; CHECK-NEXT:    [[TMP7:%.*]] = load i16, ptr [[TMP5]], align 2
; CHECK-NEXT:    store i16 [[TMP7]], ptr [[TMP6]], align 2
; CHECK-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[TMP5]], i32 2
; CHECK-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[TMP6]], i32 2
; CHECK-NEXT:    [[TMP10:%.*]] = load i8, ptr [[TMP8]], align 1
; CHECK-NEXT:    store i8 [[TMP10]], ptr [[TMP9]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(15) %a, ptr noundef nonnull align 16 dereferenceable(15) %b, i32 15, i1 false)
  ret void
}

define void @test_src16_dst16_size_16(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dst16_size_16(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q0, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q0, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(16) %a, ptr noundef nonnull align 16 dereferenceable(16) %b, i32 16, i1 false)
  ret void
}

define void @test_src16_dst16_size_17(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dst16_size_17(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q0, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q0, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[B]], i64 16
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[A]], i64 16
; CHECK-NEXT:    [[TMP4:%.*]] = load i8, ptr [[TMP2]], align 1
; CHECK-NEXT:    store i8 [[TMP4]], ptr [[TMP3]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(17) %a, ptr noundef nonnull align 16 dereferenceable(17) %b, i32 17, i1 false)
  ret void
}

define void @test_src16_dst16_size_31(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dst16_size_31(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q0, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q0, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[B]], i64 16
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[A]], i64 16
; CHECK-NEXT:    [[TMP4:%.*]] = ptrtoint ptr [[TMP2]] to i32
; CHECK-NEXT:    [[TMP5:%.*]] = ptrtoint ptr [[TMP3]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP4]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP5]])
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[TMP2]], i32 8
; CHECK-NEXT:    [[TMP7:%.*]] = getelementptr i8, ptr [[TMP3]], i32 8
; CHECK-NEXT:    [[TMP8:%.*]] = load i32, ptr [[TMP6]], align 4
; CHECK-NEXT:    store i32 [[TMP8]], ptr [[TMP7]], align 4
; CHECK-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[TMP6]], i32 4
; CHECK-NEXT:    [[TMP10:%.*]] = getelementptr i8, ptr [[TMP7]], i32 4
; CHECK-NEXT:    [[TMP11:%.*]] = load i16, ptr [[TMP9]], align 2
; CHECK-NEXT:    store i16 [[TMP11]], ptr [[TMP10]], align 2
; CHECK-NEXT:    [[TMP12:%.*]] = getelementptr i8, ptr [[TMP9]], i32 2
; CHECK-NEXT:    [[TMP13:%.*]] = getelementptr i8, ptr [[TMP10]], i32 2
; CHECK-NEXT:    [[TMP14:%.*]] = load i8, ptr [[TMP12]], align 1
; CHECK-NEXT:    store i8 [[TMP14]], ptr [[TMP13]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(31) %a, ptr noundef nonnull align 16 dereferenceable(31) %b, i32 31, i1 false)
  ret void
}

define void @test_src16_dst16_size_32(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dst16_size_32(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q0, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q1, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q0, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q1, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(32) %a, ptr noundef nonnull align 16 dereferenceable(32) %b, i32 32, i1 false)
  ret void
}

define void @test_src16_dst16_size_33(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dst16_size_33(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q0, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q1, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q0, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q1, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[B]], i64 32
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[A]], i64 32
; CHECK-NEXT:    [[TMP4:%.*]] = load i8, ptr [[TMP2]], align 1
; CHECK-NEXT:    store i8 [[TMP4]], ptr [[TMP3]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(33) %a, ptr noundef nonnull align 16 dereferenceable(33) %b, i32 33, i1 false)
  ret void
}

define void @test_src16_dst16_size_47(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dst16_size_47(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q0, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q1, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q0, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q1, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[B]], i64 32
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[A]], i64 32
; CHECK-NEXT:    [[TMP4:%.*]] = ptrtoint ptr [[TMP2]] to i32
; CHECK-NEXT:    [[TMP5:%.*]] = ptrtoint ptr [[TMP3]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP4]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP5]])
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[TMP2]], i32 8
; CHECK-NEXT:    [[TMP7:%.*]] = getelementptr i8, ptr [[TMP3]], i32 8
; CHECK-NEXT:    [[TMP8:%.*]] = load i32, ptr [[TMP6]], align 4
; CHECK-NEXT:    store i32 [[TMP8]], ptr [[TMP7]], align 4
; CHECK-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[TMP6]], i32 4
; CHECK-NEXT:    [[TMP10:%.*]] = getelementptr i8, ptr [[TMP7]], i32 4
; CHECK-NEXT:    [[TMP11:%.*]] = load i16, ptr [[TMP9]], align 2
; CHECK-NEXT:    store i16 [[TMP11]], ptr [[TMP10]], align 2
; CHECK-NEXT:    [[TMP12:%.*]] = getelementptr i8, ptr [[TMP9]], i32 2
; CHECK-NEXT:    [[TMP13:%.*]] = getelementptr i8, ptr [[TMP10]], i32 2
; CHECK-NEXT:    [[TMP14:%.*]] = load i8, ptr [[TMP12]], align 1
; CHECK-NEXT:    store i8 [[TMP14]], ptr [[TMP13]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(47) %a, ptr noundef nonnull align 16 dereferenceable(47) %b, i32 47, i1 false)
  ret void
}

define void @test_src16_dst16_size_48(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dst16_size_48(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q0, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q1, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q2, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q0, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q1, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q2, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(48) %a, ptr noundef nonnull align 16 dereferenceable(48) %b, i32 48, i1 false)
  ret void
}

define void @test_src16_dst16_size_49(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dst16_size_49(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q0, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q1, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q2, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q0, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q1, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q2, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[B]], i64 48
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[A]], i64 48
; CHECK-NEXT:    [[TMP4:%.*]] = load i8, ptr [[TMP2]], align 1
; CHECK-NEXT:    store i8 [[TMP4]], ptr [[TMP3]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(49) %a, ptr noundef nonnull align 16 dereferenceable(49) %b, i32 49, i1 false)
  ret void
}

define void @test_src16_dst16_size_63(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dst16_size_63(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q0, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q1, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q2, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q0, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q1, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q2, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[B]], i64 48
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[A]], i64 48
; CHECK-NEXT:    [[TMP4:%.*]] = ptrtoint ptr [[TMP2]] to i32
; CHECK-NEXT:    [[TMP5:%.*]] = ptrtoint ptr [[TMP3]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP4]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP5]])
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[TMP2]], i32 8
; CHECK-NEXT:    [[TMP7:%.*]] = getelementptr i8, ptr [[TMP3]], i32 8
; CHECK-NEXT:    [[TMP8:%.*]] = load i32, ptr [[TMP6]], align 4
; CHECK-NEXT:    store i32 [[TMP8]], ptr [[TMP7]], align 4
; CHECK-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[TMP6]], i32 4
; CHECK-NEXT:    [[TMP10:%.*]] = getelementptr i8, ptr [[TMP7]], i32 4
; CHECK-NEXT:    [[TMP11:%.*]] = load i16, ptr [[TMP9]], align 2
; CHECK-NEXT:    store i16 [[TMP11]], ptr [[TMP10]], align 2
; CHECK-NEXT:    [[TMP12:%.*]] = getelementptr i8, ptr [[TMP9]], i32 2
; CHECK-NEXT:    [[TMP13:%.*]] = getelementptr i8, ptr [[TMP10]], i32 2
; CHECK-NEXT:    [[TMP14:%.*]] = load i8, ptr [[TMP12]], align 1
; CHECK-NEXT:    store i8 [[TMP14]], ptr [[TMP13]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(63) %a, ptr noundef nonnull align 16 dereferenceable(63) %b, i32 63, i1 false)
  ret void
}

define void @test_src16_dst16_size_64(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dst16_size_64(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q0, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q1, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q2, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q3, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q0, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q1, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q2, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q3, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(64) %a, ptr noundef nonnull align 16 dereferenceable(64) %b, i32 64, i1 false)
  ret void
}

define void @test_src16_dst16_size_65(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dst16_size_65(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q0, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q1, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q2, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q3, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q0, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q1, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q2, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q3, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[B]], i64 64
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[A]], i64 64
; CHECK-NEXT:    [[TMP4:%.*]] = load i8, ptr [[TMP2]], align 1
; CHECK-NEXT:    store i8 [[TMP4]], ptr [[TMP3]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(65) %a, ptr noundef nonnull align 16 dereferenceable(65) %b, i32 65, i1 false)
  ret void
}

define void @test_src16_dst16_size_80(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dst16_size_80(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q0, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q1, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q2, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q3, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q4, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q0, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q1, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q2, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q3, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q4, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(80) %a, ptr noundef nonnull align 16 dereferenceable(80) %b, i32 80, i1 false)
  ret void
}

define void @test_src16_dst16_size_81(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dst16_size_81(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q0, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q1, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q2, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q3, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q4, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q0, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q1, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q2, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q3, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q4, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[B]], i64 80
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[A]], i64 80
; CHECK-NEXT:    [[TMP4:%.*]] = load i8, ptr [[TMP2]], align 1
; CHECK-NEXT:    store i8 [[TMP4]], ptr [[TMP3]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(81) %a, ptr noundef nonnull align 16 dereferenceable(81) %b, i32 81, i1 false)
  ret void
}

define void @test_src16_dst16_size_88(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dst16_size_88(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q0, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q1, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q2, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q3, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q4, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q0, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q1, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q2, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q3, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q4, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(88) %a, ptr noundef nonnull align 16 dereferenceable(88) %b, i32 88, i1 false)
  ret void
}

define void @test_src16_dst16_size_96(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dst16_size_96(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q0, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q1, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q2, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q3, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q4, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q5, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q0, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q1, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q2, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q3, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q4, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q5, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(96) %a, ptr noundef nonnull align 16 dereferenceable(96) %b, i32 96, i1 false)
  ret void
}

define void @test_src16_dst16_size_112(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dst16_size_112(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q0, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q1, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q2, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q3, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q4, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q5, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q6, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q0, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q1, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q2, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q3, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q4, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q5, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q6, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(112) %a, ptr noundef nonnull align 16 dereferenceable(112) %b, i32 112, i1 false)
  ret void
}

define void @test_src16_dst16_size_124(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dst16_size_124(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q0, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q1, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q2, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q3, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q4, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q5, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q6, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q0, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q1, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q2, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q3, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q4, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q5, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q6, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[B]], i64 112
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[A]], i64 112
; CHECK-NEXT:    [[TMP4:%.*]] = ptrtoint ptr [[TMP2]] to i32
; CHECK-NEXT:    [[TMP5:%.*]] = ptrtoint ptr [[TMP3]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP4]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP5]])
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[TMP2]], i32 8
; CHECK-NEXT:    [[TMP7:%.*]] = getelementptr i8, ptr [[TMP3]], i32 8
; CHECK-NEXT:    [[TMP8:%.*]] = load i32, ptr [[TMP6]], align 4
; CHECK-NEXT:    store i32 [[TMP8]], ptr [[TMP7]], align 4
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(124) %a, ptr noundef nonnull align 16 dereferenceable(124) %b, i32 124, i1 false)
  ret void
}

define void @test_src16_dst16_size_127(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dst16_size_127(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q0, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q1, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q2, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q3, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q4, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q5, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q6, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q0, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q1, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q2, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q3, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q4, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q5, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q6, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[B]], i64 112
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[A]], i64 112
; CHECK-NEXT:    [[TMP4:%.*]] = ptrtoint ptr [[TMP2]] to i32
; CHECK-NEXT:    [[TMP5:%.*]] = ptrtoint ptr [[TMP3]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP4]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP5]])
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[TMP2]], i32 8
; CHECK-NEXT:    [[TMP7:%.*]] = getelementptr i8, ptr [[TMP3]], i32 8
; CHECK-NEXT:    [[TMP8:%.*]] = load i32, ptr [[TMP6]], align 4
; CHECK-NEXT:    store i32 [[TMP8]], ptr [[TMP7]], align 4
; CHECK-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[TMP6]], i32 4
; CHECK-NEXT:    [[TMP10:%.*]] = getelementptr i8, ptr [[TMP7]], i32 4
; CHECK-NEXT:    [[TMP11:%.*]] = load i16, ptr [[TMP9]], align 2
; CHECK-NEXT:    store i16 [[TMP11]], ptr [[TMP10]], align 2
; CHECK-NEXT:    [[TMP12:%.*]] = getelementptr i8, ptr [[TMP9]], i32 2
; CHECK-NEXT:    [[TMP13:%.*]] = getelementptr i8, ptr [[TMP10]], i32 2
; CHECK-NEXT:    [[TMP14:%.*]] = load i8, ptr [[TMP12]], align 1
; CHECK-NEXT:    store i8 [[TMP14]], ptr [[TMP13]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(127) %a, ptr noundef nonnull align 16 dereferenceable(127) %b, i32 127, i1 false)
  ret void
}

define void @test_src16_dst16_size_128(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dst16_size_128(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q0, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q1, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q2, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q3, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q4, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q5, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q6, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q7, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q0, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q1, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q2, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q3, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q4, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q5, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q6, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q7, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(128) %a, ptr noundef nonnull align 16 dereferenceable(128) %b, i32 128, i1 false)
  ret void
}

define void @test_src16_dst16_size_129(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dst16_size_129(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q0, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q1, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q2, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q3, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q4, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q5, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q6, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q7, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q0, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q1, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q2, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q3, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q4, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q5, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q6, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q7, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[B]], i64 128
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[A]], i64 128
; CHECK-NEXT:    [[TMP4:%.*]] = load i8, ptr [[TMP2]], align 1
; CHECK-NEXT:    store i8 [[TMP4]], ptr [[TMP3]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(129) %a, ptr noundef nonnull align 16 dereferenceable(129) %b, i32 129, i1 false)
  ret void
}

define void @test_src16_dst16_size_255(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dst16_size_255(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q0, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q1, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q2, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q3, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q4, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q5, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q6, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q7, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q0, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q1, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q2, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q3, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q4, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q5, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q6, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q7, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q0, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q1, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q2, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q3, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q4, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q5, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q6, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q0, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q1, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q2, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q3, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q4, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q5, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q6, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[B]], i64 240
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[A]], i64 240
; CHECK-NEXT:    [[TMP4:%.*]] = ptrtoint ptr [[TMP2]] to i32
; CHECK-NEXT:    [[TMP5:%.*]] = ptrtoint ptr [[TMP3]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP4]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP5]])
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[TMP2]], i32 8
; CHECK-NEXT:    [[TMP7:%.*]] = getelementptr i8, ptr [[TMP3]], i32 8
; CHECK-NEXT:    [[TMP8:%.*]] = load i32, ptr [[TMP6]], align 4
; CHECK-NEXT:    store i32 [[TMP8]], ptr [[TMP7]], align 4
; CHECK-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[TMP6]], i32 4
; CHECK-NEXT:    [[TMP10:%.*]] = getelementptr i8, ptr [[TMP7]], i32 4
; CHECK-NEXT:    [[TMP11:%.*]] = load i16, ptr [[TMP9]], align 2
; CHECK-NEXT:    store i16 [[TMP11]], ptr [[TMP10]], align 2
; CHECK-NEXT:    [[TMP12:%.*]] = getelementptr i8, ptr [[TMP9]], i32 2
; CHECK-NEXT:    [[TMP13:%.*]] = getelementptr i8, ptr [[TMP10]], i32 2
; CHECK-NEXT:    [[TMP14:%.*]] = load i8, ptr [[TMP12]], align 1
; CHECK-NEXT:    store i8 [[TMP14]], ptr [[TMP13]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(255) %a, ptr noundef nonnull align 16 dereferenceable(255) %b, i32 255, i1 false)
  ret void
}

define void @test_src16_dst16_size_256(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dst16_size_256(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q0, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q1, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q2, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q3, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q4, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q5, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q6, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q7, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q0, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q1, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q2, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q3, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q4, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q5, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q6, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q7, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q0, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q1, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q2, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q3, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q4, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q5, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q6, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q7, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q0, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q1, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q2, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q3, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q4, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q5, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q6, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q7, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(256) %a, ptr noundef nonnull align 16 dereferenceable(256) %b, i32 256, i1 false)
  ret void
}

define void @test_src16_dst16_size_1023(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dst16_size_1023(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q0, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q1, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q2, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q3, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q4, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q5, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q6, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q7, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q0, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q1, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q2, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q3, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q4, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q5, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q6, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q7, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q0, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q1, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q2, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q3, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q4, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q5, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q6, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q7, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q0, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q1, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q2, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q3, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q4, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q5, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q6, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q7, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q0, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q1, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q2, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q3, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q4, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q5, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q6, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q7, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q0, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q1, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q2, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q3, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q4, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q5, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q6, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q7, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q0, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q1, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q2, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q3, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q4, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q5, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q6, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q7, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q0, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q1, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q2, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q3, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q4, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q5, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q6, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q7, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q0, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q1, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q2, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q3, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q4, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q5, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q6, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q7, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q0, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q1, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q2, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q3, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q4, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q5, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q6, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q7, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q0, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q1, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q2, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q3, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q4, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q5, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q6, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q7, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q0, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q1, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q2, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q3, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q4, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q5, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q6, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q7, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q0, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q1, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q2, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q3, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q4, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q5, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q6, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q7, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q0, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q1, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q2, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q3, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q4, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q5, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q6, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q7, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q0, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q1, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q2, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q3, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q4, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q5, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q6, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q0, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q1, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q2, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q3, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q4, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q5, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q6, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[B]], i64 1008
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[A]], i64 1008
; CHECK-NEXT:    [[TMP4:%.*]] = ptrtoint ptr [[TMP2]] to i32
; CHECK-NEXT:    [[TMP5:%.*]] = ptrtoint ptr [[TMP3]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP4]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP5]])
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[TMP2]], i32 8
; CHECK-NEXT:    [[TMP7:%.*]] = getelementptr i8, ptr [[TMP3]], i32 8
; CHECK-NEXT:    [[TMP8:%.*]] = load i32, ptr [[TMP6]], align 4
; CHECK-NEXT:    store i32 [[TMP8]], ptr [[TMP7]], align 4
; CHECK-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[TMP6]], i32 4
; CHECK-NEXT:    [[TMP10:%.*]] = getelementptr i8, ptr [[TMP7]], i32 4
; CHECK-NEXT:    [[TMP11:%.*]] = load i16, ptr [[TMP9]], align 2
; CHECK-NEXT:    store i16 [[TMP11]], ptr [[TMP10]], align 2
; CHECK-NEXT:    [[TMP12:%.*]] = getelementptr i8, ptr [[TMP9]], i32 2
; CHECK-NEXT:    [[TMP13:%.*]] = getelementptr i8, ptr [[TMP10]], i32 2
; CHECK-NEXT:    [[TMP14:%.*]] = load i8, ptr [[TMP12]], align 1
; CHECK-NEXT:    store i8 [[TMP14]], ptr [[TMP13]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(1023) %a, ptr noundef nonnull align 16 dereferenceable(1023) %b, i32 1023, i1 false)
  ret void
}

define void @test_src16_dst16_size_1024(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dst16_size_1024(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q0, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q1, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q2, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q3, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q4, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q5, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q6, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q7, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q0, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q1, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q2, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q3, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q4, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q5, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q6, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q7, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q0, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q1, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q2, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q3, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q4, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q5, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q6, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q7, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q0, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q1, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q2, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q3, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q4, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q5, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q6, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q7, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q0, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q1, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q2, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q3, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q4, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q5, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q6, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q7, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q0, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q1, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q2, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q3, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q4, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q5, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q6, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q7, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q0, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q1, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q2, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q3, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q4, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q5, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q6, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q7, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q0, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q1, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q2, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q3, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q4, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q5, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q6, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q7, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q0, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q1, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q2, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q3, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q4, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q5, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q6, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q7, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q0, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q1, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q2, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q3, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q4, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q5, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q6, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q7, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q0, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q1, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q2, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q3, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q4, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q5, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q6, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q7, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q0, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q1, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q2, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q3, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q4, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q5, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q6, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q7, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q0, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q1, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q2, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q3, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q4, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q5, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q6, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q7, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q0, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q1, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q2, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q3, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q4, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q5, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q6, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q7, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q0, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q1, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q2, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q3, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q4, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q5, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q6, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q7, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q0, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q1, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q2, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q3, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q4, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q5, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q6, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q7, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(1024) %a, ptr noundef nonnull align 16 dereferenceable(1024) %b, i32 1024, i1 false)
  ret void
}

define void @test_src16_dst16_size_20000(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dst16_size_20000(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    tail call void @esp32p4MemCpySrc16Dst16Const16(i32 [[TMP1]], i32 [[TMP0]], i32 20000)
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(20000) %a, ptr noundef nonnull align 16 dereferenceable(20000) %b, i32 20000, i1 false)
  ret void
}


; src16 dst8
define void @test_src16_dst8_size_1(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dst8_size_1(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = load i8, ptr [[B]], align 1
; CHECK-NEXT:    store i8 [[TMP0]], ptr [[A]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(1) %a, ptr noundef nonnull align 16 dereferenceable(1) %b, i32 1, i1 false)
  ret void
}

define void @test_src16_dst8_size_2(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dst8_size_2(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = load i16, ptr [[B]], align 2
; CHECK-NEXT:    store i16 [[TMP0]], ptr [[A]], align 2
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(2) %a, ptr noundef nonnull align 16 dereferenceable(2) %b, i32 2, i1 false)
  ret void
}

define void @test_src16_dst8_size_3(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dst8_size_3(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = load i16, ptr [[B]], align 2
; CHECK-NEXT:    store i16 [[TMP0]], ptr [[A]], align 2
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[B]], i32 2
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[A]], i32 2
; CHECK-NEXT:    [[TMP3:%.*]] = load i8, ptr [[TMP1]], align 1
; CHECK-NEXT:    store i8 [[TMP3]], ptr [[TMP2]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(3) %a, ptr noundef nonnull align 16 dereferenceable(3) %b, i32 3, i1 false)
  ret void
}

define void @test_src16_dst8_size_4(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dst8_size_4(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = load i32, ptr [[B]], align 4
; CHECK-NEXT:    store i32 [[TMP0]], ptr [[A]], align 4
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(4) %a, ptr noundef nonnull align 16 dereferenceable(4) %b, i32 4, i1 false)
  ret void
}

define void @test_src16_dst8_size_5(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dst8_size_5(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = load i32, ptr [[B]], align 4
; CHECK-NEXT:    store i32 [[TMP0]], ptr [[A]], align 4
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[B]], i32 4
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[A]], i32 4
; CHECK-NEXT:    [[TMP3:%.*]] = load i8, ptr [[TMP1]], align 1
; CHECK-NEXT:    store i8 [[TMP3]], ptr [[TMP2]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(5) %a, ptr noundef nonnull align 16 dereferenceable(5) %b, i32 5, i1 false)
  ret void
}

define void @test_src16_dst8_size_6(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dst8_size_6(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = load i32, ptr [[B]], align 4
; CHECK-NEXT:    store i32 [[TMP0]], ptr [[A]], align 4
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[B]], i32 4
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[A]], i32 4
; CHECK-NEXT:    [[TMP3:%.*]] = load i16, ptr [[TMP1]], align 2
; CHECK-NEXT:    store i16 [[TMP3]], ptr [[TMP2]], align 2
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(6) %a, ptr noundef nonnull align 16 dereferenceable(6) %b, i32 6, i1 false)
  ret void
}

define void @test_src16_dst8_size_7(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dst8_size_7(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = load i32, ptr [[B]], align 4
; CHECK-NEXT:    store i32 [[TMP0]], ptr [[A]], align 4
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[B]], i32 4
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[A]], i32 4
; CHECK-NEXT:    [[TMP3:%.*]] = load i16, ptr [[TMP1]], align 2
; CHECK-NEXT:    store i16 [[TMP3]], ptr [[TMP2]], align 2
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[TMP1]], i32 2
; CHECK-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[TMP2]], i32 2
; CHECK-NEXT:    [[TMP6:%.*]] = load i8, ptr [[TMP4]], align 1
; CHECK-NEXT:    store i8 [[TMP6]], ptr [[TMP5]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(7) %a, ptr noundef nonnull align 16 dereferenceable(7) %b, i32 7, i1 false)
  ret void
}

define void @test_src16_dst8_size_8(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dst8_size_8(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = getelementptr i8, ptr [[B]], i32 0
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[A]], i32 0
; CHECK-NEXT:    [[TMP2:%.*]] = load i32, ptr [[TMP0]], align 4
; CHECK-NEXT:    store i32 [[TMP2]], ptr [[TMP1]], align 4
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[B]], i32 4
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[A]], i32 4
; CHECK-NEXT:    [[TMP5:%.*]] = load i32, ptr [[TMP3]], align 4
; CHECK-NEXT:    store i32 [[TMP5]], ptr [[TMP4]], align 4
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(8) %a, ptr noundef nonnull align 16 dereferenceable(8) %b, i32 8, i1 false)
  ret void
}

define void @test_src16_dst8_size_9(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dst8_size_9(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[B]], i32 8
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[A]], i32 8
; CHECK-NEXT:    [[TMP4:%.*]] = load i8, ptr [[TMP2]], align 1
; CHECK-NEXT:    store i8 [[TMP4]], ptr [[TMP3]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(9) %a, ptr noundef nonnull align 16 dereferenceable(9) %b, i32 9, i1 false)
  ret void
}

define void @test_src16_dst8_size_10(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dst8_size_10(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[B]], i32 8
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[A]], i32 8
; CHECK-NEXT:    [[TMP4:%.*]] = load i16, ptr [[TMP2]], align 2
; CHECK-NEXT:    store i16 [[TMP4]], ptr [[TMP3]], align 2
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(10) %a, ptr noundef nonnull align 16 dereferenceable(10) %b, i32 10, i1 false)
  ret void
}

define void @test_src16_dst8_size_11(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dst8_size_11(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[B]], i32 8
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[A]], i32 8
; CHECK-NEXT:    [[TMP4:%.*]] = load i16, ptr [[TMP2]], align 2
; CHECK-NEXT:    store i16 [[TMP4]], ptr [[TMP3]], align 2
; CHECK-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[TMP2]], i32 2
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[TMP3]], i32 2
; CHECK-NEXT:    [[TMP7:%.*]] = load i8, ptr [[TMP5]], align 1
; CHECK-NEXT:    store i8 [[TMP7]], ptr [[TMP6]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(11) %a, ptr noundef nonnull align 16 dereferenceable(11) %b, i32 11, i1 false)
  ret void
}

define void @test_src16_dst8_size_12(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dst8_size_12(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[B]], i32 8
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[A]], i32 8
; CHECK-NEXT:    [[TMP4:%.*]] = load i32, ptr [[TMP2]], align 4
; CHECK-NEXT:    store i32 [[TMP4]], ptr [[TMP3]], align 4
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(12) %a, ptr noundef nonnull align 16 dereferenceable(12) %b, i32 12, i1 false)
  ret void
}

define void @test_src16_dst8_size_13(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dst8_size_13(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[B]], i32 8
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[A]], i32 8
; CHECK-NEXT:    [[TMP4:%.*]] = load i32, ptr [[TMP2]], align 4
; CHECK-NEXT:    store i32 [[TMP4]], ptr [[TMP3]], align 4
; CHECK-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[TMP2]], i32 4
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[TMP3]], i32 4
; CHECK-NEXT:    [[TMP7:%.*]] = load i8, ptr [[TMP5]], align 1
; CHECK-NEXT:    store i8 [[TMP7]], ptr [[TMP6]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(13) %a, ptr noundef nonnull align 16 dereferenceable(13) %b, i32 13, i1 false)
  ret void
}

define void @test_src16_dst8_size_14(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dst8_size_14(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[B]], i32 8
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[A]], i32 8
; CHECK-NEXT:    [[TMP4:%.*]] = load i32, ptr [[TMP2]], align 4
; CHECK-NEXT:    store i32 [[TMP4]], ptr [[TMP3]], align 4
; CHECK-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[TMP2]], i32 4
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[TMP3]], i32 4
; CHECK-NEXT:    [[TMP7:%.*]] = load i16, ptr [[TMP5]], align 2
; CHECK-NEXT:    store i16 [[TMP7]], ptr [[TMP6]], align 2
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(14) %a, ptr noundef nonnull align 16 dereferenceable(14) %b, i32 14, i1 false)
  ret void
}

define void @test_src16_dst8_size_15(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dst8_size_15(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[B]], i32 8
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[A]], i32 8
; CHECK-NEXT:    [[TMP4:%.*]] = load i32, ptr [[TMP2]], align 4
; CHECK-NEXT:    store i32 [[TMP4]], ptr [[TMP3]], align 4
; CHECK-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[TMP2]], i32 4
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[TMP3]], i32 4
; CHECK-NEXT:    [[TMP7:%.*]] = load i16, ptr [[TMP5]], align 2
; CHECK-NEXT:    store i16 [[TMP7]], ptr [[TMP6]], align 2
; CHECK-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[TMP5]], i32 2
; CHECK-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[TMP6]], i32 2
; CHECK-NEXT:    [[TMP10:%.*]] = load i8, ptr [[TMP8]], align 1
; CHECK-NEXT:    store i8 [[TMP10]], ptr [[TMP9]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(15) %a, ptr noundef nonnull align 16 dereferenceable(15) %b, i32 15, i1 false)
  ret void
}

define void @test_src16_dst8_size_16(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dst8_size_16(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q0, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(16) %a, ptr noundef nonnull align 16 dereferenceable(16) %b, i32 16, i1 false)
  ret void
}

define void @test_src16_dst8_size_17(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dst8_size_17(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q0, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[B]], i64 16
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[A]], i64 16
; CHECK-NEXT:    [[TMP4:%.*]] = load i8, ptr [[TMP2]], align 1
; CHECK-NEXT:    store i8 [[TMP4]], ptr [[TMP3]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(17) %a, ptr noundef nonnull align 16 dereferenceable(17) %b, i32 17, i1 false)
  ret void
}

define void @test_src16_dst8_size_31(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dst8_size_31(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q0, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[B]], i64 16
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[A]], i64 16
; CHECK-NEXT:    [[TMP4:%.*]] = ptrtoint ptr [[TMP2]] to i32
; CHECK-NEXT:    [[TMP5:%.*]] = ptrtoint ptr [[TMP3]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP4]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP5]])
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[TMP2]], i32 8
; CHECK-NEXT:    [[TMP7:%.*]] = getelementptr i8, ptr [[TMP3]], i32 8
; CHECK-NEXT:    [[TMP8:%.*]] = load i32, ptr [[TMP6]], align 4
; CHECK-NEXT:    store i32 [[TMP8]], ptr [[TMP7]], align 4
; CHECK-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[TMP6]], i32 4
; CHECK-NEXT:    [[TMP10:%.*]] = getelementptr i8, ptr [[TMP7]], i32 4
; CHECK-NEXT:    [[TMP11:%.*]] = load i16, ptr [[TMP9]], align 2
; CHECK-NEXT:    store i16 [[TMP11]], ptr [[TMP10]], align 2
; CHECK-NEXT:    [[TMP12:%.*]] = getelementptr i8, ptr [[TMP9]], i32 2
; CHECK-NEXT:    [[TMP13:%.*]] = getelementptr i8, ptr [[TMP10]], i32 2
; CHECK-NEXT:    [[TMP14:%.*]] = load i8, ptr [[TMP12]], align 1
; CHECK-NEXT:    store i8 [[TMP14]], ptr [[TMP13]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(31) %a, ptr noundef nonnull align 16 dereferenceable(31) %b, i32 31, i1 false)
  ret void
}

define void @test_src16_dst8_size_32(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dst8_size_32(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q0, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q1, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(32) %a, ptr noundef nonnull align 16 dereferenceable(32) %b, i32 32, i1 false)
  ret void
}

define void @test_src16_dst8_size_33(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dst8_size_33(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q0, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q1, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[B]], i64 32
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[A]], i64 32
; CHECK-NEXT:    [[TMP4:%.*]] = load i8, ptr [[TMP2]], align 1
; CHECK-NEXT:    store i8 [[TMP4]], ptr [[TMP3]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(33) %a, ptr noundef nonnull align 16 dereferenceable(33) %b, i32 33, i1 false)
  ret void
}

define void @test_src16_dst8_size_47(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dst8_size_47(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q0, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q1, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[B]], i64 32
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[A]], i64 32
; CHECK-NEXT:    [[TMP4:%.*]] = ptrtoint ptr [[TMP2]] to i32
; CHECK-NEXT:    [[TMP5:%.*]] = ptrtoint ptr [[TMP3]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP4]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP5]])
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[TMP2]], i32 8
; CHECK-NEXT:    [[TMP7:%.*]] = getelementptr i8, ptr [[TMP3]], i32 8
; CHECK-NEXT:    [[TMP8:%.*]] = load i32, ptr [[TMP6]], align 4
; CHECK-NEXT:    store i32 [[TMP8]], ptr [[TMP7]], align 4
; CHECK-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[TMP6]], i32 4
; CHECK-NEXT:    [[TMP10:%.*]] = getelementptr i8, ptr [[TMP7]], i32 4
; CHECK-NEXT:    [[TMP11:%.*]] = load i16, ptr [[TMP9]], align 2
; CHECK-NEXT:    store i16 [[TMP11]], ptr [[TMP10]], align 2
; CHECK-NEXT:    [[TMP12:%.*]] = getelementptr i8, ptr [[TMP9]], i32 2
; CHECK-NEXT:    [[TMP13:%.*]] = getelementptr i8, ptr [[TMP10]], i32 2
; CHECK-NEXT:    [[TMP14:%.*]] = load i8, ptr [[TMP12]], align 1
; CHECK-NEXT:    store i8 [[TMP14]], ptr [[TMP13]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(47) %a, ptr noundef nonnull align 16 dereferenceable(47) %b, i32 47, i1 false)
  ret void
}

define void @test_src16_dst8_size_48(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dst8_size_48(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q0, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q1, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q2, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(48) %a, ptr noundef nonnull align 16 dereferenceable(48) %b, i32 48, i1 false)
  ret void
}

define void @test_src16_dst8_size_49(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dst8_size_49(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q0, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q1, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q2, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[B]], i64 48
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[A]], i64 48
; CHECK-NEXT:    [[TMP4:%.*]] = load i8, ptr [[TMP2]], align 1
; CHECK-NEXT:    store i8 [[TMP4]], ptr [[TMP3]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(49) %a, ptr noundef nonnull align 16 dereferenceable(49) %b, i32 49, i1 false)
  ret void
}

define void @test_src16_dst8_size_63(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dst8_size_63(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q0, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q1, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q2, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[B]], i64 48
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[A]], i64 48
; CHECK-NEXT:    [[TMP4:%.*]] = ptrtoint ptr [[TMP2]] to i32
; CHECK-NEXT:    [[TMP5:%.*]] = ptrtoint ptr [[TMP3]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP4]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP5]])
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[TMP2]], i32 8
; CHECK-NEXT:    [[TMP7:%.*]] = getelementptr i8, ptr [[TMP3]], i32 8
; CHECK-NEXT:    [[TMP8:%.*]] = load i32, ptr [[TMP6]], align 4
; CHECK-NEXT:    store i32 [[TMP8]], ptr [[TMP7]], align 4
; CHECK-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[TMP6]], i32 4
; CHECK-NEXT:    [[TMP10:%.*]] = getelementptr i8, ptr [[TMP7]], i32 4
; CHECK-NEXT:    [[TMP11:%.*]] = load i16, ptr [[TMP9]], align 2
; CHECK-NEXT:    store i16 [[TMP11]], ptr [[TMP10]], align 2
; CHECK-NEXT:    [[TMP12:%.*]] = getelementptr i8, ptr [[TMP9]], i32 2
; CHECK-NEXT:    [[TMP13:%.*]] = getelementptr i8, ptr [[TMP10]], i32 2
; CHECK-NEXT:    [[TMP14:%.*]] = load i8, ptr [[TMP12]], align 1
; CHECK-NEXT:    store i8 [[TMP14]], ptr [[TMP13]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(63) %a, ptr noundef nonnull align 16 dereferenceable(63) %b, i32 63, i1 false)
  ret void
}

define void @test_src16_dst8_size_64(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dst8_size_64(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q0, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q1, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q2, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q3, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(64) %a, ptr noundef nonnull align 16 dereferenceable(64) %b, i32 64, i1 false)
  ret void
}

define void @test_src16_dst8_size_65(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dst8_size_65(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q0, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q1, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q2, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q3, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[B]], i64 64
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[A]], i64 64
; CHECK-NEXT:    [[TMP4:%.*]] = load i8, ptr [[TMP2]], align 1
; CHECK-NEXT:    store i8 [[TMP4]], ptr [[TMP3]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(65) %a, ptr noundef nonnull align 16 dereferenceable(65) %b, i32 65, i1 false)
  ret void
}

define void @test_src16_dst8_size_80(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dst8_size_80(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q0, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q1, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q2, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q3, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q4, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(80) %a, ptr noundef nonnull align 16 dereferenceable(80) %b, i32 80, i1 false)
  ret void
}

define void @test_src16_dst8_size_81(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dst8_size_81(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q0, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q1, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q2, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q3, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q4, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[B]], i64 80
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[A]], i64 80
; CHECK-NEXT:    [[TMP4:%.*]] = load i8, ptr [[TMP2]], align 1
; CHECK-NEXT:    store i8 [[TMP4]], ptr [[TMP3]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(81) %a, ptr noundef nonnull align 16 dereferenceable(81) %b, i32 81, i1 false)
  ret void
}

define void @test_src16_dst8_size_88(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dst8_size_88(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q0, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q1, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q2, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q3, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q4, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(88) %a, ptr noundef nonnull align 16 dereferenceable(88) %b, i32 88, i1 false)
  ret void
}

define void @test_src16_dst8_size_96(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dst8_size_96(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q0, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q1, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q2, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q3, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q4, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q5, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(96) %a, ptr noundef nonnull align 16 dereferenceable(96) %b, i32 96, i1 false)
  ret void
}

define void @test_src16_dst8_size_112(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dst8_size_112(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q0, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q1, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q2, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q3, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q4, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q5, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q6, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q6, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q6, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(112) %a, ptr noundef nonnull align 16 dereferenceable(112) %b, i32 112, i1 false)
  ret void
}

define void @test_src16_dst8_size_124(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dst8_size_124(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q0, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q1, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q2, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q3, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q4, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q5, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q6, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q6, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q6, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[B]], i64 112
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[A]], i64 112
; CHECK-NEXT:    [[TMP4:%.*]] = ptrtoint ptr [[TMP2]] to i32
; CHECK-NEXT:    [[TMP5:%.*]] = ptrtoint ptr [[TMP3]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP4]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP5]])
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[TMP2]], i32 8
; CHECK-NEXT:    [[TMP7:%.*]] = getelementptr i8, ptr [[TMP3]], i32 8
; CHECK-NEXT:    [[TMP8:%.*]] = load i32, ptr [[TMP6]], align 4
; CHECK-NEXT:    store i32 [[TMP8]], ptr [[TMP7]], align 4
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(124) %a, ptr noundef nonnull align 16 dereferenceable(124) %b, i32 124, i1 false)
  ret void
}

define void @test_src16_dst8_size_127(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dst8_size_127(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q0, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q1, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q2, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q3, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q4, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q5, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q6, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q6, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q6, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[B]], i64 112
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[A]], i64 112
; CHECK-NEXT:    [[TMP4:%.*]] = ptrtoint ptr [[TMP2]] to i32
; CHECK-NEXT:    [[TMP5:%.*]] = ptrtoint ptr [[TMP3]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP4]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP5]])
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[TMP2]], i32 8
; CHECK-NEXT:    [[TMP7:%.*]] = getelementptr i8, ptr [[TMP3]], i32 8
; CHECK-NEXT:    [[TMP8:%.*]] = load i32, ptr [[TMP6]], align 4
; CHECK-NEXT:    store i32 [[TMP8]], ptr [[TMP7]], align 4
; CHECK-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[TMP6]], i32 4
; CHECK-NEXT:    [[TMP10:%.*]] = getelementptr i8, ptr [[TMP7]], i32 4
; CHECK-NEXT:    [[TMP11:%.*]] = load i16, ptr [[TMP9]], align 2
; CHECK-NEXT:    store i16 [[TMP11]], ptr [[TMP10]], align 2
; CHECK-NEXT:    [[TMP12:%.*]] = getelementptr i8, ptr [[TMP9]], i32 2
; CHECK-NEXT:    [[TMP13:%.*]] = getelementptr i8, ptr [[TMP10]], i32 2
; CHECK-NEXT:    [[TMP14:%.*]] = load i8, ptr [[TMP12]], align 1
; CHECK-NEXT:    store i8 [[TMP14]], ptr [[TMP13]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(127) %a, ptr noundef nonnull align 16 dereferenceable(127) %b, i32 127, i1 false)
  ret void
}

define void @test_src16_dst8_size_128(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dst8_size_128(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q0, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q1, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q2, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q3, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q4, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q5, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q6, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q7, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q6, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q6, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q7, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q7, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(128) %a, ptr noundef nonnull align 16 dereferenceable(128) %b, i32 128, i1 false)
  ret void
}

define void @test_src16_dst8_size_129(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dst8_size_129(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q0, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q1, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q2, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q3, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q4, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q5, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q6, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q7, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q6, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q6, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q7, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q7, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[B]], i64 128
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[A]], i64 128
; CHECK-NEXT:    [[TMP4:%.*]] = load i8, ptr [[TMP2]], align 1
; CHECK-NEXT:    store i8 [[TMP4]], ptr [[TMP3]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(129) %a, ptr noundef nonnull align 16 dereferenceable(129) %b, i32 129, i1 false)
  ret void
}

define void @test_src16_dst8_size_255(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dst8_size_255(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q0, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q1, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q2, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q3, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q4, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q5, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q6, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q7, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q6, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q6, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q7, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q7, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q0, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q1, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q2, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q3, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q4, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q5, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q6, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q6, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q6, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[B]], i64 240
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[A]], i64 240
; CHECK-NEXT:    [[TMP4:%.*]] = ptrtoint ptr [[TMP2]] to i32
; CHECK-NEXT:    [[TMP5:%.*]] = ptrtoint ptr [[TMP3]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP4]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP5]])
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[TMP2]], i32 8
; CHECK-NEXT:    [[TMP7:%.*]] = getelementptr i8, ptr [[TMP3]], i32 8
; CHECK-NEXT:    [[TMP8:%.*]] = load i32, ptr [[TMP6]], align 4
; CHECK-NEXT:    store i32 [[TMP8]], ptr [[TMP7]], align 4
; CHECK-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[TMP6]], i32 4
; CHECK-NEXT:    [[TMP10:%.*]] = getelementptr i8, ptr [[TMP7]], i32 4
; CHECK-NEXT:    [[TMP11:%.*]] = load i16, ptr [[TMP9]], align 2
; CHECK-NEXT:    store i16 [[TMP11]], ptr [[TMP10]], align 2
; CHECK-NEXT:    [[TMP12:%.*]] = getelementptr i8, ptr [[TMP9]], i32 2
; CHECK-NEXT:    [[TMP13:%.*]] = getelementptr i8, ptr [[TMP10]], i32 2
; CHECK-NEXT:    [[TMP14:%.*]] = load i8, ptr [[TMP12]], align 1
; CHECK-NEXT:    store i8 [[TMP14]], ptr [[TMP13]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(255) %a, ptr noundef nonnull align 16 dereferenceable(255) %b, i32 255, i1 false)
  ret void
}

define void @test_src16_dst8_size_256(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dst8_size_256(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q0, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q1, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q2, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q3, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q4, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q5, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q6, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q7, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q6, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q6, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q7, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q7, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q0, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q1, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q2, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q3, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q4, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q5, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q6, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q7, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q6, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q6, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q7, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q7, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(256) %a, ptr noundef nonnull align 16 dereferenceable(256) %b, i32 256, i1 false)
  ret void
}

define void @test_src16_dst8_size_1023(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dst8_size_1023(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q0, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q1, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q2, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q3, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q4, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q5, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q6, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q7, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q6, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q6, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q7, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q7, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q0, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q1, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q2, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q3, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q4, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q5, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q6, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q7, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q6, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q6, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q7, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q7, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q0, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q1, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q2, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q3, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q4, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q5, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q6, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q7, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q6, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q6, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q7, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q7, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q0, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q1, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q2, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q3, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q4, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q5, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q6, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q7, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q6, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q6, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q7, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q7, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q0, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q1, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q2, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q3, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q4, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q5, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q6, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q7, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q6, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q6, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q7, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q7, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q0, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q1, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q2, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q3, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q4, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q5, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q6, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q7, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q6, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q6, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q7, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q7, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q0, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q1, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q2, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q3, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q4, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q5, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q6, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q7, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q6, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q6, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q7, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q7, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q0, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q1, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q2, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q3, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q4, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q5, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q6, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q6, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q6, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[B]], i64 1008
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[A]], i64 1008
; CHECK-NEXT:    [[TMP4:%.*]] = ptrtoint ptr [[TMP2]] to i32
; CHECK-NEXT:    [[TMP5:%.*]] = ptrtoint ptr [[TMP3]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP4]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP5]])
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[TMP2]], i32 8
; CHECK-NEXT:    [[TMP7:%.*]] = getelementptr i8, ptr [[TMP3]], i32 8
; CHECK-NEXT:    [[TMP8:%.*]] = load i32, ptr [[TMP6]], align 4
; CHECK-NEXT:    store i32 [[TMP8]], ptr [[TMP7]], align 4
; CHECK-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[TMP6]], i32 4
; CHECK-NEXT:    [[TMP10:%.*]] = getelementptr i8, ptr [[TMP7]], i32 4
; CHECK-NEXT:    [[TMP11:%.*]] = load i16, ptr [[TMP9]], align 2
; CHECK-NEXT:    store i16 [[TMP11]], ptr [[TMP10]], align 2
; CHECK-NEXT:    [[TMP12:%.*]] = getelementptr i8, ptr [[TMP9]], i32 2
; CHECK-NEXT:    [[TMP13:%.*]] = getelementptr i8, ptr [[TMP10]], i32 2
; CHECK-NEXT:    [[TMP14:%.*]] = load i8, ptr [[TMP12]], align 1
; CHECK-NEXT:    store i8 [[TMP14]], ptr [[TMP13]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(1023) %a, ptr noundef nonnull align 16 dereferenceable(1023) %b, i32 1023, i1 false)
  ret void
}

define void @test_src16_dst8_size_1024(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dst8_size_1024(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q0, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q1, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q2, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q3, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q4, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q5, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q6, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q7, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q6, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q6, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q7, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q7, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q0, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q1, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q2, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q3, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q4, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q5, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q6, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q7, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q6, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q6, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q7, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q7, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q0, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q1, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q2, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q3, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q4, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q5, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q6, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q7, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q6, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q6, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q7, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q7, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q0, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q1, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q2, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q3, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q4, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q5, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q6, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q7, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q6, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q6, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q7, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q7, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q0, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q1, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q2, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q3, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q4, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q5, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q6, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q7, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q6, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q6, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q7, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q7, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q0, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q1, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q2, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q3, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q4, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q5, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q6, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q7, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q6, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q6, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q7, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q7, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q0, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q1, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q2, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q3, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q4, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q5, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q6, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q7, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q6, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q6, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q7, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q7, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q0, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q1, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q2, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q3, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q4, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q5, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q6, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.128.ip q7, $0, 16", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q6, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q6, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q7, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q7, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(1024) %a, ptr noundef nonnull align 16 dereferenceable(1024) %b, i32 1024, i1 false)
  ret void
}

define void @test_src16_dst8_size_20000(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dst8_size_20000(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    tail call void @esp32p4MemCpySrc16Dst8Const16(i32 [[TMP1]], i32 [[TMP0]], i32 20000)
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(20000) %a, ptr noundef nonnull align 16 dereferenceable(20000) %b, i32 20000, i1 false)
  ret void
}

; src8 dst16
define void @test_src8_dst16_size_1(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dst16_size_1(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = load i8, ptr [[B]], align 1
; CHECK-NEXT:    store i8 [[TMP0]], ptr [[A]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(1) %a, ptr noundef nonnull align 8 dereferenceable(1) %b, i32 1, i1 false)
  ret void
}

define void @test_src8_dst16_size_2(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dst16_size_2(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = load i16, ptr [[B]], align 2
; CHECK-NEXT:    store i16 [[TMP0]], ptr [[A]], align 2
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(2) %a, ptr noundef nonnull align 8 dereferenceable(2) %b, i32 2, i1 false)
  ret void
}

define void @test_src8_dst16_size_3(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dst16_size_3(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = load i16, ptr [[B]], align 2
; CHECK-NEXT:    store i16 [[TMP0]], ptr [[A]], align 2
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[B]], i32 2
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[A]], i32 2
; CHECK-NEXT:    [[TMP3:%.*]] = load i8, ptr [[TMP1]], align 1
; CHECK-NEXT:    store i8 [[TMP3]], ptr [[TMP2]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(3) %a, ptr noundef nonnull align 8 dereferenceable(3) %b, i32 3, i1 false)
  ret void
}

define void @test_src8_dst16_size_4(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dst16_size_4(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = load i32, ptr [[B]], align 4
; CHECK-NEXT:    store i32 [[TMP0]], ptr [[A]], align 4
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(4) %a, ptr noundef nonnull align 8 dereferenceable(4) %b, i32 4, i1 false)
  ret void
}

define void @test_src8_dst16_size_5(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dst16_size_5(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = load i32, ptr [[B]], align 4
; CHECK-NEXT:    store i32 [[TMP0]], ptr [[A]], align 4
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[B]], i32 4
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[A]], i32 4
; CHECK-NEXT:    [[TMP3:%.*]] = load i8, ptr [[TMP1]], align 1
; CHECK-NEXT:    store i8 [[TMP3]], ptr [[TMP2]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(5) %a, ptr noundef nonnull align 8 dereferenceable(5) %b, i32 5, i1 false)
  ret void
}

define void @test_src8_dst16_size_6(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dst16_size_6(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = load i32, ptr [[B]], align 4
; CHECK-NEXT:    store i32 [[TMP0]], ptr [[A]], align 4
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[B]], i32 4
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[A]], i32 4
; CHECK-NEXT:    [[TMP3:%.*]] = load i16, ptr [[TMP1]], align 2
; CHECK-NEXT:    store i16 [[TMP3]], ptr [[TMP2]], align 2
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(6) %a, ptr noundef nonnull align 8 dereferenceable(6) %b, i32 6, i1 false)
  ret void
}

define void @test_src8_dst16_size_7(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dst16_size_7(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = load i32, ptr [[B]], align 4
; CHECK-NEXT:    store i32 [[TMP0]], ptr [[A]], align 4
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[B]], i32 4
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[A]], i32 4
; CHECK-NEXT:    [[TMP3:%.*]] = load i16, ptr [[TMP1]], align 2
; CHECK-NEXT:    store i16 [[TMP3]], ptr [[TMP2]], align 2
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[TMP1]], i32 2
; CHECK-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[TMP2]], i32 2
; CHECK-NEXT:    [[TMP6:%.*]] = load i8, ptr [[TMP4]], align 1
; CHECK-NEXT:    store i8 [[TMP6]], ptr [[TMP5]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(7) %a, ptr noundef nonnull align 8 dereferenceable(7) %b, i32 7, i1 false)
  ret void
}

define void @test_src8_dst16_size_8(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dst16_size_8(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = getelementptr i8, ptr [[B]], i32 0
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[A]], i32 0
; CHECK-NEXT:    [[TMP2:%.*]] = load i32, ptr [[TMP0]], align 4
; CHECK-NEXT:    store i32 [[TMP2]], ptr [[TMP1]], align 4
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[B]], i32 4
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[A]], i32 4
; CHECK-NEXT:    [[TMP5:%.*]] = load i32, ptr [[TMP3]], align 4
; CHECK-NEXT:    store i32 [[TMP5]], ptr [[TMP4]], align 4
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(8) %a, ptr noundef nonnull align 8 dereferenceable(8) %b, i32 8, i1 false)
  ret void
}

define void @test_src8_dst16_size_9(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dst16_size_9(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[B]], i32 8
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[A]], i32 8
; CHECK-NEXT:    [[TMP4:%.*]] = load i8, ptr [[TMP2]], align 1
; CHECK-NEXT:    store i8 [[TMP4]], ptr [[TMP3]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(9) %a, ptr noundef nonnull align 8 dereferenceable(9) %b, i32 9, i1 false)
  ret void
}

define void @test_src8_dst16_size_10(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dst16_size_10(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[B]], i32 8
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[A]], i32 8
; CHECK-NEXT:    [[TMP4:%.*]] = load i16, ptr [[TMP2]], align 2
; CHECK-NEXT:    store i16 [[TMP4]], ptr [[TMP3]], align 2
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(10) %a, ptr noundef nonnull align 8 dereferenceable(10) %b, i32 10, i1 false)
  ret void
}

define void @test_src8_dst16_size_11(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dst16_size_11(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[B]], i32 8
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[A]], i32 8
; CHECK-NEXT:    [[TMP4:%.*]] = load i16, ptr [[TMP2]], align 2
; CHECK-NEXT:    store i16 [[TMP4]], ptr [[TMP3]], align 2
; CHECK-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[TMP2]], i32 2
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[TMP3]], i32 2
; CHECK-NEXT:    [[TMP7:%.*]] = load i8, ptr [[TMP5]], align 1
; CHECK-NEXT:    store i8 [[TMP7]], ptr [[TMP6]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(11) %a, ptr noundef nonnull align 8 dereferenceable(11) %b, i32 11, i1 false)
  ret void
}

define void @test_src8_dst16_size_12(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dst16_size_12(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[B]], i32 8
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[A]], i32 8
; CHECK-NEXT:    [[TMP4:%.*]] = load i32, ptr [[TMP2]], align 4
; CHECK-NEXT:    store i32 [[TMP4]], ptr [[TMP3]], align 4
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(12) %a, ptr noundef nonnull align 8 dereferenceable(12) %b, i32 12, i1 false)
  ret void
}

define void @test_src8_dst16_size_13(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dst16_size_13(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[B]], i32 8
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[A]], i32 8
; CHECK-NEXT:    [[TMP4:%.*]] = load i32, ptr [[TMP2]], align 4
; CHECK-NEXT:    store i32 [[TMP4]], ptr [[TMP3]], align 4
; CHECK-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[TMP2]], i32 4
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[TMP3]], i32 4
; CHECK-NEXT:    [[TMP7:%.*]] = load i8, ptr [[TMP5]], align 1
; CHECK-NEXT:    store i8 [[TMP7]], ptr [[TMP6]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(13) %a, ptr noundef nonnull align 8 dereferenceable(13) %b, i32 13, i1 false)
  ret void
}

define void @test_src8_dst16_size_14(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dst16_size_14(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[B]], i32 8
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[A]], i32 8
; CHECK-NEXT:    [[TMP4:%.*]] = load i32, ptr [[TMP2]], align 4
; CHECK-NEXT:    store i32 [[TMP4]], ptr [[TMP3]], align 4
; CHECK-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[TMP2]], i32 4
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[TMP3]], i32 4
; CHECK-NEXT:    [[TMP7:%.*]] = load i16, ptr [[TMP5]], align 2
; CHECK-NEXT:    store i16 [[TMP7]], ptr [[TMP6]], align 2
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(14) %a, ptr noundef nonnull align 8 dereferenceable(14) %b, i32 14, i1 false)
  ret void
}

define void @test_src8_dst16_size_15(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dst16_size_15(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[B]], i32 8
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[A]], i32 8
; CHECK-NEXT:    [[TMP4:%.*]] = load i32, ptr [[TMP2]], align 4
; CHECK-NEXT:    store i32 [[TMP4]], ptr [[TMP3]], align 4
; CHECK-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[TMP2]], i32 4
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[TMP3]], i32 4
; CHECK-NEXT:    [[TMP7:%.*]] = load i16, ptr [[TMP5]], align 2
; CHECK-NEXT:    store i16 [[TMP7]], ptr [[TMP6]], align 2
; CHECK-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[TMP5]], i32 2
; CHECK-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[TMP6]], i32 2
; CHECK-NEXT:    [[TMP10:%.*]] = load i8, ptr [[TMP8]], align 1
; CHECK-NEXT:    store i8 [[TMP10]], ptr [[TMP9]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(15) %a, ptr noundef nonnull align 8 dereferenceable(15) %b, i32 15, i1 false)
  ret void
}

define void @test_src8_dst16_size_16(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dst16_size_16(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q0, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(16) %a, ptr noundef nonnull align 8 dereferenceable(16) %b, i32 16, i1 false)
  ret void
}

define void @test_src8_dst16_size_17(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dst16_size_17(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q0, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[B]], i64 16
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[A]], i64 16
; CHECK-NEXT:    [[TMP4:%.*]] = load i8, ptr [[TMP2]], align 1
; CHECK-NEXT:    store i8 [[TMP4]], ptr [[TMP3]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(17) %a, ptr noundef nonnull align 8 dereferenceable(17) %b, i32 17, i1 false)
  ret void
}

define void @test_src8_dst16_size_31(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dst16_size_31(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q0, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[B]], i64 16
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[A]], i64 16
; CHECK-NEXT:    [[TMP4:%.*]] = ptrtoint ptr [[TMP2]] to i32
; CHECK-NEXT:    [[TMP5:%.*]] = ptrtoint ptr [[TMP3]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP4]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP5]])
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[TMP2]], i32 8
; CHECK-NEXT:    [[TMP7:%.*]] = getelementptr i8, ptr [[TMP3]], i32 8
; CHECK-NEXT:    [[TMP8:%.*]] = load i32, ptr [[TMP6]], align 4
; CHECK-NEXT:    store i32 [[TMP8]], ptr [[TMP7]], align 4
; CHECK-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[TMP6]], i32 4
; CHECK-NEXT:    [[TMP10:%.*]] = getelementptr i8, ptr [[TMP7]], i32 4
; CHECK-NEXT:    [[TMP11:%.*]] = load i16, ptr [[TMP9]], align 2
; CHECK-NEXT:    store i16 [[TMP11]], ptr [[TMP10]], align 2
; CHECK-NEXT:    [[TMP12:%.*]] = getelementptr i8, ptr [[TMP9]], i32 2
; CHECK-NEXT:    [[TMP13:%.*]] = getelementptr i8, ptr [[TMP10]], i32 2
; CHECK-NEXT:    [[TMP14:%.*]] = load i8, ptr [[TMP12]], align 1
; CHECK-NEXT:    store i8 [[TMP14]], ptr [[TMP13]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(31) %a, ptr noundef nonnull align 8 dereferenceable(31) %b, i32 31, i1 false)
  ret void
}

define void @test_src8_dst16_size_32(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dst16_size_32(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q0, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q1, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(32) %a, ptr noundef nonnull align 8 dereferenceable(32) %b, i32 32, i1 false)
  ret void
}

define void @test_src8_dst16_size_33(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dst16_size_33(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q0, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q1, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[B]], i64 32
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[A]], i64 32
; CHECK-NEXT:    [[TMP4:%.*]] = load i8, ptr [[TMP2]], align 1
; CHECK-NEXT:    store i8 [[TMP4]], ptr [[TMP3]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(33) %a, ptr noundef nonnull align 8 dereferenceable(33) %b, i32 33, i1 false)
  ret void
}

define void @test_src8_dst16_size_47(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dst16_size_47(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q0, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q1, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[B]], i64 32
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[A]], i64 32
; CHECK-NEXT:    [[TMP4:%.*]] = ptrtoint ptr [[TMP2]] to i32
; CHECK-NEXT:    [[TMP5:%.*]] = ptrtoint ptr [[TMP3]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP4]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP5]])
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[TMP2]], i32 8
; CHECK-NEXT:    [[TMP7:%.*]] = getelementptr i8, ptr [[TMP3]], i32 8
; CHECK-NEXT:    [[TMP8:%.*]] = load i32, ptr [[TMP6]], align 4
; CHECK-NEXT:    store i32 [[TMP8]], ptr [[TMP7]], align 4
; CHECK-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[TMP6]], i32 4
; CHECK-NEXT:    [[TMP10:%.*]] = getelementptr i8, ptr [[TMP7]], i32 4
; CHECK-NEXT:    [[TMP11:%.*]] = load i16, ptr [[TMP9]], align 2
; CHECK-NEXT:    store i16 [[TMP11]], ptr [[TMP10]], align 2
; CHECK-NEXT:    [[TMP12:%.*]] = getelementptr i8, ptr [[TMP9]], i32 2
; CHECK-NEXT:    [[TMP13:%.*]] = getelementptr i8, ptr [[TMP10]], i32 2
; CHECK-NEXT:    [[TMP14:%.*]] = load i8, ptr [[TMP12]], align 1
; CHECK-NEXT:    store i8 [[TMP14]], ptr [[TMP13]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(47) %a, ptr noundef nonnull align 8 dereferenceable(47) %b, i32 47, i1 false)
  ret void
}

define void @test_src8_dst16_size_48(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dst16_size_48(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q0, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q1, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q2, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(48) %a, ptr noundef nonnull align 8 dereferenceable(48) %b, i32 48, i1 false)
  ret void
}

define void @test_src8_dst16_size_49(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dst16_size_49(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q0, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q1, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q2, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[B]], i64 48
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[A]], i64 48
; CHECK-NEXT:    [[TMP4:%.*]] = load i8, ptr [[TMP2]], align 1
; CHECK-NEXT:    store i8 [[TMP4]], ptr [[TMP3]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(49) %a, ptr noundef nonnull align 8 dereferenceable(49) %b, i32 49, i1 false)
  ret void
}

define void @test_src8_dst16_size_63(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dst16_size_63(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q0, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q1, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q2, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[B]], i64 48
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[A]], i64 48
; CHECK-NEXT:    [[TMP4:%.*]] = ptrtoint ptr [[TMP2]] to i32
; CHECK-NEXT:    [[TMP5:%.*]] = ptrtoint ptr [[TMP3]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP4]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP5]])
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[TMP2]], i32 8
; CHECK-NEXT:    [[TMP7:%.*]] = getelementptr i8, ptr [[TMP3]], i32 8
; CHECK-NEXT:    [[TMP8:%.*]] = load i32, ptr [[TMP6]], align 4
; CHECK-NEXT:    store i32 [[TMP8]], ptr [[TMP7]], align 4
; CHECK-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[TMP6]], i32 4
; CHECK-NEXT:    [[TMP10:%.*]] = getelementptr i8, ptr [[TMP7]], i32 4
; CHECK-NEXT:    [[TMP11:%.*]] = load i16, ptr [[TMP9]], align 2
; CHECK-NEXT:    store i16 [[TMP11]], ptr [[TMP10]], align 2
; CHECK-NEXT:    [[TMP12:%.*]] = getelementptr i8, ptr [[TMP9]], i32 2
; CHECK-NEXT:    [[TMP13:%.*]] = getelementptr i8, ptr [[TMP10]], i32 2
; CHECK-NEXT:    [[TMP14:%.*]] = load i8, ptr [[TMP12]], align 1
; CHECK-NEXT:    store i8 [[TMP14]], ptr [[TMP13]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(63) %a, ptr noundef nonnull align 8 dereferenceable(63) %b, i32 63, i1 false)
  ret void
}

define void @test_src8_dst16_size_64(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dst16_size_64(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q0, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q1, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q2, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q3, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(64) %a, ptr noundef nonnull align 8 dereferenceable(64) %b, i32 64, i1 false)
  ret void
}

define void @test_src8_dst16_size_65(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dst16_size_65(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q0, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q1, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q2, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q3, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[B]], i64 64
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[A]], i64 64
; CHECK-NEXT:    [[TMP4:%.*]] = load i8, ptr [[TMP2]], align 1
; CHECK-NEXT:    store i8 [[TMP4]], ptr [[TMP3]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(65) %a, ptr noundef nonnull align 8 dereferenceable(65) %b, i32 65, i1 false)
  ret void
}

define void @test_src8_dst16_size_80(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dst16_size_80(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q0, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q1, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q2, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q3, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q4, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(80) %a, ptr noundef nonnull align 8 dereferenceable(80) %b, i32 80, i1 false)
  ret void
}

define void @test_src8_dst16_size_81(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dst16_size_81(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q0, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q1, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q2, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q3, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q4, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[B]], i64 80
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[A]], i64 80
; CHECK-NEXT:    [[TMP4:%.*]] = load i8, ptr [[TMP2]], align 1
; CHECK-NEXT:    store i8 [[TMP4]], ptr [[TMP3]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(81) %a, ptr noundef nonnull align 8 dereferenceable(81) %b, i32 81, i1 false)
  ret void
}

define void @test_src8_dst16_size_88(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dst16_size_88(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q0, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q1, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q2, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q3, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q4, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(88) %a, ptr noundef nonnull align 8 dereferenceable(88) %b, i32 88, i1 false)
  ret void
}

define void @test_src8_dst16_size_96(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dst16_size_96(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q0, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q1, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q2, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q3, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q4, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q5, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(96) %a, ptr noundef nonnull align 8 dereferenceable(96) %b, i32 96, i1 false)
  ret void
}

define void @test_src8_dst16_size_112(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dst16_size_112(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q6, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q6, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q0, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q1, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q2, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q3, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q4, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q5, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q6, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(112) %a, ptr noundef nonnull align 8 dereferenceable(112) %b, i32 112, i1 false)
  ret void
}

define void @test_src8_dst16_size_124(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dst16_size_124(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q6, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q6, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q0, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q1, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q2, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q3, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q4, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q5, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q6, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[B]], i64 112
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[A]], i64 112
; CHECK-NEXT:    [[TMP4:%.*]] = ptrtoint ptr [[TMP2]] to i32
; CHECK-NEXT:    [[TMP5:%.*]] = ptrtoint ptr [[TMP3]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP4]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP5]])
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[TMP2]], i32 8
; CHECK-NEXT:    [[TMP7:%.*]] = getelementptr i8, ptr [[TMP3]], i32 8
; CHECK-NEXT:    [[TMP8:%.*]] = load i32, ptr [[TMP6]], align 4
; CHECK-NEXT:    store i32 [[TMP8]], ptr [[TMP7]], align 4
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(124) %a, ptr noundef nonnull align 8 dereferenceable(124) %b, i32 124, i1 false)
  ret void
}

define void @test_src8_dst16_size_127(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dst16_size_127(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q6, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q6, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q0, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q1, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q2, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q3, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q4, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q5, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q6, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[B]], i64 112
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[A]], i64 112
; CHECK-NEXT:    [[TMP4:%.*]] = ptrtoint ptr [[TMP2]] to i32
; CHECK-NEXT:    [[TMP5:%.*]] = ptrtoint ptr [[TMP3]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP4]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP5]])
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[TMP2]], i32 8
; CHECK-NEXT:    [[TMP7:%.*]] = getelementptr i8, ptr [[TMP3]], i32 8
; CHECK-NEXT:    [[TMP8:%.*]] = load i32, ptr [[TMP6]], align 4
; CHECK-NEXT:    store i32 [[TMP8]], ptr [[TMP7]], align 4
; CHECK-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[TMP6]], i32 4
; CHECK-NEXT:    [[TMP10:%.*]] = getelementptr i8, ptr [[TMP7]], i32 4
; CHECK-NEXT:    [[TMP11:%.*]] = load i16, ptr [[TMP9]], align 2
; CHECK-NEXT:    store i16 [[TMP11]], ptr [[TMP10]], align 2
; CHECK-NEXT:    [[TMP12:%.*]] = getelementptr i8, ptr [[TMP9]], i32 2
; CHECK-NEXT:    [[TMP13:%.*]] = getelementptr i8, ptr [[TMP10]], i32 2
; CHECK-NEXT:    [[TMP14:%.*]] = load i8, ptr [[TMP12]], align 1
; CHECK-NEXT:    store i8 [[TMP14]], ptr [[TMP13]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(127) %a, ptr noundef nonnull align 8 dereferenceable(127) %b, i32 127, i1 false)
  ret void
}

define void @test_src8_dst16_size_128(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dst16_size_128(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q6, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q6, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q7, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q7, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q0, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q1, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q2, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q3, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q4, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q5, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q6, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q7, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(128) %a, ptr noundef nonnull align 8 dereferenceable(128) %b, i32 128, i1 false)
  ret void
}

define void @test_src8_dst16_size_129(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dst16_size_129(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q6, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q6, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q7, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q7, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q0, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q1, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q2, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q3, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q4, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q5, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q6, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q7, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[B]], i64 128
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[A]], i64 128
; CHECK-NEXT:    [[TMP4:%.*]] = load i8, ptr [[TMP2]], align 1
; CHECK-NEXT:    store i8 [[TMP4]], ptr [[TMP3]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(129) %a, ptr noundef nonnull align 8 dereferenceable(129) %b, i32 129, i1 false)
  ret void
}

define void @test_src8_dst16_size_255(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dst16_size_255(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q6, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q6, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q7, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q7, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q0, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q1, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q2, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q3, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q4, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q5, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q6, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q7, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q6, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q6, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q0, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q1, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q2, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q3, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q4, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q5, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q6, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[B]], i64 240
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[A]], i64 240
; CHECK-NEXT:    [[TMP4:%.*]] = ptrtoint ptr [[TMP2]] to i32
; CHECK-NEXT:    [[TMP5:%.*]] = ptrtoint ptr [[TMP3]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP4]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP5]])
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[TMP2]], i32 8
; CHECK-NEXT:    [[TMP7:%.*]] = getelementptr i8, ptr [[TMP3]], i32 8
; CHECK-NEXT:    [[TMP8:%.*]] = load i32, ptr [[TMP6]], align 4
; CHECK-NEXT:    store i32 [[TMP8]], ptr [[TMP7]], align 4
; CHECK-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[TMP6]], i32 4
; CHECK-NEXT:    [[TMP10:%.*]] = getelementptr i8, ptr [[TMP7]], i32 4
; CHECK-NEXT:    [[TMP11:%.*]] = load i16, ptr [[TMP9]], align 2
; CHECK-NEXT:    store i16 [[TMP11]], ptr [[TMP10]], align 2
; CHECK-NEXT:    [[TMP12:%.*]] = getelementptr i8, ptr [[TMP9]], i32 2
; CHECK-NEXT:    [[TMP13:%.*]] = getelementptr i8, ptr [[TMP10]], i32 2
; CHECK-NEXT:    [[TMP14:%.*]] = load i8, ptr [[TMP12]], align 1
; CHECK-NEXT:    store i8 [[TMP14]], ptr [[TMP13]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(255) %a, ptr noundef nonnull align 8 dereferenceable(255) %b, i32 255, i1 false)
  ret void
}

define void @test_src8_dst16_size_256(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dst16_size_256(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q6, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q6, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q7, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q7, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q0, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q1, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q2, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q3, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q4, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q5, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q6, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q7, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q6, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q6, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q7, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q7, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q0, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q1, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q2, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q3, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q4, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q5, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q6, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q7, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(256) %a, ptr noundef nonnull align 8 dereferenceable(256) %b, i32 256, i1 false)
  ret void
}

define void @test_src8_dst16_size_1023(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dst16_size_1023(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q6, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q6, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q7, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q7, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q0, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q1, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q2, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q3, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q4, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q5, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q6, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q7, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q6, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q6, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q7, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q7, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q0, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q1, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q2, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q3, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q4, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q5, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q6, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q7, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q6, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q6, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q7, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q7, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q0, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q1, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q2, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q3, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q4, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q5, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q6, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q7, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q6, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q6, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q7, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q7, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q0, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q1, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q2, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q3, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q4, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q5, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q6, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q7, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q6, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q6, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q7, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q7, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q0, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q1, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q2, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q3, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q4, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q5, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q6, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q7, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q6, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q6, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q7, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q7, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q0, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q1, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q2, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q3, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q4, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q5, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q6, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q7, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q6, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q6, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q7, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q7, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q0, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q1, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q2, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q3, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q4, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q5, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q6, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q7, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q6, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q6, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q0, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q1, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q2, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q3, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q4, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q5, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q6, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[B]], i64 1008
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[A]], i64 1008
; CHECK-NEXT:    [[TMP4:%.*]] = ptrtoint ptr [[TMP2]] to i32
; CHECK-NEXT:    [[TMP5:%.*]] = ptrtoint ptr [[TMP3]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP4]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP5]])
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[TMP2]], i32 8
; CHECK-NEXT:    [[TMP7:%.*]] = getelementptr i8, ptr [[TMP3]], i32 8
; CHECK-NEXT:    [[TMP8:%.*]] = load i32, ptr [[TMP6]], align 4
; CHECK-NEXT:    store i32 [[TMP8]], ptr [[TMP7]], align 4
; CHECK-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[TMP6]], i32 4
; CHECK-NEXT:    [[TMP10:%.*]] = getelementptr i8, ptr [[TMP7]], i32 4
; CHECK-NEXT:    [[TMP11:%.*]] = load i16, ptr [[TMP9]], align 2
; CHECK-NEXT:    store i16 [[TMP11]], ptr [[TMP10]], align 2
; CHECK-NEXT:    [[TMP12:%.*]] = getelementptr i8, ptr [[TMP9]], i32 2
; CHECK-NEXT:    [[TMP13:%.*]] = getelementptr i8, ptr [[TMP10]], i32 2
; CHECK-NEXT:    [[TMP14:%.*]] = load i8, ptr [[TMP12]], align 1
; CHECK-NEXT:    store i8 [[TMP14]], ptr [[TMP13]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(1023) %a, ptr noundef nonnull align 8 dereferenceable(1023) %b, i32 1023, i1 false)
  ret void
}

define void @test_src8_dst16_size_1024(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dst16_size_1024(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q6, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q6, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q7, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q7, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q0, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q1, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q2, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q3, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q4, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q5, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q6, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q7, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q6, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q6, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q7, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q7, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q0, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q1, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q2, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q3, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q4, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q5, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q6, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q7, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q6, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q6, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q7, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q7, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q0, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q1, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q2, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q3, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q4, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q5, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q6, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q7, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q6, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q6, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q7, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q7, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q0, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q1, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q2, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q3, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q4, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q5, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q6, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q7, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q6, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q6, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q7, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q7, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q0, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q1, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q2, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q3, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q4, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q5, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q6, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q7, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q6, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q6, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q7, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q7, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q0, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q1, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q2, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q3, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q4, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q5, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q6, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q7, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q6, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q6, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q7, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q7, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q0, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q1, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q2, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q3, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q4, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q5, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q6, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q7, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q6, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q6, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q7, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q7, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q0, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q1, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q2, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q3, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q4, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q5, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q6, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q7, $0, 16", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(1024) %a, ptr noundef nonnull align 8 dereferenceable(1024) %b, i32 1024, i1 false)
  ret void
}

define void @test_src8_dst16_size_20000(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dst16_size_20000(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    tail call void @esp32p4MemCpySrc8Dst16Const16(i32 [[TMP1]], i32 [[TMP0]], i32 20000)
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(20000) %a, ptr noundef nonnull align 8 dereferenceable(20000) %b, i32 20000, i1 false)
  ret void
}


; src8 dst8
define void @test_src8_dst8_size_1(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dst8_size_1(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = load i8, ptr [[B]], align 1
; CHECK-NEXT:    store i8 [[TMP0]], ptr [[A]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(1) %a, ptr noundef nonnull align 8 dereferenceable(1) %b, i32 1, i1 false)
  ret void
}

define void @test_src8_dst8_size_2(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dst8_size_2(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = load i16, ptr [[B]], align 2
; CHECK-NEXT:    store i16 [[TMP0]], ptr [[A]], align 2
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(2) %a, ptr noundef nonnull align 8 dereferenceable(2) %b, i32 2, i1 false)
  ret void
}

define void @test_src8_dst8_size_3(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dst8_size_3(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = load i16, ptr [[B]], align 2
; CHECK-NEXT:    store i16 [[TMP0]], ptr [[A]], align 2
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[B]], i32 2
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[A]], i32 2
; CHECK-NEXT:    [[TMP3:%.*]] = load i8, ptr [[TMP1]], align 1
; CHECK-NEXT:    store i8 [[TMP3]], ptr [[TMP2]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(3) %a, ptr noundef nonnull align 8 dereferenceable(3) %b, i32 3, i1 false)
  ret void
}

define void @test_src8_dst8_size_4(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dst8_size_4(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = load i32, ptr [[B]], align 4
; CHECK-NEXT:    store i32 [[TMP0]], ptr [[A]], align 4
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(4) %a, ptr noundef nonnull align 8 dereferenceable(4) %b, i32 4, i1 false)
  ret void
}

define void @test_src8_dst8_size_5(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dst8_size_5(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = load i32, ptr [[B]], align 4
; CHECK-NEXT:    store i32 [[TMP0]], ptr [[A]], align 4
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[B]], i32 4
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[A]], i32 4
; CHECK-NEXT:    [[TMP3:%.*]] = load i8, ptr [[TMP1]], align 1
; CHECK-NEXT:    store i8 [[TMP3]], ptr [[TMP2]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(5) %a, ptr noundef nonnull align 8 dereferenceable(5) %b, i32 5, i1 false)
  ret void
}

define void @test_src8_dst8_size_6(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dst8_size_6(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = load i32, ptr [[B]], align 4
; CHECK-NEXT:    store i32 [[TMP0]], ptr [[A]], align 4
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[B]], i32 4
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[A]], i32 4
; CHECK-NEXT:    [[TMP3:%.*]] = load i16, ptr [[TMP1]], align 2
; CHECK-NEXT:    store i16 [[TMP3]], ptr [[TMP2]], align 2
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(6) %a, ptr noundef nonnull align 8 dereferenceable(6) %b, i32 6, i1 false)
  ret void
}

define void @test_src8_dst8_size_7(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dst8_size_7(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = load i32, ptr [[B]], align 4
; CHECK-NEXT:    store i32 [[TMP0]], ptr [[A]], align 4
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[B]], i32 4
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[A]], i32 4
; CHECK-NEXT:    [[TMP3:%.*]] = load i16, ptr [[TMP1]], align 2
; CHECK-NEXT:    store i16 [[TMP3]], ptr [[TMP2]], align 2
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[TMP1]], i32 2
; CHECK-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[TMP2]], i32 2
; CHECK-NEXT:    [[TMP6:%.*]] = load i8, ptr [[TMP4]], align 1
; CHECK-NEXT:    store i8 [[TMP6]], ptr [[TMP5]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(7) %a, ptr noundef nonnull align 8 dereferenceable(7) %b, i32 7, i1 false)
  ret void
}

define void @test_src8_dst8_size_8(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dst8_size_8(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = getelementptr i8, ptr [[B]], i32 0
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[A]], i32 0
; CHECK-NEXT:    [[TMP2:%.*]] = load i32, ptr [[TMP0]], align 4
; CHECK-NEXT:    store i32 [[TMP2]], ptr [[TMP1]], align 4
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[B]], i32 4
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[A]], i32 4
; CHECK-NEXT:    [[TMP5:%.*]] = load i32, ptr [[TMP3]], align 4
; CHECK-NEXT:    store i32 [[TMP5]], ptr [[TMP4]], align 4
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(8) %a, ptr noundef nonnull align 8 dereferenceable(8) %b, i32 8, i1 false)
  ret void
}

define void @test_src8_dst8_size_9(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dst8_size_9(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[B]], i32 8
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[A]], i32 8
; CHECK-NEXT:    [[TMP4:%.*]] = load i8, ptr [[TMP2]], align 1
; CHECK-NEXT:    store i8 [[TMP4]], ptr [[TMP3]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(9) %a, ptr noundef nonnull align 8 dereferenceable(9) %b, i32 9, i1 false)
  ret void
}

define void @test_src8_dst8_size_10(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dst8_size_10(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[B]], i32 8
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[A]], i32 8
; CHECK-NEXT:    [[TMP4:%.*]] = load i16, ptr [[TMP2]], align 2
; CHECK-NEXT:    store i16 [[TMP4]], ptr [[TMP3]], align 2
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(10) %a, ptr noundef nonnull align 8 dereferenceable(10) %b, i32 10, i1 false)
  ret void
}

define void @test_src8_dst8_size_11(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dst8_size_11(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[B]], i32 8
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[A]], i32 8
; CHECK-NEXT:    [[TMP4:%.*]] = load i16, ptr [[TMP2]], align 2
; CHECK-NEXT:    store i16 [[TMP4]], ptr [[TMP3]], align 2
; CHECK-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[TMP2]], i32 2
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[TMP3]], i32 2
; CHECK-NEXT:    [[TMP7:%.*]] = load i8, ptr [[TMP5]], align 1
; CHECK-NEXT:    store i8 [[TMP7]], ptr [[TMP6]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(11) %a, ptr noundef nonnull align 8 dereferenceable(11) %b, i32 11, i1 false)
  ret void
}

define void @test_src8_dst8_size_12(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dst8_size_12(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[B]], i32 8
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[A]], i32 8
; CHECK-NEXT:    [[TMP4:%.*]] = load i32, ptr [[TMP2]], align 4
; CHECK-NEXT:    store i32 [[TMP4]], ptr [[TMP3]], align 4
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(12) %a, ptr noundef nonnull align 8 dereferenceable(12) %b, i32 12, i1 false)
  ret void
}

define void @test_src8_dst8_size_13(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dst8_size_13(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[B]], i32 8
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[A]], i32 8
; CHECK-NEXT:    [[TMP4:%.*]] = load i32, ptr [[TMP2]], align 4
; CHECK-NEXT:    store i32 [[TMP4]], ptr [[TMP3]], align 4
; CHECK-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[TMP2]], i32 4
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[TMP3]], i32 4
; CHECK-NEXT:    [[TMP7:%.*]] = load i8, ptr [[TMP5]], align 1
; CHECK-NEXT:    store i8 [[TMP7]], ptr [[TMP6]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(13) %a, ptr noundef nonnull align 8 dereferenceable(13) %b, i32 13, i1 false)
  ret void
}

define void @test_src8_dst8_size_14(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dst8_size_14(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[B]], i32 8
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[A]], i32 8
; CHECK-NEXT:    [[TMP4:%.*]] = load i32, ptr [[TMP2]], align 4
; CHECK-NEXT:    store i32 [[TMP4]], ptr [[TMP3]], align 4
; CHECK-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[TMP2]], i32 4
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[TMP3]], i32 4
; CHECK-NEXT:    [[TMP7:%.*]] = load i16, ptr [[TMP5]], align 2
; CHECK-NEXT:    store i16 [[TMP7]], ptr [[TMP6]], align 2
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(14) %a, ptr noundef nonnull align 8 dereferenceable(14) %b, i32 14, i1 false)
  ret void
}

define void @test_src8_dst8_size_15(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dst8_size_15(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[B]], i32 8
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[A]], i32 8
; CHECK-NEXT:    [[TMP4:%.*]] = load i32, ptr [[TMP2]], align 4
; CHECK-NEXT:    store i32 [[TMP4]], ptr [[TMP3]], align 4
; CHECK-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[TMP2]], i32 4
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[TMP3]], i32 4
; CHECK-NEXT:    [[TMP7:%.*]] = load i16, ptr [[TMP5]], align 2
; CHECK-NEXT:    store i16 [[TMP7]], ptr [[TMP6]], align 2
; CHECK-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[TMP5]], i32 2
; CHECK-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[TMP6]], i32 2
; CHECK-NEXT:    [[TMP10:%.*]] = load i8, ptr [[TMP8]], align 1
; CHECK-NEXT:    store i8 [[TMP10]], ptr [[TMP9]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(15) %a, ptr noundef nonnull align 8 dereferenceable(15) %b, i32 15, i1 false)
  ret void
}

define void @test_src8_dst8_size_16(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dst8_size_16(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(16) %a, ptr noundef nonnull align 8 dereferenceable(16) %b, i32 16, i1 false)
  ret void
}

define void @test_src8_dst8_size_17(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dst8_size_17(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[B]], i64 16
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[A]], i64 16
; CHECK-NEXT:    [[TMP4:%.*]] = load i8, ptr [[TMP2]], align 1
; CHECK-NEXT:    store i8 [[TMP4]], ptr [[TMP3]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(17) %a, ptr noundef nonnull align 8 dereferenceable(17) %b, i32 17, i1 false)
  ret void
}

define void @test_src8_dst8_size_31(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dst8_size_31(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[B]], i64 16
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[A]], i64 16
; CHECK-NEXT:    [[TMP4:%.*]] = ptrtoint ptr [[TMP2]] to i32
; CHECK-NEXT:    [[TMP5:%.*]] = ptrtoint ptr [[TMP3]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP4]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP5]])
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[TMP2]], i32 8
; CHECK-NEXT:    [[TMP7:%.*]] = getelementptr i8, ptr [[TMP3]], i32 8
; CHECK-NEXT:    [[TMP8:%.*]] = load i32, ptr [[TMP6]], align 4
; CHECK-NEXT:    store i32 [[TMP8]], ptr [[TMP7]], align 4
; CHECK-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[TMP6]], i32 4
; CHECK-NEXT:    [[TMP10:%.*]] = getelementptr i8, ptr [[TMP7]], i32 4
; CHECK-NEXT:    [[TMP11:%.*]] = load i16, ptr [[TMP9]], align 2
; CHECK-NEXT:    store i16 [[TMP11]], ptr [[TMP10]], align 2
; CHECK-NEXT:    [[TMP12:%.*]] = getelementptr i8, ptr [[TMP9]], i32 2
; CHECK-NEXT:    [[TMP13:%.*]] = getelementptr i8, ptr [[TMP10]], i32 2
; CHECK-NEXT:    [[TMP14:%.*]] = load i8, ptr [[TMP12]], align 1
; CHECK-NEXT:    store i8 [[TMP14]], ptr [[TMP13]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(31) %a, ptr noundef nonnull align 8 dereferenceable(31) %b, i32 31, i1 false)
  ret void
}

define void @test_src8_dst8_size_32(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dst8_size_32(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(32) %a, ptr noundef nonnull align 8 dereferenceable(32) %b, i32 32, i1 false)
  ret void
}

define void @test_src8_dst8_size_33(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dst8_size_33(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[B]], i64 32
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[A]], i64 32
; CHECK-NEXT:    [[TMP4:%.*]] = load i8, ptr [[TMP2]], align 1
; CHECK-NEXT:    store i8 [[TMP4]], ptr [[TMP3]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(33) %a, ptr noundef nonnull align 8 dereferenceable(33) %b, i32 33, i1 false)
  ret void
}

define void @test_src8_dst8_size_47(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dst8_size_47(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[B]], i64 32
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[A]], i64 32
; CHECK-NEXT:    [[TMP4:%.*]] = ptrtoint ptr [[TMP2]] to i32
; CHECK-NEXT:    [[TMP5:%.*]] = ptrtoint ptr [[TMP3]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP4]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP5]])
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[TMP2]], i32 8
; CHECK-NEXT:    [[TMP7:%.*]] = getelementptr i8, ptr [[TMP3]], i32 8
; CHECK-NEXT:    [[TMP8:%.*]] = load i32, ptr [[TMP6]], align 4
; CHECK-NEXT:    store i32 [[TMP8]], ptr [[TMP7]], align 4
; CHECK-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[TMP6]], i32 4
; CHECK-NEXT:    [[TMP10:%.*]] = getelementptr i8, ptr [[TMP7]], i32 4
; CHECK-NEXT:    [[TMP11:%.*]] = load i16, ptr [[TMP9]], align 2
; CHECK-NEXT:    store i16 [[TMP11]], ptr [[TMP10]], align 2
; CHECK-NEXT:    [[TMP12:%.*]] = getelementptr i8, ptr [[TMP9]], i32 2
; CHECK-NEXT:    [[TMP13:%.*]] = getelementptr i8, ptr [[TMP10]], i32 2
; CHECK-NEXT:    [[TMP14:%.*]] = load i8, ptr [[TMP12]], align 1
; CHECK-NEXT:    store i8 [[TMP14]], ptr [[TMP13]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(47) %a, ptr noundef nonnull align 8 dereferenceable(47) %b, i32 47, i1 false)
  ret void
}

define void @test_src8_dst8_size_48(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dst8_size_48(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(48) %a, ptr noundef nonnull align 8 dereferenceable(48) %b, i32 48, i1 false)
  ret void
}

define void @test_src8_dst8_size_49(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dst8_size_49(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[B]], i64 48
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[A]], i64 48
; CHECK-NEXT:    [[TMP4:%.*]] = load i8, ptr [[TMP2]], align 1
; CHECK-NEXT:    store i8 [[TMP4]], ptr [[TMP3]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(49) %a, ptr noundef nonnull align 8 dereferenceable(49) %b, i32 49, i1 false)
  ret void
}

define void @test_src8_dst8_size_63(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dst8_size_63(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[B]], i64 48
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[A]], i64 48
; CHECK-NEXT:    [[TMP4:%.*]] = ptrtoint ptr [[TMP2]] to i32
; CHECK-NEXT:    [[TMP5:%.*]] = ptrtoint ptr [[TMP3]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP4]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP5]])
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[TMP2]], i32 8
; CHECK-NEXT:    [[TMP7:%.*]] = getelementptr i8, ptr [[TMP3]], i32 8
; CHECK-NEXT:    [[TMP8:%.*]] = load i32, ptr [[TMP6]], align 4
; CHECK-NEXT:    store i32 [[TMP8]], ptr [[TMP7]], align 4
; CHECK-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[TMP6]], i32 4
; CHECK-NEXT:    [[TMP10:%.*]] = getelementptr i8, ptr [[TMP7]], i32 4
; CHECK-NEXT:    [[TMP11:%.*]] = load i16, ptr [[TMP9]], align 2
; CHECK-NEXT:    store i16 [[TMP11]], ptr [[TMP10]], align 2
; CHECK-NEXT:    [[TMP12:%.*]] = getelementptr i8, ptr [[TMP9]], i32 2
; CHECK-NEXT:    [[TMP13:%.*]] = getelementptr i8, ptr [[TMP10]], i32 2
; CHECK-NEXT:    [[TMP14:%.*]] = load i8, ptr [[TMP12]], align 1
; CHECK-NEXT:    store i8 [[TMP14]], ptr [[TMP13]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(63) %a, ptr noundef nonnull align 8 dereferenceable(63) %b, i32 63, i1 false)
  ret void
}

define void @test_src8_dst8_size_64(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dst8_size_64(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(64) %a, ptr noundef nonnull align 8 dereferenceable(64) %b, i32 64, i1 false)
  ret void
}

define void @test_src8_dst8_size_65(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dst8_size_65(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[B]], i64 64
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[A]], i64 64
; CHECK-NEXT:    [[TMP4:%.*]] = load i8, ptr [[TMP2]], align 1
; CHECK-NEXT:    store i8 [[TMP4]], ptr [[TMP3]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(65) %a, ptr noundef nonnull align 8 dereferenceable(65) %b, i32 65, i1 false)
  ret void
}

define void @test_src8_dst8_size_80(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dst8_size_80(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(80) %a, ptr noundef nonnull align 8 dereferenceable(80) %b, i32 80, i1 false)
  ret void
}

define void @test_src8_dst8_size_81(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dst8_size_81(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[B]], i64 80
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[A]], i64 80
; CHECK-NEXT:    [[TMP4:%.*]] = load i8, ptr [[TMP2]], align 1
; CHECK-NEXT:    store i8 [[TMP4]], ptr [[TMP3]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(81) %a, ptr noundef nonnull align 8 dereferenceable(81) %b, i32 81, i1 false)
  ret void
}

define void @test_src8_dst8_size_88(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dst8_size_88(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q6, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q7, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q6, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q7, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(88) %a, ptr noundef nonnull align 8 dereferenceable(88) %b, i32 88, i1 false)
  ret void
}

define void @test_src8_dst8_size_96(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dst8_size_96(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(96) %a, ptr noundef nonnull align 8 dereferenceable(96) %b, i32 96, i1 false)
  ret void
}

define void @test_src8_dst8_size_112(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dst8_size_112(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q6, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q6, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q6, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q6, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(112) %a, ptr noundef nonnull align 8 dereferenceable(112) %b, i32 112, i1 false)
  ret void
}

define void @test_src8_dst8_size_124(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dst8_size_124(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q6, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q6, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q6, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q6, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[B]], i64 112
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[A]], i64 112
; CHECK-NEXT:    [[TMP4:%.*]] = ptrtoint ptr [[TMP2]] to i32
; CHECK-NEXT:    [[TMP5:%.*]] = ptrtoint ptr [[TMP3]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP4]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP5]])
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[TMP2]], i32 8
; CHECK-NEXT:    [[TMP7:%.*]] = getelementptr i8, ptr [[TMP3]], i32 8
; CHECK-NEXT:    [[TMP8:%.*]] = load i32, ptr [[TMP6]], align 4
; CHECK-NEXT:    store i32 [[TMP8]], ptr [[TMP7]], align 4
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(124) %a, ptr noundef nonnull align 8 dereferenceable(124) %b, i32 124, i1 false)
  ret void
}

define void @test_src8_dst8_size_127(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dst8_size_127(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q6, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q6, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q6, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q6, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[B]], i64 112
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[A]], i64 112
; CHECK-NEXT:    [[TMP4:%.*]] = ptrtoint ptr [[TMP2]] to i32
; CHECK-NEXT:    [[TMP5:%.*]] = ptrtoint ptr [[TMP3]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP4]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP5]])
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[TMP2]], i32 8
; CHECK-NEXT:    [[TMP7:%.*]] = getelementptr i8, ptr [[TMP3]], i32 8
; CHECK-NEXT:    [[TMP8:%.*]] = load i32, ptr [[TMP6]], align 4
; CHECK-NEXT:    store i32 [[TMP8]], ptr [[TMP7]], align 4
; CHECK-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[TMP6]], i32 4
; CHECK-NEXT:    [[TMP10:%.*]] = getelementptr i8, ptr [[TMP7]], i32 4
; CHECK-NEXT:    [[TMP11:%.*]] = load i16, ptr [[TMP9]], align 2
; CHECK-NEXT:    store i16 [[TMP11]], ptr [[TMP10]], align 2
; CHECK-NEXT:    [[TMP12:%.*]] = getelementptr i8, ptr [[TMP9]], i32 2
; CHECK-NEXT:    [[TMP13:%.*]] = getelementptr i8, ptr [[TMP10]], i32 2
; CHECK-NEXT:    [[TMP14:%.*]] = load i8, ptr [[TMP12]], align 1
; CHECK-NEXT:    store i8 [[TMP14]], ptr [[TMP13]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(127) %a, ptr noundef nonnull align 8 dereferenceable(127) %b, i32 127, i1 false)
  ret void
}

define void @test_src8_dst8_size_128(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dst8_size_128(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q6, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q6, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q7, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q7, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q6, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q6, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q7, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q7, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(128) %a, ptr noundef nonnull align 8 dereferenceable(128) %b, i32 128, i1 false)
  ret void
}

define void @test_src8_dst8_size_129(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dst8_size_129(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q6, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q6, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q7, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q7, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q6, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q6, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q7, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q7, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[B]], i64 128
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[A]], i64 128
; CHECK-NEXT:    [[TMP4:%.*]] = load i8, ptr [[TMP2]], align 1
; CHECK-NEXT:    store i8 [[TMP4]], ptr [[TMP3]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(129) %a, ptr noundef nonnull align 8 dereferenceable(129) %b, i32 129, i1 false)
  ret void
}

define void @test_src8_dst8_size_255(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dst8_size_255(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q6, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q6, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q7, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q7, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q6, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q6, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q7, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q7, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q6, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q6, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q6, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q6, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[B]], i64 240
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[A]], i64 240
; CHECK-NEXT:    [[TMP4:%.*]] = ptrtoint ptr [[TMP2]] to i32
; CHECK-NEXT:    [[TMP5:%.*]] = ptrtoint ptr [[TMP3]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP4]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP5]])
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[TMP2]], i32 8
; CHECK-NEXT:    [[TMP7:%.*]] = getelementptr i8, ptr [[TMP3]], i32 8
; CHECK-NEXT:    [[TMP8:%.*]] = load i32, ptr [[TMP6]], align 4
; CHECK-NEXT:    store i32 [[TMP8]], ptr [[TMP7]], align 4
; CHECK-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[TMP6]], i32 4
; CHECK-NEXT:    [[TMP10:%.*]] = getelementptr i8, ptr [[TMP7]], i32 4
; CHECK-NEXT:    [[TMP11:%.*]] = load i16, ptr [[TMP9]], align 2
; CHECK-NEXT:    store i16 [[TMP11]], ptr [[TMP10]], align 2
; CHECK-NEXT:    [[TMP12:%.*]] = getelementptr i8, ptr [[TMP9]], i32 2
; CHECK-NEXT:    [[TMP13:%.*]] = getelementptr i8, ptr [[TMP10]], i32 2
; CHECK-NEXT:    [[TMP14:%.*]] = load i8, ptr [[TMP12]], align 1
; CHECK-NEXT:    store i8 [[TMP14]], ptr [[TMP13]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(255) %a, ptr noundef nonnull align 8 dereferenceable(255) %b, i32 255, i1 false)
  ret void
}

define void @test_src8_dst8_size_256(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dst8_size_256(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q6, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q6, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q7, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q7, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q6, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q6, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q7, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q7, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q6, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q6, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q7, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q7, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q6, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q6, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q7, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q7, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(256) %a, ptr noundef nonnull align 8 dereferenceable(256) %b, i32 256, i1 false)
  ret void
}

define void @test_src8_dst8_size_1023(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dst8_size_1023(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q6, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q6, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q7, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q7, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q6, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q6, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q7, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q7, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q6, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q6, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q7, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q7, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q6, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q6, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q7, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q7, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q6, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q6, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q7, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q7, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q6, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q6, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q7, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q7, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q6, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q6, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q7, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q7, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q6, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q6, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q7, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q7, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q6, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q6, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q7, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q7, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q6, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q6, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q7, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q7, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q6, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q6, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q7, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q7, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q6, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q6, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q7, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q7, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q6, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q6, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q7, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q7, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q6, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q6, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q7, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q7, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q6, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q6, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q6, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q6, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[B]], i64 1008
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[A]], i64 1008
; CHECK-NEXT:    [[TMP4:%.*]] = ptrtoint ptr [[TMP2]] to i32
; CHECK-NEXT:    [[TMP5:%.*]] = ptrtoint ptr [[TMP3]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP4]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP5]])
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[TMP2]], i32 8
; CHECK-NEXT:    [[TMP7:%.*]] = getelementptr i8, ptr [[TMP3]], i32 8
; CHECK-NEXT:    [[TMP8:%.*]] = load i32, ptr [[TMP6]], align 4
; CHECK-NEXT:    store i32 [[TMP8]], ptr [[TMP7]], align 4
; CHECK-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[TMP6]], i32 4
; CHECK-NEXT:    [[TMP10:%.*]] = getelementptr i8, ptr [[TMP7]], i32 4
; CHECK-NEXT:    [[TMP11:%.*]] = load i16, ptr [[TMP9]], align 2
; CHECK-NEXT:    store i16 [[TMP11]], ptr [[TMP10]], align 2
; CHECK-NEXT:    [[TMP12:%.*]] = getelementptr i8, ptr [[TMP9]], i32 2
; CHECK-NEXT:    [[TMP13:%.*]] = getelementptr i8, ptr [[TMP10]], i32 2
; CHECK-NEXT:    [[TMP14:%.*]] = load i8, ptr [[TMP12]], align 1
; CHECK-NEXT:    store i8 [[TMP14]], ptr [[TMP13]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(1023) %a, ptr noundef nonnull align 8 dereferenceable(1023) %b, i32 1023, i1 false)
  ret void
}

define void @test_src8_dst8_size_1024(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dst8_size_1024(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q6, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q6, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q7, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q7, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q6, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q6, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q7, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q7, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q6, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q6, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q7, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q7, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q6, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q6, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q7, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q7, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q6, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q6, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q7, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q7, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q6, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q6, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q7, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q7, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q6, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q6, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q7, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q7, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q6, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q6, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q7, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q7, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q6, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q6, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q7, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q7, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q6, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q6, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q7, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q7, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q6, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q6, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q7, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q7, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q6, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q6, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q7, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q7, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q6, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q6, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q7, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q7, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q6, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q6, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q7, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q7, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q0, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q1, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q2, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q3, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q4, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q5, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q6, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q6, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.l.64.ip q7, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vld.h.64.ip q7, $0, 8", "+{a1}"(i32 [[TMP0]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q0, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q1, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q2, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q3, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q4, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q5, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q6, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q6, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.l.64.ip q7, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.h.64.ip q7, $0, 8", "+{a0}"(i32 [[TMP1]])
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(1024) %a, ptr noundef nonnull align 8 dereferenceable(1024) %b, i32 1024, i1 false)
  ret void
}

define void @test_src8_dst8_size_20000(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dst8_size_20000(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    tail call void @esp32p4MemCpySrc8Dst8Const16(i32 [[TMP1]], i32 [[TMP0]], i32 20000)
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(20000) %a, ptr noundef nonnull align 8 dereferenceable(20000) %b, i32 20000, i1 false)
  ret void
}


; src16 dstunalign
define void @test_src16_dstunalign_constant_size_1(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dstunalign_constant_size_1(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = getelementptr i8, ptr [[B]], i32 0
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[A]], i32 0
; CHECK-NEXT:    [[TMP2:%.*]] = load i8, ptr [[TMP0]], align 1
; CHECK-NEXT:    store i8 [[TMP2]], ptr [[TMP1]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(1) %a, ptr noundef nonnull align 16 dereferenceable(1) %b, i32 1, i1 false)
  ret void
}

define void @test_src16_dstunalign_constant_size_2(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dstunalign_constant_size_2(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = getelementptr i8, ptr [[B]], i32 0
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[A]], i32 0
; CHECK-NEXT:    [[TMP2:%.*]] = load i16, ptr [[TMP0]], align 2
; CHECK-NEXT:    store i16 [[TMP2]], ptr [[TMP1]], align 2
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(2) %a, ptr noundef nonnull align 16 dereferenceable(2) %b, i32 2, i1 false)
  ret void
}

define void @test_src16_dstunalign_constant_size_3(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dstunalign_constant_size_3(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = getelementptr i8, ptr [[B]], i32 0
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[A]], i32 0
; CHECK-NEXT:    [[TMP2:%.*]] = load i16, ptr [[TMP0]], align 2
; CHECK-NEXT:    store i16 [[TMP2]], ptr [[TMP1]], align 2
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[B]], i32 2
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[A]], i32 2
; CHECK-NEXT:    [[TMP5:%.*]] = load i8, ptr [[TMP3]], align 1
; CHECK-NEXT:    store i8 [[TMP5]], ptr [[TMP4]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(3) %a, ptr noundef nonnull align 16 dereferenceable(3) %b, i32 3, i1 false)
  ret void
}

define void @test_src16_dstunalign_constant_size_4(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dstunalign_constant_size_4(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = getelementptr i8, ptr [[B]], i32 0
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[A]], i32 0
; CHECK-NEXT:    [[TMP2:%.*]] = load i32, ptr [[TMP0]], align 4
; CHECK-NEXT:    store i32 [[TMP2]], ptr [[TMP1]], align 4
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(4) %a, ptr noundef nonnull align 16 dereferenceable(4) %b, i32 4, i1 false)
  ret void
}

define void @test_src16_dstunalign_constant_size_5(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dstunalign_constant_size_5(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = getelementptr i8, ptr [[B]], i32 0
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[A]], i32 0
; CHECK-NEXT:    [[TMP2:%.*]] = load i32, ptr [[TMP0]], align 4
; CHECK-NEXT:    store i32 [[TMP2]], ptr [[TMP1]], align 4
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[B]], i32 4
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[A]], i32 4
; CHECK-NEXT:    [[TMP5:%.*]] = load i8, ptr [[TMP3]], align 1
; CHECK-NEXT:    store i8 [[TMP5]], ptr [[TMP4]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(5) %a, ptr noundef nonnull align 16 dereferenceable(5) %b, i32 5, i1 false)
  ret void
}

define void @test_src16_dstunalign_constant_size_6(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dstunalign_constant_size_6(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = getelementptr i8, ptr [[B]], i32 0
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[A]], i32 0
; CHECK-NEXT:    [[TMP2:%.*]] = load i32, ptr [[TMP0]], align 4
; CHECK-NEXT:    store i32 [[TMP2]], ptr [[TMP1]], align 4
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[B]], i32 4
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[A]], i32 4
; CHECK-NEXT:    [[TMP5:%.*]] = load i16, ptr [[TMP3]], align 2
; CHECK-NEXT:    store i16 [[TMP5]], ptr [[TMP4]], align 2
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(6) %a, ptr noundef nonnull align 16 dereferenceable(6) %b, i32 6, i1 false)
  ret void
}

define void @test_src16_dstunalign_constant_size_7(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dstunalign_constant_size_7(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = getelementptr i8, ptr [[B]], i32 0
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[A]], i32 0
; CHECK-NEXT:    [[TMP2:%.*]] = load i32, ptr [[TMP0]], align 4
; CHECK-NEXT:    store i32 [[TMP2]], ptr [[TMP1]], align 4
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[B]], i32 4
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[A]], i32 4
; CHECK-NEXT:    [[TMP5:%.*]] = load i16, ptr [[TMP3]], align 2
; CHECK-NEXT:    store i16 [[TMP5]], ptr [[TMP4]], align 2
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[B]], i32 6
; CHECK-NEXT:    [[TMP7:%.*]] = getelementptr i8, ptr [[A]], i32 6
; CHECK-NEXT:    [[TMP8:%.*]] = load i8, ptr [[TMP6]], align 1
; CHECK-NEXT:    store i8 [[TMP8]], ptr [[TMP7]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(7) %a, ptr noundef nonnull align 16 dereferenceable(7) %b, i32 7, i1 false)
  ret void
}

define void @test_src16_dstunalign_constant_size_8(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dstunalign_constant_size_8(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = getelementptr i8, ptr [[B]], i32 0
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[A]], i32 0
; CHECK-NEXT:    [[TMP2:%.*]] = load i32, ptr [[TMP0]], align 4
; CHECK-NEXT:    store i32 [[TMP2]], ptr [[TMP1]], align 4
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[B]], i32 4
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[A]], i32 4
; CHECK-NEXT:    [[TMP5:%.*]] = load i32, ptr [[TMP3]], align 4
; CHECK-NEXT:    store i32 [[TMP5]], ptr [[TMP4]], align 4
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(8) %a, ptr noundef nonnull align 16 dereferenceable(8) %b, i32 8, i1 false)
  ret void
}

define void @test_src16_dstunalign_constant_size_9(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dstunalign_constant_size_9(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = getelementptr i8, ptr [[B]], i32 0
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[A]], i32 0
; CHECK-NEXT:    [[TMP2:%.*]] = load i32, ptr [[TMP0]], align 4
; CHECK-NEXT:    store i32 [[TMP2]], ptr [[TMP1]], align 4
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[B]], i32 4
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[A]], i32 4
; CHECK-NEXT:    [[TMP5:%.*]] = load i32, ptr [[TMP3]], align 4
; CHECK-NEXT:    store i32 [[TMP5]], ptr [[TMP4]], align 4
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[B]], i32 8
; CHECK-NEXT:    [[TMP7:%.*]] = getelementptr i8, ptr [[A]], i32 8
; CHECK-NEXT:    [[TMP8:%.*]] = load i8, ptr [[TMP6]], align 1
; CHECK-NEXT:    store i8 [[TMP8]], ptr [[TMP7]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(9) %a, ptr noundef nonnull align 16 dereferenceable(9) %b, i32 9, i1 false)
  ret void
}

define void @test_src16_dstunalign_constant_size_10(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dstunalign_constant_size_10(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = getelementptr i8, ptr [[B]], i32 0
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[A]], i32 0
; CHECK-NEXT:    [[TMP2:%.*]] = load i32, ptr [[TMP0]], align 4
; CHECK-NEXT:    store i32 [[TMP2]], ptr [[TMP1]], align 4
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[B]], i32 4
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[A]], i32 4
; CHECK-NEXT:    [[TMP5:%.*]] = load i32, ptr [[TMP3]], align 4
; CHECK-NEXT:    store i32 [[TMP5]], ptr [[TMP4]], align 4
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[B]], i32 8
; CHECK-NEXT:    [[TMP7:%.*]] = getelementptr i8, ptr [[A]], i32 8
; CHECK-NEXT:    [[TMP8:%.*]] = load i16, ptr [[TMP6]], align 2
; CHECK-NEXT:    store i16 [[TMP8]], ptr [[TMP7]], align 2
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(10) %a, ptr noundef nonnull align 16 dereferenceable(10) %b, i32 10, i1 false)
  ret void
}

define void @test_src16_dstunalign_constant_size_11(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dstunalign_constant_size_11(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = getelementptr i8, ptr [[B]], i32 0
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[A]], i32 0
; CHECK-NEXT:    [[TMP2:%.*]] = load i32, ptr [[TMP0]], align 4
; CHECK-NEXT:    store i32 [[TMP2]], ptr [[TMP1]], align 4
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[B]], i32 4
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[A]], i32 4
; CHECK-NEXT:    [[TMP5:%.*]] = load i32, ptr [[TMP3]], align 4
; CHECK-NEXT:    store i32 [[TMP5]], ptr [[TMP4]], align 4
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[B]], i32 8
; CHECK-NEXT:    [[TMP7:%.*]] = getelementptr i8, ptr [[A]], i32 8
; CHECK-NEXT:    [[TMP8:%.*]] = load i16, ptr [[TMP6]], align 2
; CHECK-NEXT:    store i16 [[TMP8]], ptr [[TMP7]], align 2
; CHECK-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[B]], i32 10
; CHECK-NEXT:    [[TMP10:%.*]] = getelementptr i8, ptr [[A]], i32 10
; CHECK-NEXT:    [[TMP11:%.*]] = load i8, ptr [[TMP9]], align 1
; CHECK-NEXT:    store i8 [[TMP11]], ptr [[TMP10]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(11) %a, ptr noundef nonnull align 16 dereferenceable(11) %b, i32 11, i1 false)
  ret void
}

define void @test_src16_dstunalign_constant_size_12(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dstunalign_constant_size_12(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = getelementptr i8, ptr [[B]], i32 0
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[A]], i32 0
; CHECK-NEXT:    [[TMP2:%.*]] = load i32, ptr [[TMP0]], align 4
; CHECK-NEXT:    store i32 [[TMP2]], ptr [[TMP1]], align 4
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[B]], i32 4
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[A]], i32 4
; CHECK-NEXT:    [[TMP5:%.*]] = load i32, ptr [[TMP3]], align 4
; CHECK-NEXT:    store i32 [[TMP5]], ptr [[TMP4]], align 4
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[B]], i32 8
; CHECK-NEXT:    [[TMP7:%.*]] = getelementptr i8, ptr [[A]], i32 8
; CHECK-NEXT:    [[TMP8:%.*]] = load i32, ptr [[TMP6]], align 4
; CHECK-NEXT:    store i32 [[TMP8]], ptr [[TMP7]], align 4
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(12) %a, ptr noundef nonnull align 16 dereferenceable(12) %b, i32 12, i1 false)
  ret void
}

define void @test_src16_dstunalign_constant_size_13(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dstunalign_constant_size_13(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = getelementptr i8, ptr [[B]], i32 0
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[A]], i32 0
; CHECK-NEXT:    [[TMP2:%.*]] = load i32, ptr [[TMP0]], align 4
; CHECK-NEXT:    store i32 [[TMP2]], ptr [[TMP1]], align 4
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[B]], i32 4
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[A]], i32 4
; CHECK-NEXT:    [[TMP5:%.*]] = load i32, ptr [[TMP3]], align 4
; CHECK-NEXT:    store i32 [[TMP5]], ptr [[TMP4]], align 4
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[B]], i32 8
; CHECK-NEXT:    [[TMP7:%.*]] = getelementptr i8, ptr [[A]], i32 8
; CHECK-NEXT:    [[TMP8:%.*]] = load i32, ptr [[TMP6]], align 4
; CHECK-NEXT:    store i32 [[TMP8]], ptr [[TMP7]], align 4
; CHECK-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[B]], i32 12
; CHECK-NEXT:    [[TMP10:%.*]] = getelementptr i8, ptr [[A]], i32 12
; CHECK-NEXT:    [[TMP11:%.*]] = load i8, ptr [[TMP9]], align 1
; CHECK-NEXT:    store i8 [[TMP11]], ptr [[TMP10]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(13) %a, ptr noundef nonnull align 16 dereferenceable(13) %b, i32 13, i1 false)
  ret void
}

define void @test_src16_dstunalign_constant_size_14(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dstunalign_constant_size_14(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = getelementptr i8, ptr [[B]], i32 0
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[A]], i32 0
; CHECK-NEXT:    [[TMP2:%.*]] = load i32, ptr [[TMP0]], align 4
; CHECK-NEXT:    store i32 [[TMP2]], ptr [[TMP1]], align 4
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[B]], i32 4
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[A]], i32 4
; CHECK-NEXT:    [[TMP5:%.*]] = load i32, ptr [[TMP3]], align 4
; CHECK-NEXT:    store i32 [[TMP5]], ptr [[TMP4]], align 4
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[B]], i32 8
; CHECK-NEXT:    [[TMP7:%.*]] = getelementptr i8, ptr [[A]], i32 8
; CHECK-NEXT:    [[TMP8:%.*]] = load i32, ptr [[TMP6]], align 4
; CHECK-NEXT:    store i32 [[TMP8]], ptr [[TMP7]], align 4
; CHECK-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[B]], i32 12
; CHECK-NEXT:    [[TMP10:%.*]] = getelementptr i8, ptr [[A]], i32 12
; CHECK-NEXT:    [[TMP11:%.*]] = load i16, ptr [[TMP9]], align 2
; CHECK-NEXT:    store i16 [[TMP11]], ptr [[TMP10]], align 2
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(14) %a, ptr noundef nonnull align 16 dereferenceable(14) %b, i32 14, i1 false)
  ret void
}

define void @test_src16_dstunalign_constant_size_15(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dstunalign_constant_size_15(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = getelementptr i8, ptr [[B]], i32 0
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[A]], i32 0
; CHECK-NEXT:    [[TMP2:%.*]] = load i32, ptr [[TMP0]], align 4
; CHECK-NEXT:    store i32 [[TMP2]], ptr [[TMP1]], align 4
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[B]], i32 4
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[A]], i32 4
; CHECK-NEXT:    [[TMP5:%.*]] = load i32, ptr [[TMP3]], align 4
; CHECK-NEXT:    store i32 [[TMP5]], ptr [[TMP4]], align 4
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[B]], i32 8
; CHECK-NEXT:    [[TMP7:%.*]] = getelementptr i8, ptr [[A]], i32 8
; CHECK-NEXT:    [[TMP8:%.*]] = load i32, ptr [[TMP6]], align 4
; CHECK-NEXT:    store i32 [[TMP8]], ptr [[TMP7]], align 4
; CHECK-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[B]], i32 12
; CHECK-NEXT:    [[TMP10:%.*]] = getelementptr i8, ptr [[A]], i32 12
; CHECK-NEXT:    [[TMP11:%.*]] = load i16, ptr [[TMP9]], align 2
; CHECK-NEXT:    store i16 [[TMP11]], ptr [[TMP10]], align 2
; CHECK-NEXT:    [[TMP12:%.*]] = getelementptr i8, ptr [[B]], i32 14
; CHECK-NEXT:    [[TMP13:%.*]] = getelementptr i8, ptr [[A]], i32 14
; CHECK-NEXT:    [[TMP14:%.*]] = load i8, ptr [[TMP12]], align 1
; CHECK-NEXT:    store i8 [[TMP14]], ptr [[TMP13]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(15) %a, ptr noundef nonnull align 16 dereferenceable(15) %b, i32 15, i1 false)
  ret void
}

define void @test_src16_dstunalign_constant_size_16(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dstunalign_constant_size_16(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    call void @esp32p4MemCpySrc16DstunalignedVar(ptr [[A]], ptr [[B]], i32 16, i32 1)
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(16) %a, ptr noundef nonnull align 16 dereferenceable(16) %b, i32 16, i1 false)
  ret void
}

define void @test_src16_dstunalign_constant_size_17(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dstunalign_constant_size_17(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    call void @esp32p4MemCpySrc16DstunalignedVar(ptr [[A]], ptr [[B]], i32 17, i32 1)
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(17) %a, ptr noundef nonnull align 16 dereferenceable(17) %b, i32 17, i1 false)
  ret void
}

define void @test_src16_dstunalign_constant_size_31(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dstunalign_constant_size_31(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    call void @esp32p4MemCpySrc16DstunalignedVar(ptr [[A]], ptr [[B]], i32 31, i32 1)
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(31) %a, ptr noundef nonnull align 16 dereferenceable(31) %b, i32 31, i1 false)
  ret void
}

define void @test_src16_dstunalign_constant_size_32(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dstunalign_constant_size_32(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    call void @esp32p4MemCpySrc16DstunalignedVar(ptr [[A]], ptr [[B]], i32 32, i32 1)
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(32) %a, ptr noundef nonnull align 16 dereferenceable(32) %b, i32 32, i1 false)
  ret void
}

define void @test_src16_dstunalign_constant_size_33(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dstunalign_constant_size_33(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    call void @esp32p4MemCpySrc16DstunalignedVar(ptr [[A]], ptr [[B]], i32 33, i32 1)
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(33) %a, ptr noundef nonnull align 16 dereferenceable(33) %b, i32 33, i1 false)
  ret void
}

define void @test_src16_dstunalign_constant_size_47(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dstunalign_constant_size_47(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    call void @esp32p4MemCpySrc16DstunalignedVar(ptr [[A]], ptr [[B]], i32 47, i32 1)
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(47) %a, ptr noundef nonnull align 16 dereferenceable(47) %b, i32 47, i1 false)
  ret void
}

define void @test_src16_dstunalign_constant_size_48(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dstunalign_constant_size_48(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    call void @esp32p4MemCpySrc16DstunalignedVar(ptr [[A]], ptr [[B]], i32 48, i32 1)
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(48) %a, ptr noundef nonnull align 16 dereferenceable(48) %b, i32 48, i1 false)
  ret void
}

define void @test_src16_dstunalign_constant_size_49(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dstunalign_constant_size_49(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    call void @esp32p4MemCpySrc16DstunalignedVar(ptr [[A]], ptr [[B]], i32 49, i32 1)
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(49) %a, ptr noundef nonnull align 16 dereferenceable(49) %b, i32 49, i1 false)
  ret void
}

define void @test_src16_dstunalign_constant_size_63(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dstunalign_constant_size_63(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    call void @esp32p4MemCpySrc16DstunalignedVar(ptr [[A]], ptr [[B]], i32 63, i32 1)
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(63) %a, ptr noundef nonnull align 16 dereferenceable(63) %b, i32 63, i1 false)
  ret void
}

define void @test_src16_dstunalign_constant_size_64(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dstunalign_constant_size_64(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    call void @esp32p4MemCpySrc16DstunalignedVar(ptr [[A]], ptr [[B]], i32 64, i32 1)
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(64) %a, ptr noundef nonnull align 16 dereferenceable(64) %b, i32 64, i1 false)
  ret void
}

define void @test_src16_dstunalign_constant_size_65(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dstunalign_constant_size_65(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    call void @esp32p4MemCpySrc16DstunalignedVar(ptr [[A]], ptr [[B]], i32 65, i32 1)
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(65) %a, ptr noundef nonnull align 16 dereferenceable(65) %b, i32 65, i1 false)
  ret void
}

define void @test_src16_dstunalign_constant_size_80(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dstunalign_constant_size_80(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    call void @esp32p4MemCpySrc16DstunalignedVar(ptr [[A]], ptr [[B]], i32 80, i32 1)
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(80) %a, ptr noundef nonnull align 16 dereferenceable(80) %b, i32 80, i1 false)
  ret void
}

define void @test_src16_dstunalign_constant_size_81(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dstunalign_constant_size_81(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    call void @esp32p4MemCpySrc16DstunalignedVar(ptr [[A]], ptr [[B]], i32 81, i32 1)
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(81) %a, ptr noundef nonnull align 16 dereferenceable(81) %b, i32 81, i1 false)
  ret void
}

define void @test_src16_dstunalign_constant_size_88(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dstunalign_constant_size_88(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    call void @esp32p4MemCpySrc16DstunalignedVar(ptr [[A]], ptr [[B]], i32 88, i32 1)
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(88) %a, ptr noundef nonnull align 16 dereferenceable(88) %b, i32 88, i1 false)
  ret void
}

define void @test_src16_dstunalign_constant_size_96(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dstunalign_constant_size_96(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    call void @esp32p4MemCpySrc16DstunalignedVar(ptr [[A]], ptr [[B]], i32 96, i32 1)
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(96) %a, ptr noundef nonnull align 16 dereferenceable(96) %b, i32 96, i1 false)
  ret void
}

define void @test_src16_dstunalign_constant_size_112(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dstunalign_constant_size_112(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    call void @esp32p4MemCpySrc16DstunalignedVar(ptr [[A]], ptr [[B]], i32 112, i32 1)
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(112) %a, ptr noundef nonnull align 16 dereferenceable(112) %b, i32 112, i1 false)
  ret void
}

define void @test_src16_dstunalign_constant_size_124(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dstunalign_constant_size_124(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    call void @esp32p4MemCpySrc16DstunalignedVar(ptr [[A]], ptr [[B]], i32 124, i32 1)
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(124) %a, ptr noundef nonnull align 16 dereferenceable(124) %b, i32 124, i1 false)
  ret void
}

define void @test_src16_dstunalign_constant_size_127(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dstunalign_constant_size_127(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    call void @esp32p4MemCpySrc16DstunalignedVar(ptr [[A]], ptr [[B]], i32 127, i32 1)
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(127) %a, ptr noundef nonnull align 16 dereferenceable(127) %b, i32 127, i1 false)
  ret void
}

define void @test_src16_dstunalign_constant_size_128(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dstunalign_constant_size_128(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    call void @esp32p4MemCpySrc16DstunalignedVar(ptr [[A]], ptr [[B]], i32 128, i32 1)
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(128) %a, ptr noundef nonnull align 16 dereferenceable(128) %b, i32 128, i1 false)
  ret void
}

define void @test_src16_dstunalign_constant_size_129(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dstunalign_constant_size_129(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    call void @esp32p4MemCpySrc16DstunalignedVar(ptr [[A]], ptr [[B]], i32 129, i32 1)
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(129) %a, ptr noundef nonnull align 16 dereferenceable(129) %b, i32 129, i1 false)
  ret void
}

define void @test_src16_dstunalign_constant_size_255(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dstunalign_constant_size_255(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    call void @esp32p4MemCpySrc16DstunalignedVar(ptr [[A]], ptr [[B]], i32 255, i32 1)
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(255) %a, ptr noundef nonnull align 16 dereferenceable(255) %b, i32 255, i1 false)
  ret void
}

define void @test_src16_dstunalign_constant_size_256(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dstunalign_constant_size_256(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    call void @esp32p4MemCpySrc16DstunalignedVar(ptr [[A]], ptr [[B]], i32 256, i32 1)
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(256) %a, ptr noundef nonnull align 16 dereferenceable(256) %b, i32 256, i1 false)
  ret void
}

define void @test_src16_dstunalign_constant_size_1023(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dstunalign_constant_size_1023(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    call void @esp32p4MemCpySrc16DstunalignedVar(ptr [[A]], ptr [[B]], i32 1023, i32 1)
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(1023) %a, ptr noundef nonnull align 16 dereferenceable(1023) %b, i32 1023, i1 false)
  ret void
}

define void @test_src16_dstunalign_constant_size_1024(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src16_dstunalign_constant_size_1024(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    call void @esp32p4MemCpySrc16DstunalignedVar(ptr [[A]], ptr [[B]], i32 1024, i32 1)
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(1024) %a, ptr noundef nonnull align 16 dereferenceable(1024) %b, i32 1024, i1 false)
  ret void
}

; src8 dstunalign
define void @test_src8_dstunalign_constant_size_1(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dstunalign_constant_size_1(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = getelementptr i8, ptr [[B]], i32 0
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[A]], i32 0
; CHECK-NEXT:    [[TMP2:%.*]] = load i8, ptr [[TMP0]], align 1
; CHECK-NEXT:    store i8 [[TMP2]], ptr [[TMP1]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(1) %a, ptr noundef nonnull align 8 dereferenceable(1) %b, i32 1, i1 false)
  ret void
}

define void @test_src8_dstunalign_constant_size_2(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dstunalign_constant_size_2(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = getelementptr i8, ptr [[B]], i32 0
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[A]], i32 0
; CHECK-NEXT:    [[TMP2:%.*]] = load i16, ptr [[TMP0]], align 2
; CHECK-NEXT:    store i16 [[TMP2]], ptr [[TMP1]], align 2
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(2) %a, ptr noundef nonnull align 8 dereferenceable(2) %b, i32 2, i1 false)
  ret void
}

define void @test_src8_dstunalign_constant_size_3(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dstunalign_constant_size_3(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = getelementptr i8, ptr [[B]], i32 0
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[A]], i32 0
; CHECK-NEXT:    [[TMP2:%.*]] = load i16, ptr [[TMP0]], align 2
; CHECK-NEXT:    store i16 [[TMP2]], ptr [[TMP1]], align 2
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[B]], i32 2
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[A]], i32 2
; CHECK-NEXT:    [[TMP5:%.*]] = load i8, ptr [[TMP3]], align 1
; CHECK-NEXT:    store i8 [[TMP5]], ptr [[TMP4]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(3) %a, ptr noundef nonnull align 8 dereferenceable(3) %b, i32 3, i1 false)
  ret void
}

define void @test_src8_dstunalign_constant_size_4(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dstunalign_constant_size_4(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = getelementptr i8, ptr [[B]], i32 0
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[A]], i32 0
; CHECK-NEXT:    [[TMP2:%.*]] = load i32, ptr [[TMP0]], align 4
; CHECK-NEXT:    store i32 [[TMP2]], ptr [[TMP1]], align 4
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(4) %a, ptr noundef nonnull align 8 dereferenceable(4) %b, i32 4, i1 false)
  ret void
}

define void @test_src8_dstunalign_constant_size_5(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dstunalign_constant_size_5(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = getelementptr i8, ptr [[B]], i32 0
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[A]], i32 0
; CHECK-NEXT:    [[TMP2:%.*]] = load i32, ptr [[TMP0]], align 4
; CHECK-NEXT:    store i32 [[TMP2]], ptr [[TMP1]], align 4
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[B]], i32 4
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[A]], i32 4
; CHECK-NEXT:    [[TMP5:%.*]] = load i8, ptr [[TMP3]], align 1
; CHECK-NEXT:    store i8 [[TMP5]], ptr [[TMP4]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(5) %a, ptr noundef nonnull align 8 dereferenceable(5) %b, i32 5, i1 false)
  ret void
}

define void @test_src8_dstunalign_constant_size_6(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dstunalign_constant_size_6(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = getelementptr i8, ptr [[B]], i32 0
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[A]], i32 0
; CHECK-NEXT:    [[TMP2:%.*]] = load i32, ptr [[TMP0]], align 4
; CHECK-NEXT:    store i32 [[TMP2]], ptr [[TMP1]], align 4
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[B]], i32 4
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[A]], i32 4
; CHECK-NEXT:    [[TMP5:%.*]] = load i16, ptr [[TMP3]], align 2
; CHECK-NEXT:    store i16 [[TMP5]], ptr [[TMP4]], align 2
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(6) %a, ptr noundef nonnull align 8 dereferenceable(6) %b, i32 6, i1 false)
  ret void
}

define void @test_src8_dstunalign_constant_size_7(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dstunalign_constant_size_7(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = getelementptr i8, ptr [[B]], i32 0
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[A]], i32 0
; CHECK-NEXT:    [[TMP2:%.*]] = load i32, ptr [[TMP0]], align 4
; CHECK-NEXT:    store i32 [[TMP2]], ptr [[TMP1]], align 4
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[B]], i32 4
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[A]], i32 4
; CHECK-NEXT:    [[TMP5:%.*]] = load i16, ptr [[TMP3]], align 2
; CHECK-NEXT:    store i16 [[TMP5]], ptr [[TMP4]], align 2
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[B]], i32 6
; CHECK-NEXT:    [[TMP7:%.*]] = getelementptr i8, ptr [[A]], i32 6
; CHECK-NEXT:    [[TMP8:%.*]] = load i8, ptr [[TMP6]], align 1
; CHECK-NEXT:    store i8 [[TMP8]], ptr [[TMP7]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(7) %a, ptr noundef nonnull align 8 dereferenceable(7) %b, i32 7, i1 false)
  ret void
}

define void @test_src8_dstunalign_constant_size_8(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dstunalign_constant_size_8(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = getelementptr i8, ptr [[B]], i32 0
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[A]], i32 0
; CHECK-NEXT:    [[TMP2:%.*]] = load i32, ptr [[TMP0]], align 4
; CHECK-NEXT:    store i32 [[TMP2]], ptr [[TMP1]], align 4
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[B]], i32 4
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[A]], i32 4
; CHECK-NEXT:    [[TMP5:%.*]] = load i32, ptr [[TMP3]], align 4
; CHECK-NEXT:    store i32 [[TMP5]], ptr [[TMP4]], align 4
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(8) %a, ptr noundef nonnull align 8 dereferenceable(8) %b, i32 8, i1 false)
  ret void
}

define void @test_src8_dstunalign_constant_size_9(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dstunalign_constant_size_9(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = getelementptr i8, ptr [[B]], i32 0
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[A]], i32 0
; CHECK-NEXT:    [[TMP2:%.*]] = load i32, ptr [[TMP0]], align 4
; CHECK-NEXT:    store i32 [[TMP2]], ptr [[TMP1]], align 4
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[B]], i32 4
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[A]], i32 4
; CHECK-NEXT:    [[TMP5:%.*]] = load i32, ptr [[TMP3]], align 4
; CHECK-NEXT:    store i32 [[TMP5]], ptr [[TMP4]], align 4
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[B]], i32 8
; CHECK-NEXT:    [[TMP7:%.*]] = getelementptr i8, ptr [[A]], i32 8
; CHECK-NEXT:    [[TMP8:%.*]] = load i8, ptr [[TMP6]], align 1
; CHECK-NEXT:    store i8 [[TMP8]], ptr [[TMP7]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(9) %a, ptr noundef nonnull align 8 dereferenceable(9) %b, i32 9, i1 false)
  ret void
}

define void @test_src8_dstunalign_constant_size_10(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dstunalign_constant_size_10(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = getelementptr i8, ptr [[B]], i32 0
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[A]], i32 0
; CHECK-NEXT:    [[TMP2:%.*]] = load i32, ptr [[TMP0]], align 4
; CHECK-NEXT:    store i32 [[TMP2]], ptr [[TMP1]], align 4
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[B]], i32 4
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[A]], i32 4
; CHECK-NEXT:    [[TMP5:%.*]] = load i32, ptr [[TMP3]], align 4
; CHECK-NEXT:    store i32 [[TMP5]], ptr [[TMP4]], align 4
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[B]], i32 8
; CHECK-NEXT:    [[TMP7:%.*]] = getelementptr i8, ptr [[A]], i32 8
; CHECK-NEXT:    [[TMP8:%.*]] = load i16, ptr [[TMP6]], align 2
; CHECK-NEXT:    store i16 [[TMP8]], ptr [[TMP7]], align 2
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(10) %a, ptr noundef nonnull align 8 dereferenceable(10) %b, i32 10, i1 false)
  ret void
}

define void @test_src8_dstunalign_constant_size_11(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dstunalign_constant_size_11(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = getelementptr i8, ptr [[B]], i32 0
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[A]], i32 0
; CHECK-NEXT:    [[TMP2:%.*]] = load i32, ptr [[TMP0]], align 4
; CHECK-NEXT:    store i32 [[TMP2]], ptr [[TMP1]], align 4
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[B]], i32 4
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[A]], i32 4
; CHECK-NEXT:    [[TMP5:%.*]] = load i32, ptr [[TMP3]], align 4
; CHECK-NEXT:    store i32 [[TMP5]], ptr [[TMP4]], align 4
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[B]], i32 8
; CHECK-NEXT:    [[TMP7:%.*]] = getelementptr i8, ptr [[A]], i32 8
; CHECK-NEXT:    [[TMP8:%.*]] = load i16, ptr [[TMP6]], align 2
; CHECK-NEXT:    store i16 [[TMP8]], ptr [[TMP7]], align 2
; CHECK-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[B]], i32 10
; CHECK-NEXT:    [[TMP10:%.*]] = getelementptr i8, ptr [[A]], i32 10
; CHECK-NEXT:    [[TMP11:%.*]] = load i8, ptr [[TMP9]], align 1
; CHECK-NEXT:    store i8 [[TMP11]], ptr [[TMP10]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(11) %a, ptr noundef nonnull align 8 dereferenceable(11) %b, i32 11, i1 false)
  ret void
}

define void @test_src8_dstunalign_constant_size_12(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dstunalign_constant_size_12(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = getelementptr i8, ptr [[B]], i32 0
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[A]], i32 0
; CHECK-NEXT:    [[TMP2:%.*]] = load i32, ptr [[TMP0]], align 4
; CHECK-NEXT:    store i32 [[TMP2]], ptr [[TMP1]], align 4
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[B]], i32 4
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[A]], i32 4
; CHECK-NEXT:    [[TMP5:%.*]] = load i32, ptr [[TMP3]], align 4
; CHECK-NEXT:    store i32 [[TMP5]], ptr [[TMP4]], align 4
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[B]], i32 8
; CHECK-NEXT:    [[TMP7:%.*]] = getelementptr i8, ptr [[A]], i32 8
; CHECK-NEXT:    [[TMP8:%.*]] = load i32, ptr [[TMP6]], align 4
; CHECK-NEXT:    store i32 [[TMP8]], ptr [[TMP7]], align 4
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(12) %a, ptr noundef nonnull align 8 dereferenceable(12) %b, i32 12, i1 false)
  ret void
}

define void @test_src8_dstunalign_constant_size_13(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dstunalign_constant_size_13(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = getelementptr i8, ptr [[B]], i32 0
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[A]], i32 0
; CHECK-NEXT:    [[TMP2:%.*]] = load i32, ptr [[TMP0]], align 4
; CHECK-NEXT:    store i32 [[TMP2]], ptr [[TMP1]], align 4
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[B]], i32 4
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[A]], i32 4
; CHECK-NEXT:    [[TMP5:%.*]] = load i32, ptr [[TMP3]], align 4
; CHECK-NEXT:    store i32 [[TMP5]], ptr [[TMP4]], align 4
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[B]], i32 8
; CHECK-NEXT:    [[TMP7:%.*]] = getelementptr i8, ptr [[A]], i32 8
; CHECK-NEXT:    [[TMP8:%.*]] = load i32, ptr [[TMP6]], align 4
; CHECK-NEXT:    store i32 [[TMP8]], ptr [[TMP7]], align 4
; CHECK-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[B]], i32 12
; CHECK-NEXT:    [[TMP10:%.*]] = getelementptr i8, ptr [[A]], i32 12
; CHECK-NEXT:    [[TMP11:%.*]] = load i8, ptr [[TMP9]], align 1
; CHECK-NEXT:    store i8 [[TMP11]], ptr [[TMP10]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(13) %a, ptr noundef nonnull align 8 dereferenceable(13) %b, i32 13, i1 false)
  ret void
}

define void @test_src8_dstunalign_constant_size_14(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dstunalign_constant_size_14(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = getelementptr i8, ptr [[B]], i32 0
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[A]], i32 0
; CHECK-NEXT:    [[TMP2:%.*]] = load i32, ptr [[TMP0]], align 4
; CHECK-NEXT:    store i32 [[TMP2]], ptr [[TMP1]], align 4
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[B]], i32 4
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[A]], i32 4
; CHECK-NEXT:    [[TMP5:%.*]] = load i32, ptr [[TMP3]], align 4
; CHECK-NEXT:    store i32 [[TMP5]], ptr [[TMP4]], align 4
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[B]], i32 8
; CHECK-NEXT:    [[TMP7:%.*]] = getelementptr i8, ptr [[A]], i32 8
; CHECK-NEXT:    [[TMP8:%.*]] = load i32, ptr [[TMP6]], align 4
; CHECK-NEXT:    store i32 [[TMP8]], ptr [[TMP7]], align 4
; CHECK-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[B]], i32 12
; CHECK-NEXT:    [[TMP10:%.*]] = getelementptr i8, ptr [[A]], i32 12
; CHECK-NEXT:    [[TMP11:%.*]] = load i16, ptr [[TMP9]], align 2
; CHECK-NEXT:    store i16 [[TMP11]], ptr [[TMP10]], align 2
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(14) %a, ptr noundef nonnull align 8 dereferenceable(14) %b, i32 14, i1 false)
  ret void
}

define void @test_src8_dstunalign_constant_size_15(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dstunalign_constant_size_15(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = getelementptr i8, ptr [[B]], i32 0
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[A]], i32 0
; CHECK-NEXT:    [[TMP2:%.*]] = load i32, ptr [[TMP0]], align 4
; CHECK-NEXT:    store i32 [[TMP2]], ptr [[TMP1]], align 4
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[B]], i32 4
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[A]], i32 4
; CHECK-NEXT:    [[TMP5:%.*]] = load i32, ptr [[TMP3]], align 4
; CHECK-NEXT:    store i32 [[TMP5]], ptr [[TMP4]], align 4
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[B]], i32 8
; CHECK-NEXT:    [[TMP7:%.*]] = getelementptr i8, ptr [[A]], i32 8
; CHECK-NEXT:    [[TMP8:%.*]] = load i32, ptr [[TMP6]], align 4
; CHECK-NEXT:    store i32 [[TMP8]], ptr [[TMP7]], align 4
; CHECK-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[B]], i32 12
; CHECK-NEXT:    [[TMP10:%.*]] = getelementptr i8, ptr [[A]], i32 12
; CHECK-NEXT:    [[TMP11:%.*]] = load i16, ptr [[TMP9]], align 2
; CHECK-NEXT:    store i16 [[TMP11]], ptr [[TMP10]], align 2
; CHECK-NEXT:    [[TMP12:%.*]] = getelementptr i8, ptr [[B]], i32 14
; CHECK-NEXT:    [[TMP13:%.*]] = getelementptr i8, ptr [[A]], i32 14
; CHECK-NEXT:    [[TMP14:%.*]] = load i8, ptr [[TMP12]], align 1
; CHECK-NEXT:    store i8 [[TMP14]], ptr [[TMP13]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(15) %a, ptr noundef nonnull align 8 dereferenceable(15) %b, i32 15, i1 false)
  ret void
}

define void @test_src8_dstunalign_constant_size_16(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dstunalign_constant_size_16(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    call void @esp32p4MemCpySrc16DstunalignedVar(ptr [[A]], ptr [[B]], i32 16, i32 1)
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(16) %a, ptr noundef nonnull align 8 dereferenceable(16) %b, i32 16, i1 false)
  ret void
}

define void @test_src8_dstunalign_constant_size_17(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dstunalign_constant_size_17(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    call void @esp32p4MemCpySrc16DstunalignedVar(ptr [[A]], ptr [[B]], i32 17, i32 1)
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(17) %a, ptr noundef nonnull align 8 dereferenceable(17) %b, i32 17, i1 false)
  ret void
}

define void @test_src8_dstunalign_constant_size_31(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dstunalign_constant_size_31(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    call void @esp32p4MemCpySrc16DstunalignedVar(ptr [[A]], ptr [[B]], i32 31, i32 1)
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(31) %a, ptr noundef nonnull align 8 dereferenceable(31) %b, i32 31, i1 false)
  ret void
}

define void @test_src8_dstunalign_constant_size_32(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dstunalign_constant_size_32(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    call void @esp32p4MemCpySrc16DstunalignedVar(ptr [[A]], ptr [[B]], i32 32, i32 1)
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(32) %a, ptr noundef nonnull align 8 dereferenceable(32) %b, i32 32, i1 false)
  ret void
}

define void @test_src8_dstunalign_constant_size_33(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dstunalign_constant_size_33(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    call void @esp32p4MemCpySrc16DstunalignedVar(ptr [[A]], ptr [[B]], i32 33, i32 1)
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(33) %a, ptr noundef nonnull align 8 dereferenceable(33) %b, i32 33, i1 false)
  ret void
}

define void @test_src8_dstunalign_constant_size_47(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dstunalign_constant_size_47(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    call void @esp32p4MemCpySrc16DstunalignedVar(ptr [[A]], ptr [[B]], i32 47, i32 1)
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(47) %a, ptr noundef nonnull align 8 dereferenceable(47) %b, i32 47, i1 false)
  ret void
}

define void @test_src8_dstunalign_constant_size_48(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dstunalign_constant_size_48(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    call void @esp32p4MemCpySrc16DstunalignedVar(ptr [[A]], ptr [[B]], i32 48, i32 1)
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(48) %a, ptr noundef nonnull align 8 dereferenceable(48) %b, i32 48, i1 false)
  ret void
}

define void @test_src8_dstunalign_constant_size_49(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dstunalign_constant_size_49(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    call void @esp32p4MemCpySrc16DstunalignedVar(ptr [[A]], ptr [[B]], i32 49, i32 1)
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(49) %a, ptr noundef nonnull align 8 dereferenceable(49) %b, i32 49, i1 false)
  ret void
}

define void @test_src8_dstunalign_constant_size_63(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dstunalign_constant_size_63(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    call void @esp32p4MemCpySrc16DstunalignedVar(ptr [[A]], ptr [[B]], i32 63, i32 1)
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(63) %a, ptr noundef nonnull align 8 dereferenceable(63) %b, i32 63, i1 false)
  ret void
}

define void @test_src8_dstunalign_constant_size_64(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dstunalign_constant_size_64(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    call void @esp32p4MemCpySrc16DstunalignedVar(ptr [[A]], ptr [[B]], i32 64, i32 1)
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(64) %a, ptr noundef nonnull align 8 dereferenceable(64) %b, i32 64, i1 false)
  ret void
}

define void @test_src8_dstunalign_constant_size_65(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dstunalign_constant_size_65(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    call void @esp32p4MemCpySrc16DstunalignedVar(ptr [[A]], ptr [[B]], i32 65, i32 1)
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(65) %a, ptr noundef nonnull align 8 dereferenceable(65) %b, i32 65, i1 false)
  ret void
}

define void @test_src8_dstunalign_constant_size_80(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dstunalign_constant_size_80(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    call void @esp32p4MemCpySrc16DstunalignedVar(ptr [[A]], ptr [[B]], i32 80, i32 1)
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(80) %a, ptr noundef nonnull align 8 dereferenceable(80) %b, i32 80, i1 false)
  ret void
}

define void @test_src8_dstunalign_constant_size_81(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dstunalign_constant_size_81(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    call void @esp32p4MemCpySrc16DstunalignedVar(ptr [[A]], ptr [[B]], i32 81, i32 1)
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(81) %a, ptr noundef nonnull align 8 dereferenceable(81) %b, i32 81, i1 false)
  ret void
}

define void @test_src8_dstunalign_constant_size_88(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dstunalign_constant_size_88(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    call void @esp32p4MemCpySrc16DstunalignedVar(ptr [[A]], ptr [[B]], i32 88, i32 1)
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(88) %a, ptr noundef nonnull align 8 dereferenceable(88) %b, i32 88, i1 false)
  ret void
}

define void @test_src8_dstunalign_constant_size_96(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dstunalign_constant_size_96(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    call void @esp32p4MemCpySrc16DstunalignedVar(ptr [[A]], ptr [[B]], i32 96, i32 1)
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(96) %a, ptr noundef nonnull align 8 dereferenceable(96) %b, i32 96, i1 false)
  ret void
}

define void @test_src8_dstunalign_constant_size_112(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dstunalign_constant_size_112(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    call void @esp32p4MemCpySrc16DstunalignedVar(ptr [[A]], ptr [[B]], i32 112, i32 1)
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(112) %a, ptr noundef nonnull align 8 dereferenceable(112) %b, i32 112, i1 false)
  ret void
}

define void @test_src8_dstunalign_constant_size_124(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dstunalign_constant_size_124(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    call void @esp32p4MemCpySrc16DstunalignedVar(ptr [[A]], ptr [[B]], i32 124, i32 1)
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(124) %a, ptr noundef nonnull align 8 dereferenceable(124) %b, i32 124, i1 false)
  ret void
}

define void @test_src8_dstunalign_constant_size_127(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dstunalign_constant_size_127(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    call void @esp32p4MemCpySrc16DstunalignedVar(ptr [[A]], ptr [[B]], i32 127, i32 1)
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(127) %a, ptr noundef nonnull align 8 dereferenceable(127) %b, i32 127, i1 false)
  ret void
}

define void @test_src8_dstunalign_constant_size_128(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dstunalign_constant_size_128(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    call void @esp32p4MemCpySrc16DstunalignedVar(ptr [[A]], ptr [[B]], i32 128, i32 1)
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(128) %a, ptr noundef nonnull align 8 dereferenceable(128) %b, i32 128, i1 false)
  ret void
}

define void @test_src8_dstunalign_constant_size_129(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dstunalign_constant_size_129(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    call void @esp32p4MemCpySrc16DstunalignedVar(ptr [[A]], ptr [[B]], i32 129, i32 1)
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(129) %a, ptr noundef nonnull align 8 dereferenceable(129) %b, i32 129, i1 false)
  ret void
}

define void @test_src8_dstunalign_constant_size_255(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dstunalign_constant_size_255(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    call void @esp32p4MemCpySrc16DstunalignedVar(ptr [[A]], ptr [[B]], i32 255, i32 1)
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(255) %a, ptr noundef nonnull align 8 dereferenceable(255) %b, i32 255, i1 false)
  ret void
}

define void @test_src8_dstunalign_constant_size_256(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dstunalign_constant_size_256(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    call void @esp32p4MemCpySrc16DstunalignedVar(ptr [[A]], ptr [[B]], i32 256, i32 1)
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(256) %a, ptr noundef nonnull align 8 dereferenceable(256) %b, i32 256, i1 false)
  ret void
}

define void @test_src8_dstunalign_constant_size_1023(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dstunalign_constant_size_1023(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    call void @esp32p4MemCpySrc16DstunalignedVar(ptr [[A]], ptr [[B]], i32 1023, i32 1)
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(1023) %a, ptr noundef nonnull align 8 dereferenceable(1023) %b, i32 1023, i1 false)
  ret void
}

define void @test_src8_dstunalign_constant_size_1024(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_src8_dstunalign_constant_size_1024(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    call void @esp32p4MemCpySrc16DstunalignedVar(ptr [[A]], ptr [[B]], i32 1024, i32 1)
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(1024) %a, ptr noundef nonnull align 8 dereferenceable(1024) %b, i32 1024, i1 false)
  ret void
}

; srcunalign dst16
define void @test_srcunalign_dst16_constant_size(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_srcunalign_dst16_constant_size(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = getelementptr i8, ptr [[B]], i32 0
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[A]], i32 0
; CHECK-NEXT:    [[TMP2:%.*]] = load i32, ptr [[TMP0]], align 4
; CHECK-NEXT:    store i32 [[TMP2]], ptr [[TMP1]], align 4
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[B]], i32 4
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[A]], i32 4
; CHECK-NEXT:    [[TMP5:%.*]] = load i16, ptr [[TMP3]], align 2
; CHECK-NEXT:    store i16 [[TMP5]], ptr [[TMP4]], align 2
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[B]], i32 6
; CHECK-NEXT:    [[TMP7:%.*]] = getelementptr i8, ptr [[A]], i32 6
; CHECK-NEXT:    [[TMP8:%.*]] = load i8, ptr [[TMP6]], align 1
; CHECK-NEXT:    store i8 [[TMP8]], ptr [[TMP7]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(7) %a, ptr noundef nonnull align 1 dereferenceable(7) %b, i32 7, i1 false)
  ret void
}

define void @test_srcunalign_dst16_constant_size_15(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_srcunalign_dst16_constant_size_15(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = getelementptr i8, ptr [[B]], i32 0
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[A]], i32 0
; CHECK-NEXT:    [[TMP2:%.*]] = load i32, ptr [[TMP0]], align 4
; CHECK-NEXT:    store i32 [[TMP2]], ptr [[TMP1]], align 4
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[B]], i32 4
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[A]], i32 4
; CHECK-NEXT:    [[TMP5:%.*]] = load i32, ptr [[TMP3]], align 4
; CHECK-NEXT:    store i32 [[TMP5]], ptr [[TMP4]], align 4
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[B]], i32 8
; CHECK-NEXT:    [[TMP7:%.*]] = getelementptr i8, ptr [[A]], i32 8
; CHECK-NEXT:    [[TMP8:%.*]] = load i32, ptr [[TMP6]], align 4
; CHECK-NEXT:    store i32 [[TMP8]], ptr [[TMP7]], align 4
; CHECK-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[B]], i32 12
; CHECK-NEXT:    [[TMP10:%.*]] = getelementptr i8, ptr [[A]], i32 12
; CHECK-NEXT:    [[TMP11:%.*]] = load i16, ptr [[TMP9]], align 2
; CHECK-NEXT:    store i16 [[TMP11]], ptr [[TMP10]], align 2
; CHECK-NEXT:    [[TMP12:%.*]] = getelementptr i8, ptr [[B]], i32 14
; CHECK-NEXT:    [[TMP13:%.*]] = getelementptr i8, ptr [[A]], i32 14
; CHECK-NEXT:    [[TMP14:%.*]] = load i8, ptr [[TMP12]], align 1
; CHECK-NEXT:    store i8 [[TMP14]], ptr [[TMP13]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(15) %a, ptr noundef nonnull align 1 dereferenceable(15) %b, i32 15, i1 false)
  ret void
}

define void @test_srcunalign_dst16_constant_size_16(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_srcunalign_dst16_constant_size_16(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.ld.128.usar.ip q0, $0, 16", "+{a1}"(i32 [[TMP0]]) #[[ATTR2:[0-9]+]]
; CHECK-NEXT:    call void asm sideeffect "esp.ld.128.usar.ip q1, $0, 16", "+{a1}"(i32 [[TMP0]]) #[[ATTR2]]
; CHECK-NEXT:    call void asm sideeffect "esp.src.q q0, q0, q1", ""() #[[ATTR2]]
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q0, $0, 16", "+{a0}"(i32 [[TMP1]]) #[[ATTR2]]
; CHECK-NEXT:    call void @esp32p4MemCpySrcUnalignedDstUnalignedVarFrom0To15Opt(ptr [[A]], ptr [[B]], i32 0)
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(16) %a, ptr noundef nonnull align 1 dereferenceable(16) %b, i32 16, i1 false)
  ret void
}

define void @test_srcunalign_dst16_constant_size_17(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_srcunalign_dst16_constant_size_17(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.ld.128.usar.ip q0, $0, 16", "+{a1}"(i32 [[TMP0]]) #[[ATTR2]]
; CHECK-NEXT:    call void asm sideeffect "esp.ld.128.usar.ip q1, $0, 16", "+{a1}"(i32 [[TMP0]]) #[[ATTR2]]
; CHECK-NEXT:    call void asm sideeffect "esp.src.q q0, q0, q1", ""() #[[ATTR2]]
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q0, $0, 16", "+{a0}"(i32 [[TMP1]]) #[[ATTR2]]
; CHECK-NEXT:    call void @esp32p4MemCpySrcUnalignedDstUnalignedVarFrom0To15Opt(ptr [[A]], ptr [[B]], i32 0)
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[B]], i64 16
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[A]], i64 16
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[TMP2]], i32 0
; CHECK-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[TMP3]], i32 0
; CHECK-NEXT:    [[TMP6:%.*]] = load i8, ptr [[TMP4]], align 1
; CHECK-NEXT:    store i8 [[TMP6]], ptr [[TMP5]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(17) %a, ptr noundef nonnull align 1 dereferenceable(17) %b, i32 17, i1 false)
  ret void
}

define void @test_srcunalign_dst16_constant_size_31(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_srcunalign_dst16_constant_size_31(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.ld.128.usar.ip q0, $0, 16", "+{a1}"(i32 [[TMP0]]) #[[ATTR2]]
; CHECK-NEXT:    call void asm sideeffect "esp.ld.128.usar.ip q1, $0, 16", "+{a1}"(i32 [[TMP0]]) #[[ATTR2]]
; CHECK-NEXT:    call void asm sideeffect "esp.src.q q0, q0, q1", ""() #[[ATTR2]]
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q0, $0, 16", "+{a0}"(i32 [[TMP1]]) #[[ATTR2]]
; CHECK-NEXT:    call void @esp32p4MemCpySrcUnalignedDstUnalignedVarFrom0To15Opt(ptr [[A]], ptr [[B]], i32 0)
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[B]], i64 16
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[A]], i64 16
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[TMP2]], i32 0
; CHECK-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[TMP3]], i32 0
; CHECK-NEXT:    [[TMP6:%.*]] = load i32, ptr [[TMP4]], align 4
; CHECK-NEXT:    store i32 [[TMP6]], ptr [[TMP5]], align 4
; CHECK-NEXT:    [[TMP7:%.*]] = getelementptr i8, ptr [[TMP2]], i32 4
; CHECK-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[TMP3]], i32 4
; CHECK-NEXT:    [[TMP9:%.*]] = load i32, ptr [[TMP7]], align 4
; CHECK-NEXT:    store i32 [[TMP9]], ptr [[TMP8]], align 4
; CHECK-NEXT:    [[TMP10:%.*]] = getelementptr i8, ptr [[TMP2]], i32 8
; CHECK-NEXT:    [[TMP11:%.*]] = getelementptr i8, ptr [[TMP3]], i32 8
; CHECK-NEXT:    [[TMP12:%.*]] = load i32, ptr [[TMP10]], align 4
; CHECK-NEXT:    store i32 [[TMP12]], ptr [[TMP11]], align 4
; CHECK-NEXT:    [[TMP13:%.*]] = getelementptr i8, ptr [[TMP2]], i32 12
; CHECK-NEXT:    [[TMP14:%.*]] = getelementptr i8, ptr [[TMP3]], i32 12
; CHECK-NEXT:    [[TMP15:%.*]] = load i16, ptr [[TMP13]], align 2
; CHECK-NEXT:    store i16 [[TMP15]], ptr [[TMP14]], align 2
; CHECK-NEXT:    [[TMP16:%.*]] = getelementptr i8, ptr [[TMP2]], i32 14
; CHECK-NEXT:    [[TMP17:%.*]] = getelementptr i8, ptr [[TMP3]], i32 14
; CHECK-NEXT:    [[TMP18:%.*]] = load i8, ptr [[TMP16]], align 1
; CHECK-NEXT:    store i8 [[TMP18]], ptr [[TMP17]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(31) %a, ptr noundef nonnull align 1 dereferenceable(31) %b, i32 31, i1 false)
  ret void
}

define void @test_srcunalign_dst16_constant_size_32(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_srcunalign_dst16_constant_size_32(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.ld.128.usar.ip q0, $0, 16", "+{a1}"(i32 [[TMP0]]) #[[ATTR2]]
; CHECK-NEXT:    call void asm sideeffect "esp.ld.128.usar.ip q1, $0, 16", "+{a1}"(i32 [[TMP0]]) #[[ATTR2]]
; CHECK-NEXT:    call void asm sideeffect "esp.src.q.ld.ip q2, $0, 0, q0, q1", "+{a1}"(i32 [[TMP0]]) #[[ATTR2]]
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q0, $0, 16", "+{a0}"(i32 [[TMP1]]) #[[ATTR2]]
; CHECK-NEXT:    call void asm sideeffect "esp.src.q q1, q1, q2", ""() #[[ATTR2]]
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q1, $0, 16", "+{a0}"(i32 [[TMP1]]) #[[ATTR2]]
; CHECK-NEXT:    call void @esp32p4MemCpySrcUnalignedDstUnalignedVarFrom0To15Opt(ptr [[A]], ptr [[B]], i32 0)
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(32) %a, ptr noundef nonnull align 1 dereferenceable(32) %b, i32 32, i1 false)
  ret void
}

define void @test_srcunalign_dst16_constant_size_33(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_srcunalign_dst16_constant_size_33(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.ld.128.usar.ip q0, $0, 16", "+{a1}"(i32 [[TMP0]]) #[[ATTR2]]
; CHECK-NEXT:    call void asm sideeffect "esp.ld.128.usar.ip q1, $0, 16", "+{a1}"(i32 [[TMP0]]) #[[ATTR2]]
; CHECK-NEXT:    call void asm sideeffect "esp.src.q.ld.ip q2, $0, 0, q0, q1", "+{a1}"(i32 [[TMP0]]) #[[ATTR2]]
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q0, $0, 16", "+{a0}"(i32 [[TMP1]]) #[[ATTR2]]
; CHECK-NEXT:    call void asm sideeffect "esp.src.q q1, q1, q2", ""() #[[ATTR2]]
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q1, $0, 16", "+{a0}"(i32 [[TMP1]]) #[[ATTR2]]
; CHECK-NEXT:    call void @esp32p4MemCpySrcUnalignedDstUnalignedVarFrom0To15Opt(ptr [[A]], ptr [[B]], i32 0)
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[B]], i64 32
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[A]], i64 32
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[TMP2]], i32 0
; CHECK-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[TMP3]], i32 0
; CHECK-NEXT:    [[TMP6:%.*]] = load i8, ptr [[TMP4]], align 1
; CHECK-NEXT:    store i8 [[TMP6]], ptr [[TMP5]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(33) %a, ptr noundef nonnull align 1 dereferenceable(33) %b, i32 33, i1 false)
  ret void
}

define void @test_srcunalign_dst16_constant_size_47(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_srcunalign_dst16_constant_size_47(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.ld.128.usar.ip q0, $0, 16", "+{a1}"(i32 [[TMP0]]) #[[ATTR2]]
; CHECK-NEXT:    call void asm sideeffect "esp.ld.128.usar.ip q1, $0, 16", "+{a1}"(i32 [[TMP0]]) #[[ATTR2]]
; CHECK-NEXT:    call void asm sideeffect "esp.src.q.ld.ip q2, $0, 0, q0, q1", "+{a1}"(i32 [[TMP0]]) #[[ATTR2]]
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q0, $0, 16", "+{a0}"(i32 [[TMP1]]) #[[ATTR2]]
; CHECK-NEXT:    call void asm sideeffect "esp.src.q q1, q1, q2", ""() #[[ATTR2]]
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q1, $0, 16", "+{a0}"(i32 [[TMP1]]) #[[ATTR2]]
; CHECK-NEXT:    call void @esp32p4MemCpySrcUnalignedDstUnalignedVarFrom0To15Opt(ptr [[A]], ptr [[B]], i32 0)
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[B]], i64 32
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[A]], i64 32
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[TMP2]], i32 0
; CHECK-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[TMP3]], i32 0
; CHECK-NEXT:    [[TMP6:%.*]] = load i32, ptr [[TMP4]], align 4
; CHECK-NEXT:    store i32 [[TMP6]], ptr [[TMP5]], align 4
; CHECK-NEXT:    [[TMP7:%.*]] = getelementptr i8, ptr [[TMP2]], i32 4
; CHECK-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[TMP3]], i32 4
; CHECK-NEXT:    [[TMP9:%.*]] = load i32, ptr [[TMP7]], align 4
; CHECK-NEXT:    store i32 [[TMP9]], ptr [[TMP8]], align 4
; CHECK-NEXT:    [[TMP10:%.*]] = getelementptr i8, ptr [[TMP2]], i32 8
; CHECK-NEXT:    [[TMP11:%.*]] = getelementptr i8, ptr [[TMP3]], i32 8
; CHECK-NEXT:    [[TMP12:%.*]] = load i32, ptr [[TMP10]], align 4
; CHECK-NEXT:    store i32 [[TMP12]], ptr [[TMP11]], align 4
; CHECK-NEXT:    [[TMP13:%.*]] = getelementptr i8, ptr [[TMP2]], i32 12
; CHECK-NEXT:    [[TMP14:%.*]] = getelementptr i8, ptr [[TMP3]], i32 12
; CHECK-NEXT:    [[TMP15:%.*]] = load i16, ptr [[TMP13]], align 2
; CHECK-NEXT:    store i16 [[TMP15]], ptr [[TMP14]], align 2
; CHECK-NEXT:    [[TMP16:%.*]] = getelementptr i8, ptr [[TMP2]], i32 14
; CHECK-NEXT:    [[TMP17:%.*]] = getelementptr i8, ptr [[TMP3]], i32 14
; CHECK-NEXT:    [[TMP18:%.*]] = load i8, ptr [[TMP16]], align 1
; CHECK-NEXT:    store i8 [[TMP18]], ptr [[TMP17]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(47) %a, ptr noundef nonnull align 1 dereferenceable(47) %b, i32 47, i1 false)
  ret void
}

define void @test_srcunalign_dst16_constant_size_48(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_srcunalign_dst16_constant_size_48(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    tail call void @esp32p4MemCpySrcunalignedDst16Div48Index0(i32 [[TMP1]], i32 [[TMP0]])
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(48) %a, ptr noundef nonnull align 1 dereferenceable(48) %b, i32 48, i1 false)
  ret void
}

define void @test_srcunalign_dst16_constant_size_49(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_srcunalign_dst16_constant_size_49(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    tail call void @esp32p4MemCpySrcunalignedDst16Div48Index1(i32 [[TMP1]], i32 [[TMP0]])
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[B]], i64 48
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[A]], i64 48
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[TMP2]], i32 0
; CHECK-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[TMP3]], i32 0
; CHECK-NEXT:    [[TMP6:%.*]] = load i8, ptr [[TMP4]], align 1
; CHECK-NEXT:    store i8 [[TMP6]], ptr [[TMP5]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(49) %a, ptr noundef nonnull align 1 dereferenceable(49) %b, i32 49, i1 false)
  ret void
}

define void @test_srcunalign_dst16_constant_size_63(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_srcunalign_dst16_constant_size_63(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    tail call void @esp32p4MemCpySrcunalignedDst16Div48Index2(i32 [[TMP1]], i32 [[TMP0]])
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[B]], i64 48
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[A]], i64 48
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[TMP2]], i32 0
; CHECK-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[TMP3]], i32 0
; CHECK-NEXT:    [[TMP6:%.*]] = load i32, ptr [[TMP4]], align 4
; CHECK-NEXT:    store i32 [[TMP6]], ptr [[TMP5]], align 4
; CHECK-NEXT:    [[TMP7:%.*]] = getelementptr i8, ptr [[TMP2]], i32 4
; CHECK-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[TMP3]], i32 4
; CHECK-NEXT:    [[TMP9:%.*]] = load i32, ptr [[TMP7]], align 4
; CHECK-NEXT:    store i32 [[TMP9]], ptr [[TMP8]], align 4
; CHECK-NEXT:    [[TMP10:%.*]] = getelementptr i8, ptr [[TMP2]], i32 8
; CHECK-NEXT:    [[TMP11:%.*]] = getelementptr i8, ptr [[TMP3]], i32 8
; CHECK-NEXT:    [[TMP12:%.*]] = load i32, ptr [[TMP10]], align 4
; CHECK-NEXT:    store i32 [[TMP12]], ptr [[TMP11]], align 4
; CHECK-NEXT:    [[TMP13:%.*]] = getelementptr i8, ptr [[TMP2]], i32 12
; CHECK-NEXT:    [[TMP14:%.*]] = getelementptr i8, ptr [[TMP3]], i32 12
; CHECK-NEXT:    [[TMP15:%.*]] = load i16, ptr [[TMP13]], align 2
; CHECK-NEXT:    store i16 [[TMP15]], ptr [[TMP14]], align 2
; CHECK-NEXT:    [[TMP16:%.*]] = getelementptr i8, ptr [[TMP2]], i32 14
; CHECK-NEXT:    [[TMP17:%.*]] = getelementptr i8, ptr [[TMP3]], i32 14
; CHECK-NEXT:    [[TMP18:%.*]] = load i8, ptr [[TMP16]], align 1
; CHECK-NEXT:    store i8 [[TMP18]], ptr [[TMP17]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(63) %a, ptr noundef nonnull align 1 dereferenceable(63) %b, i32 63, i1 false)
  ret void
}

define void @test_srcunalign_dst16_constant_size_64(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_srcunalign_dst16_constant_size_64(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    tail call void @esp32p4MemCpySrcunalignedDst16mod48From16to31.0(i32 [[TMP1]], i32 [[TMP0]])
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(64) %a, ptr noundef nonnull align 1 dereferenceable(64) %b, i32 64, i1 false)
  ret void
}

define void @test_srcunalign_dst16_constant_size_65(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_srcunalign_dst16_constant_size_65(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    tail call void @esp32p4MemCpySrcunalignedDst16mod48From16to31.1(i32 [[TMP1]], i32 [[TMP0]])
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[B]], i64 64
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[A]], i64 64
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[TMP2]], i32 0
; CHECK-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[TMP3]], i32 0
; CHECK-NEXT:    [[TMP6:%.*]] = load i8, ptr [[TMP4]], align 1
; CHECK-NEXT:    store i8 [[TMP6]], ptr [[TMP5]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(65) %a, ptr noundef nonnull align 1 dereferenceable(65) %b, i32 65, i1 false)
  ret void
}

define void @test_srcunalign_dst16_constant_size_80(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_srcunalign_dst16_constant_size_80(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    tail call void @esp32p4MemCpySrcunalignedDst16mod48From32To47Index0(i32 [[TMP1]], i32 [[TMP0]])
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(80) %a, ptr noundef nonnull align 1 dereferenceable(80) %b, i32 80, i1 false)
  ret void
}

define void @test_srcunalign_dst16_constant_size_81(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_srcunalign_dst16_constant_size_81(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    tail call void @esp32p4MemCpySrcunalignedDst16mod48From32To47Index1(i32 [[TMP1]], i32 [[TMP0]])
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[B]], i64 80
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[A]], i64 80
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[TMP2]], i32 0
; CHECK-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[TMP3]], i32 0
; CHECK-NEXT:    [[TMP6:%.*]] = load i8, ptr [[TMP4]], align 1
; CHECK-NEXT:    store i8 [[TMP6]], ptr [[TMP5]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(81) %a, ptr noundef nonnull align 1 dereferenceable(81) %b, i32 81, i1 false)
  ret void
}

define void @test_srcunalign_dst16_constant_size_88(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_srcunalign_dst16_constant_size_88(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    tail call void @esp32p4MemCpySrcunalignedDst16mod48From32To47Index2(i32 [[TMP1]], i32 [[TMP0]])
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[B]], i64 80
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[A]], i64 80
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[TMP2]], i32 0
; CHECK-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[TMP3]], i32 0
; CHECK-NEXT:    [[TMP6:%.*]] = load i32, ptr [[TMP4]], align 4
; CHECK-NEXT:    store i32 [[TMP6]], ptr [[TMP5]], align 4
; CHECK-NEXT:    [[TMP7:%.*]] = getelementptr i8, ptr [[TMP2]], i32 4
; CHECK-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[TMP3]], i32 4
; CHECK-NEXT:    [[TMP9:%.*]] = load i32, ptr [[TMP7]], align 4
; CHECK-NEXT:    store i32 [[TMP9]], ptr [[TMP8]], align 4
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(88) %a, ptr noundef nonnull align 1 dereferenceable(88) %b, i32 88, i1 false)
  ret void
}

define void @test_srcunalign_dst16_constant_size_96(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_srcunalign_dst16_constant_size_96(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    tail call void @esp32p4MemCpySrcunalignedDst16Div48Index3(i32 [[TMP1]], i32 [[TMP0]])
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(96) %a, ptr noundef nonnull align 1 dereferenceable(96) %b, i32 96, i1 false)
  ret void
}

define void @test_srcunalign_dst16_constant_size_112(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_srcunalign_dst16_constant_size_112(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    tail call void @esp32p4MemCpySrcunalignedDst16mod48From16to31.2(i32 [[TMP1]], i32 [[TMP0]])
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(112) %a, ptr noundef nonnull align 1 dereferenceable(112) %b, i32 112, i1 false)
  ret void
}

define void @test_srcunalign_dst16_constant_size_124(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_srcunalign_dst16_constant_size_124(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    tail call void @esp32p4MemCpySrcunalignedDst16mod48From16to31.3(i32 [[TMP1]], i32 [[TMP0]])
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[B]], i64 112
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[A]], i64 112
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[TMP2]], i32 0
; CHECK-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[TMP3]], i32 0
; CHECK-NEXT:    [[TMP6:%.*]] = load i32, ptr [[TMP4]], align 4
; CHECK-NEXT:    store i32 [[TMP6]], ptr [[TMP5]], align 4
; CHECK-NEXT:    [[TMP7:%.*]] = getelementptr i8, ptr [[TMP2]], i32 4
; CHECK-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[TMP3]], i32 4
; CHECK-NEXT:    [[TMP9:%.*]] = load i32, ptr [[TMP7]], align 4
; CHECK-NEXT:    store i32 [[TMP9]], ptr [[TMP8]], align 4
; CHECK-NEXT:    [[TMP10:%.*]] = getelementptr i8, ptr [[TMP2]], i32 8
; CHECK-NEXT:    [[TMP11:%.*]] = getelementptr i8, ptr [[TMP3]], i32 8
; CHECK-NEXT:    [[TMP12:%.*]] = load i32, ptr [[TMP10]], align 4
; CHECK-NEXT:    store i32 [[TMP12]], ptr [[TMP11]], align 4
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(124) %a, ptr noundef nonnull align 1 dereferenceable(124) %b, i32 124, i1 false)
  ret void
}

define void @test_srcunalign_dst16_constant_size_127(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_srcunalign_dst16_constant_size_127(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    tail call void @esp32p4MemCpySrcunalignedDst16mod48From16to31.4(i32 [[TMP1]], i32 [[TMP0]])
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[B]], i64 112
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[A]], i64 112
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[TMP2]], i32 0
; CHECK-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[TMP3]], i32 0
; CHECK-NEXT:    [[TMP6:%.*]] = load i32, ptr [[TMP4]], align 4
; CHECK-NEXT:    store i32 [[TMP6]], ptr [[TMP5]], align 4
; CHECK-NEXT:    [[TMP7:%.*]] = getelementptr i8, ptr [[TMP2]], i32 4
; CHECK-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[TMP3]], i32 4
; CHECK-NEXT:    [[TMP9:%.*]] = load i32, ptr [[TMP7]], align 4
; CHECK-NEXT:    store i32 [[TMP9]], ptr [[TMP8]], align 4
; CHECK-NEXT:    [[TMP10:%.*]] = getelementptr i8, ptr [[TMP2]], i32 8
; CHECK-NEXT:    [[TMP11:%.*]] = getelementptr i8, ptr [[TMP3]], i32 8
; CHECK-NEXT:    [[TMP12:%.*]] = load i32, ptr [[TMP10]], align 4
; CHECK-NEXT:    store i32 [[TMP12]], ptr [[TMP11]], align 4
; CHECK-NEXT:    [[TMP13:%.*]] = getelementptr i8, ptr [[TMP2]], i32 12
; CHECK-NEXT:    [[TMP14:%.*]] = getelementptr i8, ptr [[TMP3]], i32 12
; CHECK-NEXT:    [[TMP15:%.*]] = load i16, ptr [[TMP13]], align 2
; CHECK-NEXT:    store i16 [[TMP15]], ptr [[TMP14]], align 2
; CHECK-NEXT:    [[TMP16:%.*]] = getelementptr i8, ptr [[TMP2]], i32 14
; CHECK-NEXT:    [[TMP17:%.*]] = getelementptr i8, ptr [[TMP3]], i32 14
; CHECK-NEXT:    [[TMP18:%.*]] = load i8, ptr [[TMP16]], align 1
; CHECK-NEXT:    store i8 [[TMP18]], ptr [[TMP17]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(127) %a, ptr noundef nonnull align 1 dereferenceable(127) %b, i32 127, i1 false)
  ret void
}

define void @test_srcunalign_dst16_constant_size_128(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_srcunalign_dst16_constant_size_128(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    tail call void @esp32p4MemCpySrcunalignedDst16mod48From32To47Index3(i32 [[TMP1]], i32 [[TMP0]])
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(128) %a, ptr noundef nonnull align 1 dereferenceable(128) %b, i32 128, i1 false)
  ret void
}

define void @test_srcunalign_dst16_constant_size_129(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_srcunalign_dst16_constant_size_129(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    tail call void @esp32p4MemCpySrcunalignedDst16mod48From32To47Index4(i32 [[TMP1]], i32 [[TMP0]])
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[B]], i64 128
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[A]], i64 128
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[TMP2]], i32 0
; CHECK-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[TMP3]], i32 0
; CHECK-NEXT:    [[TMP6:%.*]] = load i8, ptr [[TMP4]], align 1
; CHECK-NEXT:    store i8 [[TMP6]], ptr [[TMP5]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(129) %a, ptr noundef nonnull align 1 dereferenceable(129) %b, i32 129, i1 false)
  ret void
}

define void @test_srcunalign_dst16_constant_size_255(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_srcunalign_dst16_constant_size_255(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    tail call void @esp32p4MemCpySrcunalignedDst16Div48Index4(i32 [[TMP1]], i32 [[TMP0]])
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[B]], i64 240
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[A]], i64 240
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[TMP2]], i32 0
; CHECK-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[TMP3]], i32 0
; CHECK-NEXT:    [[TMP6:%.*]] = load i32, ptr [[TMP4]], align 4
; CHECK-NEXT:    store i32 [[TMP6]], ptr [[TMP5]], align 4
; CHECK-NEXT:    [[TMP7:%.*]] = getelementptr i8, ptr [[TMP2]], i32 4
; CHECK-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[TMP3]], i32 4
; CHECK-NEXT:    [[TMP9:%.*]] = load i32, ptr [[TMP7]], align 4
; CHECK-NEXT:    store i32 [[TMP9]], ptr [[TMP8]], align 4
; CHECK-NEXT:    [[TMP10:%.*]] = getelementptr i8, ptr [[TMP2]], i32 8
; CHECK-NEXT:    [[TMP11:%.*]] = getelementptr i8, ptr [[TMP3]], i32 8
; CHECK-NEXT:    [[TMP12:%.*]] = load i32, ptr [[TMP10]], align 4
; CHECK-NEXT:    store i32 [[TMP12]], ptr [[TMP11]], align 4
; CHECK-NEXT:    [[TMP13:%.*]] = getelementptr i8, ptr [[TMP2]], i32 12
; CHECK-NEXT:    [[TMP14:%.*]] = getelementptr i8, ptr [[TMP3]], i32 12
; CHECK-NEXT:    [[TMP15:%.*]] = load i16, ptr [[TMP13]], align 2
; CHECK-NEXT:    store i16 [[TMP15]], ptr [[TMP14]], align 2
; CHECK-NEXT:    [[TMP16:%.*]] = getelementptr i8, ptr [[TMP2]], i32 14
; CHECK-NEXT:    [[TMP17:%.*]] = getelementptr i8, ptr [[TMP3]], i32 14
; CHECK-NEXT:    [[TMP18:%.*]] = load i8, ptr [[TMP16]], align 1
; CHECK-NEXT:    store i8 [[TMP18]], ptr [[TMP17]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(255) %a, ptr noundef nonnull align 1 dereferenceable(255) %b, i32 255, i1 false)
  ret void
}

define void @test_srcunalign_dst16_constant_size_256(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_srcunalign_dst16_constant_size_256(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    tail call void @esp32p4MemCpySrcunalignedDst16mod48From16to31.5(i32 [[TMP1]], i32 [[TMP0]])
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(256) %a, ptr noundef nonnull align 1 dereferenceable(256) %b, i32 256, i1 false)
  ret void
}

define void @test_srcunalign_dst16_constant_size_1023(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_srcunalign_dst16_constant_size_1023(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    tail call void @esp32p4MemCpySrcunalignedDst16Div48Index5(i32 [[TMP1]], i32 [[TMP0]])
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[B]], i64 1008
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[A]], i64 1008
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[TMP2]], i32 0
; CHECK-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[TMP3]], i32 0
; CHECK-NEXT:    [[TMP6:%.*]] = load i32, ptr [[TMP4]], align 4
; CHECK-NEXT:    store i32 [[TMP6]], ptr [[TMP5]], align 4
; CHECK-NEXT:    [[TMP7:%.*]] = getelementptr i8, ptr [[TMP2]], i32 4
; CHECK-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[TMP3]], i32 4
; CHECK-NEXT:    [[TMP9:%.*]] = load i32, ptr [[TMP7]], align 4
; CHECK-NEXT:    store i32 [[TMP9]], ptr [[TMP8]], align 4
; CHECK-NEXT:    [[TMP10:%.*]] = getelementptr i8, ptr [[TMP2]], i32 8
; CHECK-NEXT:    [[TMP11:%.*]] = getelementptr i8, ptr [[TMP3]], i32 8
; CHECK-NEXT:    [[TMP12:%.*]] = load i32, ptr [[TMP10]], align 4
; CHECK-NEXT:    store i32 [[TMP12]], ptr [[TMP11]], align 4
; CHECK-NEXT:    [[TMP13:%.*]] = getelementptr i8, ptr [[TMP2]], i32 12
; CHECK-NEXT:    [[TMP14:%.*]] = getelementptr i8, ptr [[TMP3]], i32 12
; CHECK-NEXT:    [[TMP15:%.*]] = load i16, ptr [[TMP13]], align 2
; CHECK-NEXT:    store i16 [[TMP15]], ptr [[TMP14]], align 2
; CHECK-NEXT:    [[TMP16:%.*]] = getelementptr i8, ptr [[TMP2]], i32 14
; CHECK-NEXT:    [[TMP17:%.*]] = getelementptr i8, ptr [[TMP3]], i32 14
; CHECK-NEXT:    [[TMP18:%.*]] = load i8, ptr [[TMP16]], align 1
; CHECK-NEXT:    store i8 [[TMP18]], ptr [[TMP17]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(1023) %a, ptr noundef nonnull align 1 dereferenceable(1023) %b, i32 1023, i1 false)
  ret void
}

define void @test_srcunalign_dst16_constant_size_1024(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_srcunalign_dst16_constant_size_1024(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint ptr [[B]] to i32
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[A]] to i32
; CHECK-NEXT:    tail call void @esp32p4MemCpySrcunalignedDst16mod48From16to31.6(i32 [[TMP1]], i32 [[TMP0]])
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 16 dereferenceable(1024) %a, ptr noundef nonnull align 1 dereferenceable(1024) %b, i32 1024, i1 false)
  ret void
}

; srcunalign dst8
define void @test_srcunalign_dst8_constant_size_1(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_srcunalign_dst8_constant_size_1(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = getelementptr i8, ptr [[B]], i32 0
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[A]], i32 0
; CHECK-NEXT:    [[TMP2:%.*]] = load i8, ptr [[TMP0]], align 1
; CHECK-NEXT:    store i8 [[TMP2]], ptr [[TMP1]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(1) %a, ptr noundef nonnull align 1 dereferenceable(1) %b, i32 1, i1 false)
  ret void
}

define void @test_srcunalign_dst8_constant_size_2(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_srcunalign_dst8_constant_size_2(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = getelementptr i8, ptr [[B]], i32 0
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[A]], i32 0
; CHECK-NEXT:    [[TMP2:%.*]] = load i16, ptr [[TMP0]], align 2
; CHECK-NEXT:    store i16 [[TMP2]], ptr [[TMP1]], align 2
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(2) %a, ptr noundef nonnull align 1 dereferenceable(2) %b, i32 2, i1 false)
  ret void
}

define void @test_srcunalign_dst8_constant_size_3(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_srcunalign_dst8_constant_size_3(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = getelementptr i8, ptr [[B]], i32 0
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[A]], i32 0
; CHECK-NEXT:    [[TMP2:%.*]] = load i16, ptr [[TMP0]], align 2
; CHECK-NEXT:    store i16 [[TMP2]], ptr [[TMP1]], align 2
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[B]], i32 2
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[A]], i32 2
; CHECK-NEXT:    [[TMP5:%.*]] = load i8, ptr [[TMP3]], align 1
; CHECK-NEXT:    store i8 [[TMP5]], ptr [[TMP4]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(3) %a, ptr noundef nonnull align 1 dereferenceable(3) %b, i32 3, i1 false)
  ret void
}

define void @test_srcunalign_dst8_constant_size_4(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_srcunalign_dst8_constant_size_4(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = getelementptr i8, ptr [[B]], i32 0
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[A]], i32 0
; CHECK-NEXT:    [[TMP2:%.*]] = load i32, ptr [[TMP0]], align 4
; CHECK-NEXT:    store i32 [[TMP2]], ptr [[TMP1]], align 4
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(4) %a, ptr noundef nonnull align 1 dereferenceable(4) %b, i32 4, i1 false)
  ret void
}

define void @test_srcunalign_dst8_constant_size_5(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_srcunalign_dst8_constant_size_5(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = getelementptr i8, ptr [[B]], i32 0
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[A]], i32 0
; CHECK-NEXT:    [[TMP2:%.*]] = load i32, ptr [[TMP0]], align 4
; CHECK-NEXT:    store i32 [[TMP2]], ptr [[TMP1]], align 4
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[B]], i32 4
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[A]], i32 4
; CHECK-NEXT:    [[TMP5:%.*]] = load i8, ptr [[TMP3]], align 1
; CHECK-NEXT:    store i8 [[TMP5]], ptr [[TMP4]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(5) %a, ptr noundef nonnull align 1 dereferenceable(5) %b, i32 5, i1 false)
  ret void
}

define void @test_srcunalign_dst8_constant_size_6(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_srcunalign_dst8_constant_size_6(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = getelementptr i8, ptr [[B]], i32 0
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[A]], i32 0
; CHECK-NEXT:    [[TMP2:%.*]] = load i32, ptr [[TMP0]], align 4
; CHECK-NEXT:    store i32 [[TMP2]], ptr [[TMP1]], align 4
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[B]], i32 4
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[A]], i32 4
; CHECK-NEXT:    [[TMP5:%.*]] = load i16, ptr [[TMP3]], align 2
; CHECK-NEXT:    store i16 [[TMP5]], ptr [[TMP4]], align 2
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(6) %a, ptr noundef nonnull align 1 dereferenceable(6) %b, i32 6, i1 false)
  ret void
}

define void @test_srcunalign_dst8_constant_size_7(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_srcunalign_dst8_constant_size_7(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = getelementptr i8, ptr [[B]], i32 0
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[A]], i32 0
; CHECK-NEXT:    [[TMP2:%.*]] = load i32, ptr [[TMP0]], align 4
; CHECK-NEXT:    store i32 [[TMP2]], ptr [[TMP1]], align 4
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[B]], i32 4
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[A]], i32 4
; CHECK-NEXT:    [[TMP5:%.*]] = load i16, ptr [[TMP3]], align 2
; CHECK-NEXT:    store i16 [[TMP5]], ptr [[TMP4]], align 2
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[B]], i32 6
; CHECK-NEXT:    [[TMP7:%.*]] = getelementptr i8, ptr [[A]], i32 6
; CHECK-NEXT:    [[TMP8:%.*]] = load i8, ptr [[TMP6]], align 1
; CHECK-NEXT:    store i8 [[TMP8]], ptr [[TMP7]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(7) %a, ptr noundef nonnull align 1 dereferenceable(7) %b, i32 7, i1 false)
  ret void
}

define void @test_srcunalign_dst8_constant_size_8(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_srcunalign_dst8_constant_size_8(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = getelementptr i8, ptr [[B]], i32 0
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[A]], i32 0
; CHECK-NEXT:    [[TMP2:%.*]] = load i32, ptr [[TMP0]], align 4
; CHECK-NEXT:    store i32 [[TMP2]], ptr [[TMP1]], align 4
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[B]], i32 4
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[A]], i32 4
; CHECK-NEXT:    [[TMP5:%.*]] = load i32, ptr [[TMP3]], align 4
; CHECK-NEXT:    store i32 [[TMP5]], ptr [[TMP4]], align 4
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(8) %a, ptr noundef nonnull align 1 dereferenceable(8) %b, i32 8, i1 false)
  ret void
}

define void @test_srcunalign_dst8_constant_size_9(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_srcunalign_dst8_constant_size_9(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = getelementptr i8, ptr [[B]], i32 0
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[A]], i32 0
; CHECK-NEXT:    [[TMP2:%.*]] = load i32, ptr [[TMP0]], align 4
; CHECK-NEXT:    store i32 [[TMP2]], ptr [[TMP1]], align 4
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[B]], i32 4
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[A]], i32 4
; CHECK-NEXT:    [[TMP5:%.*]] = load i32, ptr [[TMP3]], align 4
; CHECK-NEXT:    store i32 [[TMP5]], ptr [[TMP4]], align 4
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[B]], i32 8
; CHECK-NEXT:    [[TMP7:%.*]] = getelementptr i8, ptr [[A]], i32 8
; CHECK-NEXT:    [[TMP8:%.*]] = load i8, ptr [[TMP6]], align 1
; CHECK-NEXT:    store i8 [[TMP8]], ptr [[TMP7]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(9) %a, ptr noundef nonnull align 1 dereferenceable(9) %b, i32 9, i1 false)
  ret void
}

define void @test_srcunalign_dst8_constant_size_10(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_srcunalign_dst8_constant_size_10(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = getelementptr i8, ptr [[B]], i32 0
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[A]], i32 0
; CHECK-NEXT:    [[TMP2:%.*]] = load i32, ptr [[TMP0]], align 4
; CHECK-NEXT:    store i32 [[TMP2]], ptr [[TMP1]], align 4
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[B]], i32 4
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[A]], i32 4
; CHECK-NEXT:    [[TMP5:%.*]] = load i32, ptr [[TMP3]], align 4
; CHECK-NEXT:    store i32 [[TMP5]], ptr [[TMP4]], align 4
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[B]], i32 8
; CHECK-NEXT:    [[TMP7:%.*]] = getelementptr i8, ptr [[A]], i32 8
; CHECK-NEXT:    [[TMP8:%.*]] = load i16, ptr [[TMP6]], align 2
; CHECK-NEXT:    store i16 [[TMP8]], ptr [[TMP7]], align 2
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(10) %a, ptr noundef nonnull align 1 dereferenceable(10) %b, i32 10, i1 false)
  ret void
}

define void @test_srcunalign_dst8_constant_size_11(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_srcunalign_dst8_constant_size_11(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = getelementptr i8, ptr [[B]], i32 0
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[A]], i32 0
; CHECK-NEXT:    [[TMP2:%.*]] = load i32, ptr [[TMP0]], align 4
; CHECK-NEXT:    store i32 [[TMP2]], ptr [[TMP1]], align 4
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[B]], i32 4
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[A]], i32 4
; CHECK-NEXT:    [[TMP5:%.*]] = load i32, ptr [[TMP3]], align 4
; CHECK-NEXT:    store i32 [[TMP5]], ptr [[TMP4]], align 4
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[B]], i32 8
; CHECK-NEXT:    [[TMP7:%.*]] = getelementptr i8, ptr [[A]], i32 8
; CHECK-NEXT:    [[TMP8:%.*]] = load i16, ptr [[TMP6]], align 2
; CHECK-NEXT:    store i16 [[TMP8]], ptr [[TMP7]], align 2
; CHECK-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[B]], i32 10
; CHECK-NEXT:    [[TMP10:%.*]] = getelementptr i8, ptr [[A]], i32 10
; CHECK-NEXT:    [[TMP11:%.*]] = load i8, ptr [[TMP9]], align 1
; CHECK-NEXT:    store i8 [[TMP11]], ptr [[TMP10]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(11) %a, ptr noundef nonnull align 1 dereferenceable(11) %b, i32 11, i1 false)
  ret void
}

define void @test_srcunalign_dst8_constant_size_12(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_srcunalign_dst8_constant_size_12(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = getelementptr i8, ptr [[B]], i32 0
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[A]], i32 0
; CHECK-NEXT:    [[TMP2:%.*]] = load i32, ptr [[TMP0]], align 4
; CHECK-NEXT:    store i32 [[TMP2]], ptr [[TMP1]], align 4
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[B]], i32 4
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[A]], i32 4
; CHECK-NEXT:    [[TMP5:%.*]] = load i32, ptr [[TMP3]], align 4
; CHECK-NEXT:    store i32 [[TMP5]], ptr [[TMP4]], align 4
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[B]], i32 8
; CHECK-NEXT:    [[TMP7:%.*]] = getelementptr i8, ptr [[A]], i32 8
; CHECK-NEXT:    [[TMP8:%.*]] = load i32, ptr [[TMP6]], align 4
; CHECK-NEXT:    store i32 [[TMP8]], ptr [[TMP7]], align 4
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(12) %a, ptr noundef nonnull align 1 dereferenceable(12) %b, i32 12, i1 false)
  ret void
}

define void @test_srcunalign_dst8_constant_size_13(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_srcunalign_dst8_constant_size_13(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = getelementptr i8, ptr [[B]], i32 0
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[A]], i32 0
; CHECK-NEXT:    [[TMP2:%.*]] = load i32, ptr [[TMP0]], align 4
; CHECK-NEXT:    store i32 [[TMP2]], ptr [[TMP1]], align 4
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[B]], i32 4
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[A]], i32 4
; CHECK-NEXT:    [[TMP5:%.*]] = load i32, ptr [[TMP3]], align 4
; CHECK-NEXT:    store i32 [[TMP5]], ptr [[TMP4]], align 4
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[B]], i32 8
; CHECK-NEXT:    [[TMP7:%.*]] = getelementptr i8, ptr [[A]], i32 8
; CHECK-NEXT:    [[TMP8:%.*]] = load i32, ptr [[TMP6]], align 4
; CHECK-NEXT:    store i32 [[TMP8]], ptr [[TMP7]], align 4
; CHECK-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[B]], i32 12
; CHECK-NEXT:    [[TMP10:%.*]] = getelementptr i8, ptr [[A]], i32 12
; CHECK-NEXT:    [[TMP11:%.*]] = load i8, ptr [[TMP9]], align 1
; CHECK-NEXT:    store i8 [[TMP11]], ptr [[TMP10]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(13) %a, ptr noundef nonnull align 1 dereferenceable(13) %b, i32 13, i1 false)
  ret void
}

define void @test_srcunalign_dst8_constant_size_14(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_srcunalign_dst8_constant_size_14(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = getelementptr i8, ptr [[B]], i32 0
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[A]], i32 0
; CHECK-NEXT:    [[TMP2:%.*]] = load i32, ptr [[TMP0]], align 4
; CHECK-NEXT:    store i32 [[TMP2]], ptr [[TMP1]], align 4
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[B]], i32 4
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[A]], i32 4
; CHECK-NEXT:    [[TMP5:%.*]] = load i32, ptr [[TMP3]], align 4
; CHECK-NEXT:    store i32 [[TMP5]], ptr [[TMP4]], align 4
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[B]], i32 8
; CHECK-NEXT:    [[TMP7:%.*]] = getelementptr i8, ptr [[A]], i32 8
; CHECK-NEXT:    [[TMP8:%.*]] = load i32, ptr [[TMP6]], align 4
; CHECK-NEXT:    store i32 [[TMP8]], ptr [[TMP7]], align 4
; CHECK-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[B]], i32 12
; CHECK-NEXT:    [[TMP10:%.*]] = getelementptr i8, ptr [[A]], i32 12
; CHECK-NEXT:    [[TMP11:%.*]] = load i16, ptr [[TMP9]], align 2
; CHECK-NEXT:    store i16 [[TMP11]], ptr [[TMP10]], align 2
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(14) %a, ptr noundef nonnull align 1 dereferenceable(14) %b, i32 14, i1 false)
  ret void
}

define void @test_srcunalign_dst8_constant_size_15(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_srcunalign_dst8_constant_size_15(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = getelementptr i8, ptr [[B]], i32 0
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[A]], i32 0
; CHECK-NEXT:    [[TMP2:%.*]] = load i32, ptr [[TMP0]], align 4
; CHECK-NEXT:    store i32 [[TMP2]], ptr [[TMP1]], align 4
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[B]], i32 4
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[A]], i32 4
; CHECK-NEXT:    [[TMP5:%.*]] = load i32, ptr [[TMP3]], align 4
; CHECK-NEXT:    store i32 [[TMP5]], ptr [[TMP4]], align 4
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[B]], i32 8
; CHECK-NEXT:    [[TMP7:%.*]] = getelementptr i8, ptr [[A]], i32 8
; CHECK-NEXT:    [[TMP8:%.*]] = load i32, ptr [[TMP6]], align 4
; CHECK-NEXT:    store i32 [[TMP8]], ptr [[TMP7]], align 4
; CHECK-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[B]], i32 12
; CHECK-NEXT:    [[TMP10:%.*]] = getelementptr i8, ptr [[A]], i32 12
; CHECK-NEXT:    [[TMP11:%.*]] = load i16, ptr [[TMP9]], align 2
; CHECK-NEXT:    store i16 [[TMP11]], ptr [[TMP10]], align 2
; CHECK-NEXT:    [[TMP12:%.*]] = getelementptr i8, ptr [[B]], i32 14
; CHECK-NEXT:    [[TMP13:%.*]] = getelementptr i8, ptr [[A]], i32 14
; CHECK-NEXT:    [[TMP14:%.*]] = load i8, ptr [[TMP12]], align 1
; CHECK-NEXT:    store i8 [[TMP14]], ptr [[TMP13]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(15) %a, ptr noundef nonnull align 1 dereferenceable(15) %b, i32 15, i1 false)
  ret void
}

define void @test_srcunalign_dst8_constant_size_16(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_srcunalign_dst8_constant_size_16(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = load i64, ptr [[B]], align 1
; CHECK-NEXT:    store i64 [[TMP0]], ptr [[A]], align 1
; CHECK-NEXT:    [[ADD_PTR1_I:%.*]] = getelementptr i8, ptr [[A]], i32 8
; CHECK-NEXT:    [[ADD_PTR_I:%.*]] = getelementptr i8, ptr [[B]], i32 8
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[ADD_PTR_I]], i32 0
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[ADD_PTR1_I]], i32 0
; CHECK-NEXT:    [[TMP3:%.*]] = load i32, ptr [[TMP1]], align 4
; CHECK-NEXT:    store i32 [[TMP3]], ptr [[TMP2]], align 4
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[ADD_PTR_I]], i32 4
; CHECK-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[ADD_PTR1_I]], i32 4
; CHECK-NEXT:    [[TMP6:%.*]] = load i32, ptr [[TMP4]], align 4
; CHECK-NEXT:    store i32 [[TMP6]], ptr [[TMP5]], align 4
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(16) %a, ptr noundef nonnull align 1 dereferenceable(16) %b, i32 16, i1 false)
  ret void
}

define void @test_srcunalign_dst8_constant_size_17(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_srcunalign_dst8_constant_size_17(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = load i64, ptr [[B]], align 1
; CHECK-NEXT:    store i64 [[TMP0]], ptr [[A]], align 1
; CHECK-NEXT:    [[ADD_PTR1_I:%.*]] = getelementptr i8, ptr [[A]], i32 8
; CHECK-NEXT:    [[ADD_PTR_I:%.*]] = getelementptr i8, ptr [[B]], i32 8
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[ADD_PTR_I]], i32 0
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[ADD_PTR1_I]], i32 0
; CHECK-NEXT:    [[TMP3:%.*]] = load i32, ptr [[TMP1]], align 4
; CHECK-NEXT:    store i32 [[TMP3]], ptr [[TMP2]], align 4
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[ADD_PTR_I]], i32 4
; CHECK-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[ADD_PTR1_I]], i32 4
; CHECK-NEXT:    [[TMP6:%.*]] = load i32, ptr [[TMP4]], align 4
; CHECK-NEXT:    store i32 [[TMP6]], ptr [[TMP5]], align 4
; CHECK-NEXT:    [[TMP7:%.*]] = getelementptr i8, ptr [[B]], i64 16
; CHECK-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[A]], i64 16
; CHECK-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[TMP7]], i32 0
; CHECK-NEXT:    [[TMP10:%.*]] = getelementptr i8, ptr [[TMP8]], i32 0
; CHECK-NEXT:    [[TMP11:%.*]] = load i8, ptr [[TMP9]], align 1
; CHECK-NEXT:    store i8 [[TMP11]], ptr [[TMP10]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(17) %a, ptr noundef nonnull align 1 dereferenceable(17) %b, i32 17, i1 false)
  ret void
}

define void @test_srcunalign_dst8_constant_size_31(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_srcunalign_dst8_constant_size_31(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = load i64, ptr [[B]], align 1
; CHECK-NEXT:    store i64 [[TMP0]], ptr [[A]], align 1
; CHECK-NEXT:    [[ADD_PTR1_I:%.*]] = getelementptr i8, ptr [[A]], i32 8
; CHECK-NEXT:    [[ADD_PTR_I:%.*]] = getelementptr i8, ptr [[B]], i32 8
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[ADD_PTR_I]], i32 0
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[ADD_PTR1_I]], i32 0
; CHECK-NEXT:    [[TMP3:%.*]] = load i32, ptr [[TMP1]], align 4
; CHECK-NEXT:    store i32 [[TMP3]], ptr [[TMP2]], align 4
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[ADD_PTR_I]], i32 4
; CHECK-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[ADD_PTR1_I]], i32 4
; CHECK-NEXT:    [[TMP6:%.*]] = load i32, ptr [[TMP4]], align 4
; CHECK-NEXT:    store i32 [[TMP6]], ptr [[TMP5]], align 4
; CHECK-NEXT:    [[TMP7:%.*]] = getelementptr i8, ptr [[B]], i64 16
; CHECK-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[A]], i64 16
; CHECK-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[TMP7]], i32 0
; CHECK-NEXT:    [[TMP10:%.*]] = getelementptr i8, ptr [[TMP8]], i32 0
; CHECK-NEXT:    [[TMP11:%.*]] = load i32, ptr [[TMP9]], align 4
; CHECK-NEXT:    store i32 [[TMP11]], ptr [[TMP10]], align 4
; CHECK-NEXT:    [[TMP12:%.*]] = getelementptr i8, ptr [[TMP7]], i32 4
; CHECK-NEXT:    [[TMP13:%.*]] = getelementptr i8, ptr [[TMP8]], i32 4
; CHECK-NEXT:    [[TMP14:%.*]] = load i32, ptr [[TMP12]], align 4
; CHECK-NEXT:    store i32 [[TMP14]], ptr [[TMP13]], align 4
; CHECK-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[TMP7]], i32 8
; CHECK-NEXT:    [[TMP16:%.*]] = getelementptr i8, ptr [[TMP8]], i32 8
; CHECK-NEXT:    [[TMP17:%.*]] = load i32, ptr [[TMP15]], align 4
; CHECK-NEXT:    store i32 [[TMP17]], ptr [[TMP16]], align 4
; CHECK-NEXT:    [[TMP18:%.*]] = getelementptr i8, ptr [[TMP7]], i32 12
; CHECK-NEXT:    [[TMP19:%.*]] = getelementptr i8, ptr [[TMP8]], i32 12
; CHECK-NEXT:    [[TMP20:%.*]] = load i16, ptr [[TMP18]], align 2
; CHECK-NEXT:    store i16 [[TMP20]], ptr [[TMP19]], align 2
; CHECK-NEXT:    [[TMP21:%.*]] = getelementptr i8, ptr [[TMP7]], i32 14
; CHECK-NEXT:    [[TMP22:%.*]] = getelementptr i8, ptr [[TMP8]], i32 14
; CHECK-NEXT:    [[TMP23:%.*]] = load i8, ptr [[TMP21]], align 1
; CHECK-NEXT:    store i8 [[TMP23]], ptr [[TMP22]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(31) %a, ptr noundef nonnull align 1 dereferenceable(31) %b, i32 31, i1 false)
  ret void
}

define void @test_srcunalign_dst8_constant_size_32(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_srcunalign_dst8_constant_size_32(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = load i64, ptr [[B]], align 1
; CHECK-NEXT:    store i64 [[TMP0]], ptr [[A]], align 1
; CHECK-NEXT:    [[ADD_PTR1_I:%.*]] = getelementptr i8, ptr [[A]], i32 8
; CHECK-NEXT:    [[ADD_PTR_I:%.*]] = getelementptr i8, ptr [[B]], i32 8
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[ADD_PTR_I]] to i32
; CHECK-NEXT:    [[TMP2:%.*]] = ptrtoint ptr [[ADD_PTR1_I]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.ld.128.usar.ip q0, $0, 16", "+{a1}"(i32 [[TMP1]]) #[[ATTR2]]
; CHECK-NEXT:    call void asm sideeffect "esp.ld.128.usar.ip q1, $0, 16", "+{a1}"(i32 [[TMP1]]) #[[ATTR2]]
; CHECK-NEXT:    call void asm sideeffect "esp.src.q q0, q0, q1", ""() #[[ATTR2]]
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q0, $0, 16", "+{a0}"(i32 [[TMP2]]) #[[ATTR2]]
; CHECK-NEXT:    call void @esp32p4MemCpySrcUnalignedDstUnalignedVarFrom0To15Opt(ptr [[ADD_PTR1_I]], ptr [[ADD_PTR_I]], i32 0)
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[ADD_PTR_I]], i64 16
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[ADD_PTR1_I]], i64 16
; CHECK-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[TMP3]], i32 0
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[TMP4]], i32 0
; CHECK-NEXT:    [[TMP7:%.*]] = load i32, ptr [[TMP5]], align 4
; CHECK-NEXT:    store i32 [[TMP7]], ptr [[TMP6]], align 4
; CHECK-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[TMP3]], i32 4
; CHECK-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[TMP4]], i32 4
; CHECK-NEXT:    [[TMP10:%.*]] = load i32, ptr [[TMP8]], align 4
; CHECK-NEXT:    store i32 [[TMP10]], ptr [[TMP9]], align 4
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(32) %a, ptr noundef nonnull align 1 dereferenceable(32) %b, i32 32, i1 false)
  ret void
}

define void @test_srcunalign_dst8_constant_size_33(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_srcunalign_dst8_constant_size_33(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = load i64, ptr [[B]], align 1
; CHECK-NEXT:    store i64 [[TMP0]], ptr [[A]], align 1
; CHECK-NEXT:    [[ADD_PTR1_I:%.*]] = getelementptr i8, ptr [[A]], i32 8
; CHECK-NEXT:    [[ADD_PTR_I:%.*]] = getelementptr i8, ptr [[B]], i32 8
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[ADD_PTR_I]] to i32
; CHECK-NEXT:    [[TMP2:%.*]] = ptrtoint ptr [[ADD_PTR1_I]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.ld.128.usar.ip q0, $0, 16", "+{a1}"(i32 [[TMP1]]) #[[ATTR2]]
; CHECK-NEXT:    call void asm sideeffect "esp.ld.128.usar.ip q1, $0, 16", "+{a1}"(i32 [[TMP1]]) #[[ATTR2]]
; CHECK-NEXT:    call void asm sideeffect "esp.src.q q0, q0, q1", ""() #[[ATTR2]]
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q0, $0, 16", "+{a0}"(i32 [[TMP2]]) #[[ATTR2]]
; CHECK-NEXT:    call void @esp32p4MemCpySrcUnalignedDstUnalignedVarFrom0To15Opt(ptr [[ADD_PTR1_I]], ptr [[ADD_PTR_I]], i32 0)
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[ADD_PTR_I]], i64 16
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[ADD_PTR1_I]], i64 16
; CHECK-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[TMP3]], i32 0
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[TMP4]], i32 0
; CHECK-NEXT:    [[TMP7:%.*]] = load i32, ptr [[TMP5]], align 4
; CHECK-NEXT:    store i32 [[TMP7]], ptr [[TMP6]], align 4
; CHECK-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[TMP3]], i32 4
; CHECK-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[TMP4]], i32 4
; CHECK-NEXT:    [[TMP10:%.*]] = load i32, ptr [[TMP8]], align 4
; CHECK-NEXT:    store i32 [[TMP10]], ptr [[TMP9]], align 4
; CHECK-NEXT:    [[TMP11:%.*]] = getelementptr i8, ptr [[B]], i64 32
; CHECK-NEXT:    [[TMP12:%.*]] = getelementptr i8, ptr [[A]], i64 32
; CHECK-NEXT:    [[TMP13:%.*]] = getelementptr i8, ptr [[TMP11]], i32 0
; CHECK-NEXT:    [[TMP14:%.*]] = getelementptr i8, ptr [[TMP12]], i32 0
; CHECK-NEXT:    [[TMP15:%.*]] = load i8, ptr [[TMP13]], align 1
; CHECK-NEXT:    store i8 [[TMP15]], ptr [[TMP14]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(33) %a, ptr noundef nonnull align 1 dereferenceable(33) %b, i32 33, i1 false)
  ret void
}

define void @test_srcunalign_dst8_constant_size_47(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_srcunalign_dst8_constant_size_47(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = load i64, ptr [[B]], align 1
; CHECK-NEXT:    store i64 [[TMP0]], ptr [[A]], align 1
; CHECK-NEXT:    [[ADD_PTR1_I:%.*]] = getelementptr i8, ptr [[A]], i32 8
; CHECK-NEXT:    [[ADD_PTR_I:%.*]] = getelementptr i8, ptr [[B]], i32 8
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[ADD_PTR_I]] to i32
; CHECK-NEXT:    [[TMP2:%.*]] = ptrtoint ptr [[ADD_PTR1_I]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.ld.128.usar.ip q0, $0, 16", "+{a1}"(i32 [[TMP1]]) #[[ATTR2]]
; CHECK-NEXT:    call void asm sideeffect "esp.ld.128.usar.ip q1, $0, 16", "+{a1}"(i32 [[TMP1]]) #[[ATTR2]]
; CHECK-NEXT:    call void asm sideeffect "esp.src.q q0, q0, q1", ""() #[[ATTR2]]
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q0, $0, 16", "+{a0}"(i32 [[TMP2]]) #[[ATTR2]]
; CHECK-NEXT:    call void @esp32p4MemCpySrcUnalignedDstUnalignedVarFrom0To15Opt(ptr [[ADD_PTR1_I]], ptr [[ADD_PTR_I]], i32 0)
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[ADD_PTR_I]], i64 16
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[ADD_PTR1_I]], i64 16
; CHECK-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[TMP3]], i32 0
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[TMP4]], i32 0
; CHECK-NEXT:    [[TMP7:%.*]] = load i32, ptr [[TMP5]], align 4
; CHECK-NEXT:    store i32 [[TMP7]], ptr [[TMP6]], align 4
; CHECK-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[TMP3]], i32 4
; CHECK-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[TMP4]], i32 4
; CHECK-NEXT:    [[TMP10:%.*]] = load i32, ptr [[TMP8]], align 4
; CHECK-NEXT:    store i32 [[TMP10]], ptr [[TMP9]], align 4
; CHECK-NEXT:    [[TMP11:%.*]] = getelementptr i8, ptr [[B]], i64 32
; CHECK-NEXT:    [[TMP12:%.*]] = getelementptr i8, ptr [[A]], i64 32
; CHECK-NEXT:    [[TMP13:%.*]] = getelementptr i8, ptr [[TMP11]], i32 0
; CHECK-NEXT:    [[TMP14:%.*]] = getelementptr i8, ptr [[TMP12]], i32 0
; CHECK-NEXT:    [[TMP15:%.*]] = load i32, ptr [[TMP13]], align 4
; CHECK-NEXT:    store i32 [[TMP15]], ptr [[TMP14]], align 4
; CHECK-NEXT:    [[TMP16:%.*]] = getelementptr i8, ptr [[TMP11]], i32 4
; CHECK-NEXT:    [[TMP17:%.*]] = getelementptr i8, ptr [[TMP12]], i32 4
; CHECK-NEXT:    [[TMP18:%.*]] = load i32, ptr [[TMP16]], align 4
; CHECK-NEXT:    store i32 [[TMP18]], ptr [[TMP17]], align 4
; CHECK-NEXT:    [[TMP19:%.*]] = getelementptr i8, ptr [[TMP11]], i32 8
; CHECK-NEXT:    [[TMP20:%.*]] = getelementptr i8, ptr [[TMP12]], i32 8
; CHECK-NEXT:    [[TMP21:%.*]] = load i32, ptr [[TMP19]], align 4
; CHECK-NEXT:    store i32 [[TMP21]], ptr [[TMP20]], align 4
; CHECK-NEXT:    [[TMP22:%.*]] = getelementptr i8, ptr [[TMP11]], i32 12
; CHECK-NEXT:    [[TMP23:%.*]] = getelementptr i8, ptr [[TMP12]], i32 12
; CHECK-NEXT:    [[TMP24:%.*]] = load i16, ptr [[TMP22]], align 2
; CHECK-NEXT:    store i16 [[TMP24]], ptr [[TMP23]], align 2
; CHECK-NEXT:    [[TMP25:%.*]] = getelementptr i8, ptr [[TMP11]], i32 14
; CHECK-NEXT:    [[TMP26:%.*]] = getelementptr i8, ptr [[TMP12]], i32 14
; CHECK-NEXT:    [[TMP27:%.*]] = load i8, ptr [[TMP25]], align 1
; CHECK-NEXT:    store i8 [[TMP27]], ptr [[TMP26]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(47) %a, ptr noundef nonnull align 1 dereferenceable(47) %b, i32 47, i1 false)
  ret void
}

define void @test_srcunalign_dst8_constant_size_48(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_srcunalign_dst8_constant_size_48(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = load i64, ptr [[B]], align 1
; CHECK-NEXT:    store i64 [[TMP0]], ptr [[A]], align 1
; CHECK-NEXT:    [[ADD_PTR1_I:%.*]] = getelementptr i8, ptr [[A]], i32 8
; CHECK-NEXT:    [[ADD_PTR_I:%.*]] = getelementptr i8, ptr [[B]], i32 8
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[ADD_PTR_I]] to i32
; CHECK-NEXT:    [[TMP2:%.*]] = ptrtoint ptr [[ADD_PTR1_I]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.ld.128.usar.ip q0, $0, 16", "+{a1}"(i32 [[TMP1]]) #[[ATTR2]]
; CHECK-NEXT:    call void asm sideeffect "esp.ld.128.usar.ip q1, $0, 16", "+{a1}"(i32 [[TMP1]]) #[[ATTR2]]
; CHECK-NEXT:    call void asm sideeffect "esp.src.q.ld.ip q2, $0, 0, q0, q1", "+{a1}"(i32 [[TMP1]]) #[[ATTR2]]
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q0, $0, 16", "+{a0}"(i32 [[TMP2]]) #[[ATTR2]]
; CHECK-NEXT:    call void asm sideeffect "esp.src.q q1, q1, q2", ""() #[[ATTR2]]
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q1, $0, 16", "+{a0}"(i32 [[TMP2]]) #[[ATTR2]]
; CHECK-NEXT:    call void @esp32p4MemCpySrcUnalignedDstUnalignedVarFrom0To15Opt(ptr [[ADD_PTR1_I]], ptr [[ADD_PTR_I]], i32 0)
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[ADD_PTR_I]], i64 32
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[ADD_PTR1_I]], i64 32
; CHECK-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[TMP3]], i32 0
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[TMP4]], i32 0
; CHECK-NEXT:    [[TMP7:%.*]] = load i32, ptr [[TMP5]], align 4
; CHECK-NEXT:    store i32 [[TMP7]], ptr [[TMP6]], align 4
; CHECK-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[TMP3]], i32 4
; CHECK-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[TMP4]], i32 4
; CHECK-NEXT:    [[TMP10:%.*]] = load i32, ptr [[TMP8]], align 4
; CHECK-NEXT:    store i32 [[TMP10]], ptr [[TMP9]], align 4
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(48) %a, ptr noundef nonnull align 1 dereferenceable(48) %b, i32 48, i1 false)
  ret void
}

define void @test_srcunalign_dst8_constant_size_49(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_srcunalign_dst8_constant_size_49(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = load i64, ptr [[B]], align 1
; CHECK-NEXT:    store i64 [[TMP0]], ptr [[A]], align 1
; CHECK-NEXT:    [[ADD_PTR1_I:%.*]] = getelementptr i8, ptr [[A]], i32 8
; CHECK-NEXT:    [[ADD_PTR_I:%.*]] = getelementptr i8, ptr [[B]], i32 8
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[ADD_PTR_I]] to i32
; CHECK-NEXT:    [[TMP2:%.*]] = ptrtoint ptr [[ADD_PTR1_I]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.ld.128.usar.ip q0, $0, 16", "+{a1}"(i32 [[TMP1]]) #[[ATTR2]]
; CHECK-NEXT:    call void asm sideeffect "esp.ld.128.usar.ip q1, $0, 16", "+{a1}"(i32 [[TMP1]]) #[[ATTR2]]
; CHECK-NEXT:    call void asm sideeffect "esp.src.q.ld.ip q2, $0, 0, q0, q1", "+{a1}"(i32 [[TMP1]]) #[[ATTR2]]
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q0, $0, 16", "+{a0}"(i32 [[TMP2]]) #[[ATTR2]]
; CHECK-NEXT:    call void asm sideeffect "esp.src.q q1, q1, q2", ""() #[[ATTR2]]
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q1, $0, 16", "+{a0}"(i32 [[TMP2]]) #[[ATTR2]]
; CHECK-NEXT:    call void @esp32p4MemCpySrcUnalignedDstUnalignedVarFrom0To15Opt(ptr [[ADD_PTR1_I]], ptr [[ADD_PTR_I]], i32 0)
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[ADD_PTR_I]], i64 32
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[ADD_PTR1_I]], i64 32
; CHECK-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[TMP3]], i32 0
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[TMP4]], i32 0
; CHECK-NEXT:    [[TMP7:%.*]] = load i32, ptr [[TMP5]], align 4
; CHECK-NEXT:    store i32 [[TMP7]], ptr [[TMP6]], align 4
; CHECK-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[TMP3]], i32 4
; CHECK-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[TMP4]], i32 4
; CHECK-NEXT:    [[TMP10:%.*]] = load i32, ptr [[TMP8]], align 4
; CHECK-NEXT:    store i32 [[TMP10]], ptr [[TMP9]], align 4
; CHECK-NEXT:    [[TMP11:%.*]] = getelementptr i8, ptr [[B]], i64 48
; CHECK-NEXT:    [[TMP12:%.*]] = getelementptr i8, ptr [[A]], i64 48
; CHECK-NEXT:    [[TMP13:%.*]] = getelementptr i8, ptr [[TMP11]], i32 0
; CHECK-NEXT:    [[TMP14:%.*]] = getelementptr i8, ptr [[TMP12]], i32 0
; CHECK-NEXT:    [[TMP15:%.*]] = load i8, ptr [[TMP13]], align 1
; CHECK-NEXT:    store i8 [[TMP15]], ptr [[TMP14]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(49) %a, ptr noundef nonnull align 1 dereferenceable(49) %b, i32 49, i1 false)
  ret void
}

define void @test_srcunalign_dst8_constant_size_63(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_srcunalign_dst8_constant_size_63(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = load i64, ptr [[B]], align 1
; CHECK-NEXT:    store i64 [[TMP0]], ptr [[A]], align 1
; CHECK-NEXT:    [[ADD_PTR1_I:%.*]] = getelementptr i8, ptr [[A]], i32 8
; CHECK-NEXT:    [[ADD_PTR_I:%.*]] = getelementptr i8, ptr [[B]], i32 8
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[ADD_PTR_I]] to i32
; CHECK-NEXT:    [[TMP2:%.*]] = ptrtoint ptr [[ADD_PTR1_I]] to i32
; CHECK-NEXT:    call void asm sideeffect "esp.ld.128.usar.ip q0, $0, 16", "+{a1}"(i32 [[TMP1]]) #[[ATTR2]]
; CHECK-NEXT:    call void asm sideeffect "esp.ld.128.usar.ip q1, $0, 16", "+{a1}"(i32 [[TMP1]]) #[[ATTR2]]
; CHECK-NEXT:    call void asm sideeffect "esp.src.q.ld.ip q2, $0, 0, q0, q1", "+{a1}"(i32 [[TMP1]]) #[[ATTR2]]
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q0, $0, 16", "+{a0}"(i32 [[TMP2]]) #[[ATTR2]]
; CHECK-NEXT:    call void asm sideeffect "esp.src.q q1, q1, q2", ""() #[[ATTR2]]
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q1, $0, 16", "+{a0}"(i32 [[TMP2]]) #[[ATTR2]]
; CHECK-NEXT:    call void @esp32p4MemCpySrcUnalignedDstUnalignedVarFrom0To15Opt(ptr [[ADD_PTR1_I]], ptr [[ADD_PTR_I]], i32 0)
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[ADD_PTR_I]], i64 32
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[ADD_PTR1_I]], i64 32
; CHECK-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[TMP3]], i32 0
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[TMP4]], i32 0
; CHECK-NEXT:    [[TMP7:%.*]] = load i32, ptr [[TMP5]], align 4
; CHECK-NEXT:    store i32 [[TMP7]], ptr [[TMP6]], align 4
; CHECK-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[TMP3]], i32 4
; CHECK-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[TMP4]], i32 4
; CHECK-NEXT:    [[TMP10:%.*]] = load i32, ptr [[TMP8]], align 4
; CHECK-NEXT:    store i32 [[TMP10]], ptr [[TMP9]], align 4
; CHECK-NEXT:    [[TMP11:%.*]] = getelementptr i8, ptr [[B]], i64 48
; CHECK-NEXT:    [[TMP12:%.*]] = getelementptr i8, ptr [[A]], i64 48
; CHECK-NEXT:    [[TMP13:%.*]] = getelementptr i8, ptr [[TMP11]], i32 0
; CHECK-NEXT:    [[TMP14:%.*]] = getelementptr i8, ptr [[TMP12]], i32 0
; CHECK-NEXT:    [[TMP15:%.*]] = load i32, ptr [[TMP13]], align 4
; CHECK-NEXT:    store i32 [[TMP15]], ptr [[TMP14]], align 4
; CHECK-NEXT:    [[TMP16:%.*]] = getelementptr i8, ptr [[TMP11]], i32 4
; CHECK-NEXT:    [[TMP17:%.*]] = getelementptr i8, ptr [[TMP12]], i32 4
; CHECK-NEXT:    [[TMP18:%.*]] = load i32, ptr [[TMP16]], align 4
; CHECK-NEXT:    store i32 [[TMP18]], ptr [[TMP17]], align 4
; CHECK-NEXT:    [[TMP19:%.*]] = getelementptr i8, ptr [[TMP11]], i32 8
; CHECK-NEXT:    [[TMP20:%.*]] = getelementptr i8, ptr [[TMP12]], i32 8
; CHECK-NEXT:    [[TMP21:%.*]] = load i32, ptr [[TMP19]], align 4
; CHECK-NEXT:    store i32 [[TMP21]], ptr [[TMP20]], align 4
; CHECK-NEXT:    [[TMP22:%.*]] = getelementptr i8, ptr [[TMP11]], i32 12
; CHECK-NEXT:    [[TMP23:%.*]] = getelementptr i8, ptr [[TMP12]], i32 12
; CHECK-NEXT:    [[TMP24:%.*]] = load i16, ptr [[TMP22]], align 2
; CHECK-NEXT:    store i16 [[TMP24]], ptr [[TMP23]], align 2
; CHECK-NEXT:    [[TMP25:%.*]] = getelementptr i8, ptr [[TMP11]], i32 14
; CHECK-NEXT:    [[TMP26:%.*]] = getelementptr i8, ptr [[TMP12]], i32 14
; CHECK-NEXT:    [[TMP27:%.*]] = load i8, ptr [[TMP25]], align 1
; CHECK-NEXT:    store i8 [[TMP27]], ptr [[TMP26]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(63) %a, ptr noundef nonnull align 1 dereferenceable(63) %b, i32 63, i1 false)
  ret void
}

define void @test_srcunalign_dst8_constant_size_64(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_srcunalign_dst8_constant_size_64(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = load i64, ptr [[B]], align 1
; CHECK-NEXT:    store i64 [[TMP0]], ptr [[A]], align 1
; CHECK-NEXT:    [[ADD_PTR1_I:%.*]] = getelementptr i8, ptr [[A]], i32 8
; CHECK-NEXT:    [[ADD_PTR_I:%.*]] = getelementptr i8, ptr [[B]], i32 8
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[ADD_PTR_I]] to i32
; CHECK-NEXT:    [[TMP2:%.*]] = ptrtoint ptr [[ADD_PTR1_I]] to i32
; CHECK-NEXT:    tail call void @esp32p4MemCpySrcunalignedDst16Div48Index6(i32 [[TMP2]], i32 [[TMP1]])
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[ADD_PTR_I]], i64 48
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[ADD_PTR1_I]], i64 48
; CHECK-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[TMP3]], i32 0
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[TMP4]], i32 0
; CHECK-NEXT:    [[TMP7:%.*]] = load i32, ptr [[TMP5]], align 4
; CHECK-NEXT:    store i32 [[TMP7]], ptr [[TMP6]], align 4
; CHECK-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[TMP3]], i32 4
; CHECK-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[TMP4]], i32 4
; CHECK-NEXT:    [[TMP10:%.*]] = load i32, ptr [[TMP8]], align 4
; CHECK-NEXT:    store i32 [[TMP10]], ptr [[TMP9]], align 4
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(64) %a, ptr noundef nonnull align 1 dereferenceable(64) %b, i32 64, i1 false)
  ret void
}

define void @test_srcunalign_dst8_constant_size_65(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_srcunalign_dst8_constant_size_65(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = load i64, ptr [[B]], align 1
; CHECK-NEXT:    store i64 [[TMP0]], ptr [[A]], align 1
; CHECK-NEXT:    [[ADD_PTR1_I:%.*]] = getelementptr i8, ptr [[A]], i32 8
; CHECK-NEXT:    [[ADD_PTR_I:%.*]] = getelementptr i8, ptr [[B]], i32 8
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[ADD_PTR_I]] to i32
; CHECK-NEXT:    [[TMP2:%.*]] = ptrtoint ptr [[ADD_PTR1_I]] to i32
; CHECK-NEXT:    tail call void @esp32p4MemCpySrcunalignedDst16Div48Index7(i32 [[TMP2]], i32 [[TMP1]])
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[ADD_PTR_I]], i64 48
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[ADD_PTR1_I]], i64 48
; CHECK-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[TMP3]], i32 0
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[TMP4]], i32 0
; CHECK-NEXT:    [[TMP7:%.*]] = load i32, ptr [[TMP5]], align 4
; CHECK-NEXT:    store i32 [[TMP7]], ptr [[TMP6]], align 4
; CHECK-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[TMP3]], i32 4
; CHECK-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[TMP4]], i32 4
; CHECK-NEXT:    [[TMP10:%.*]] = load i32, ptr [[TMP8]], align 4
; CHECK-NEXT:    store i32 [[TMP10]], ptr [[TMP9]], align 4
; CHECK-NEXT:    [[TMP11:%.*]] = getelementptr i8, ptr [[B]], i64 64
; CHECK-NEXT:    [[TMP12:%.*]] = getelementptr i8, ptr [[A]], i64 64
; CHECK-NEXT:    [[TMP13:%.*]] = getelementptr i8, ptr [[TMP11]], i32 0
; CHECK-NEXT:    [[TMP14:%.*]] = getelementptr i8, ptr [[TMP12]], i32 0
; CHECK-NEXT:    [[TMP15:%.*]] = load i8, ptr [[TMP13]], align 1
; CHECK-NEXT:    store i8 [[TMP15]], ptr [[TMP14]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(65) %a, ptr noundef nonnull align 1 dereferenceable(65) %b, i32 65, i1 false)
  ret void
}

define void @test_srcunalign_dst8_constant_size_80(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_srcunalign_dst8_constant_size_80(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = load i64, ptr [[B]], align 1
; CHECK-NEXT:    store i64 [[TMP0]], ptr [[A]], align 1
; CHECK-NEXT:    [[ADD_PTR1_I:%.*]] = getelementptr i8, ptr [[A]], i32 8
; CHECK-NEXT:    [[ADD_PTR_I:%.*]] = getelementptr i8, ptr [[B]], i32 8
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[ADD_PTR_I]] to i32
; CHECK-NEXT:    [[TMP2:%.*]] = ptrtoint ptr [[ADD_PTR1_I]] to i32
; CHECK-NEXT:    tail call void @esp32p4MemCpySrcunalignedDst16mod48From16to31.7(i32 [[TMP2]], i32 [[TMP1]])
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[ADD_PTR_I]], i64 64
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[ADD_PTR1_I]], i64 64
; CHECK-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[TMP3]], i32 0
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[TMP4]], i32 0
; CHECK-NEXT:    [[TMP7:%.*]] = load i32, ptr [[TMP5]], align 4
; CHECK-NEXT:    store i32 [[TMP7]], ptr [[TMP6]], align 4
; CHECK-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[TMP3]], i32 4
; CHECK-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[TMP4]], i32 4
; CHECK-NEXT:    [[TMP10:%.*]] = load i32, ptr [[TMP8]], align 4
; CHECK-NEXT:    store i32 [[TMP10]], ptr [[TMP9]], align 4
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(80) %a, ptr noundef nonnull align 1 dereferenceable(80) %b, i32 80, i1 false)
  ret void
}

define void @test_srcunalign_dst8_constant_size_81(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_srcunalign_dst8_constant_size_81(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = load i64, ptr [[B]], align 1
; CHECK-NEXT:    store i64 [[TMP0]], ptr [[A]], align 1
; CHECK-NEXT:    [[ADD_PTR1_I:%.*]] = getelementptr i8, ptr [[A]], i32 8
; CHECK-NEXT:    [[ADD_PTR_I:%.*]] = getelementptr i8, ptr [[B]], i32 8
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[ADD_PTR_I]] to i32
; CHECK-NEXT:    [[TMP2:%.*]] = ptrtoint ptr [[ADD_PTR1_I]] to i32
; CHECK-NEXT:    tail call void @esp32p4MemCpySrcunalignedDst16mod48From16to31.8(i32 [[TMP2]], i32 [[TMP1]])
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[ADD_PTR_I]], i64 64
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[ADD_PTR1_I]], i64 64
; CHECK-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[TMP3]], i32 0
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[TMP4]], i32 0
; CHECK-NEXT:    [[TMP7:%.*]] = load i32, ptr [[TMP5]], align 4
; CHECK-NEXT:    store i32 [[TMP7]], ptr [[TMP6]], align 4
; CHECK-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[TMP3]], i32 4
; CHECK-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[TMP4]], i32 4
; CHECK-NEXT:    [[TMP10:%.*]] = load i32, ptr [[TMP8]], align 4
; CHECK-NEXT:    store i32 [[TMP10]], ptr [[TMP9]], align 4
; CHECK-NEXT:    [[TMP11:%.*]] = getelementptr i8, ptr [[B]], i64 80
; CHECK-NEXT:    [[TMP12:%.*]] = getelementptr i8, ptr [[A]], i64 80
; CHECK-NEXT:    [[TMP13:%.*]] = getelementptr i8, ptr [[TMP11]], i32 0
; CHECK-NEXT:    [[TMP14:%.*]] = getelementptr i8, ptr [[TMP12]], i32 0
; CHECK-NEXT:    [[TMP15:%.*]] = load i8, ptr [[TMP13]], align 1
; CHECK-NEXT:    store i8 [[TMP15]], ptr [[TMP14]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(81) %a, ptr noundef nonnull align 1 dereferenceable(81) %b, i32 81, i1 false)
  ret void
}

define void @test_srcunalign_dst8_constant_size_88(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_srcunalign_dst8_constant_size_88(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = getelementptr i8, ptr [[B]], i32 0
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[A]], i32 0
; CHECK-NEXT:    [[TMP2:%.*]] = load i32, ptr [[TMP0]], align 4
; CHECK-NEXT:    store i32 [[TMP2]], ptr [[TMP1]], align 4
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[B]], i32 4
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[A]], i32 4
; CHECK-NEXT:    [[TMP5:%.*]] = load i32, ptr [[TMP3]], align 4
; CHECK-NEXT:    store i32 [[TMP5]], ptr [[TMP4]], align 4
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[B]], i64 8
; CHECK-NEXT:    [[TMP7:%.*]] = getelementptr i8, ptr [[A]], i64 8
; CHECK-NEXT:    [[TMP8:%.*]] = ptrtoint ptr [[TMP6]] to i32
; CHECK-NEXT:    [[TMP9:%.*]] = ptrtoint ptr [[TMP7]] to i32
; CHECK-NEXT:    tail call void @esp32p4MemCpySrcunalignedDst16mod48From32To47Index5(i32 [[TMP9]], i32 [[TMP8]])
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(88) %a, ptr noundef nonnull align 1 dereferenceable(88) %b, i32 88, i1 false)
  ret void
}

define void @test_srcunalign_dst8_constant_size_96(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_srcunalign_dst8_constant_size_96(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = load i64, ptr [[B]], align 1
; CHECK-NEXT:    store i64 [[TMP0]], ptr [[A]], align 1
; CHECK-NEXT:    [[ADD_PTR1_I:%.*]] = getelementptr i8, ptr [[A]], i32 8
; CHECK-NEXT:    [[ADD_PTR_I:%.*]] = getelementptr i8, ptr [[B]], i32 8
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[ADD_PTR_I]] to i32
; CHECK-NEXT:    [[TMP2:%.*]] = ptrtoint ptr [[ADD_PTR1_I]] to i32
; CHECK-NEXT:    tail call void @esp32p4MemCpySrcunalignedDst16mod48From32To47Index6(i32 [[TMP2]], i32 [[TMP1]])
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[ADD_PTR_I]], i64 80
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[ADD_PTR1_I]], i64 80
; CHECK-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[TMP3]], i32 0
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[TMP4]], i32 0
; CHECK-NEXT:    [[TMP7:%.*]] = load i32, ptr [[TMP5]], align 4
; CHECK-NEXT:    store i32 [[TMP7]], ptr [[TMP6]], align 4
; CHECK-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[TMP3]], i32 4
; CHECK-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[TMP4]], i32 4
; CHECK-NEXT:    [[TMP10:%.*]] = load i32, ptr [[TMP8]], align 4
; CHECK-NEXT:    store i32 [[TMP10]], ptr [[TMP9]], align 4
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(96) %a, ptr noundef nonnull align 1 dereferenceable(96) %b, i32 96, i1 false)
  ret void
}

define void @test_srcunalign_dst8_constant_size_112(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_srcunalign_dst8_constant_size_112(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = load i64, ptr [[B]], align 1
; CHECK-NEXT:    store i64 [[TMP0]], ptr [[A]], align 1
; CHECK-NEXT:    [[ADD_PTR1_I:%.*]] = getelementptr i8, ptr [[A]], i32 8
; CHECK-NEXT:    [[ADD_PTR_I:%.*]] = getelementptr i8, ptr [[B]], i32 8
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[ADD_PTR_I]] to i32
; CHECK-NEXT:    [[TMP2:%.*]] = ptrtoint ptr [[ADD_PTR1_I]] to i32
; CHECK-NEXT:    tail call void @esp32p4MemCpySrcunalignedDst16Div48Index8(i32 [[TMP2]], i32 [[TMP1]])
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[ADD_PTR_I]], i64 96
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[ADD_PTR1_I]], i64 96
; CHECK-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[TMP3]], i32 0
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[TMP4]], i32 0
; CHECK-NEXT:    [[TMP7:%.*]] = load i32, ptr [[TMP5]], align 4
; CHECK-NEXT:    store i32 [[TMP7]], ptr [[TMP6]], align 4
; CHECK-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[TMP3]], i32 4
; CHECK-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[TMP4]], i32 4
; CHECK-NEXT:    [[TMP10:%.*]] = load i32, ptr [[TMP8]], align 4
; CHECK-NEXT:    store i32 [[TMP10]], ptr [[TMP9]], align 4
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(112) %a, ptr noundef nonnull align 1 dereferenceable(112) %b, i32 112, i1 false)
  ret void
}

define void @test_srcunalign_dst8_constant_size_124(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_srcunalign_dst8_constant_size_124(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = load i64, ptr [[B]], align 1
; CHECK-NEXT:    store i64 [[TMP0]], ptr [[A]], align 1
; CHECK-NEXT:    [[ADD_PTR1_I:%.*]] = getelementptr i8, ptr [[A]], i32 8
; CHECK-NEXT:    [[ADD_PTR_I:%.*]] = getelementptr i8, ptr [[B]], i32 8
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[ADD_PTR_I]] to i32
; CHECK-NEXT:    [[TMP2:%.*]] = ptrtoint ptr [[ADD_PTR1_I]] to i32
; CHECK-NEXT:    tail call void @esp32p4MemCpySrcunalignedDst16Div48Index9(i32 [[TMP2]], i32 [[TMP1]])
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[ADD_PTR_I]], i64 96
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[ADD_PTR1_I]], i64 96
; CHECK-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[TMP3]], i32 0
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[TMP4]], i32 0
; CHECK-NEXT:    [[TMP7:%.*]] = load i32, ptr [[TMP5]], align 4
; CHECK-NEXT:    store i32 [[TMP7]], ptr [[TMP6]], align 4
; CHECK-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[TMP3]], i32 4
; CHECK-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[TMP4]], i32 4
; CHECK-NEXT:    [[TMP10:%.*]] = load i32, ptr [[TMP8]], align 4
; CHECK-NEXT:    store i32 [[TMP10]], ptr [[TMP9]], align 4
; CHECK-NEXT:    [[TMP11:%.*]] = getelementptr i8, ptr [[B]], i64 112
; CHECK-NEXT:    [[TMP12:%.*]] = getelementptr i8, ptr [[A]], i64 112
; CHECK-NEXT:    [[TMP13:%.*]] = getelementptr i8, ptr [[TMP11]], i32 0
; CHECK-NEXT:    [[TMP14:%.*]] = getelementptr i8, ptr [[TMP12]], i32 0
; CHECK-NEXT:    [[TMP15:%.*]] = load i32, ptr [[TMP13]], align 4
; CHECK-NEXT:    store i32 [[TMP15]], ptr [[TMP14]], align 4
; CHECK-NEXT:    [[TMP16:%.*]] = getelementptr i8, ptr [[TMP11]], i32 4
; CHECK-NEXT:    [[TMP17:%.*]] = getelementptr i8, ptr [[TMP12]], i32 4
; CHECK-NEXT:    [[TMP18:%.*]] = load i32, ptr [[TMP16]], align 4
; CHECK-NEXT:    store i32 [[TMP18]], ptr [[TMP17]], align 4
; CHECK-NEXT:    [[TMP19:%.*]] = getelementptr i8, ptr [[TMP11]], i32 8
; CHECK-NEXT:    [[TMP20:%.*]] = getelementptr i8, ptr [[TMP12]], i32 8
; CHECK-NEXT:    [[TMP21:%.*]] = load i32, ptr [[TMP19]], align 4
; CHECK-NEXT:    store i32 [[TMP21]], ptr [[TMP20]], align 4
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(124) %a, ptr noundef nonnull align 1 dereferenceable(124) %b, i32 124, i1 false)
  ret void
}

define void @test_srcunalign_dst8_constant_size_127(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_srcunalign_dst8_constant_size_127(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = load i64, ptr [[B]], align 1
; CHECK-NEXT:    store i64 [[TMP0]], ptr [[A]], align 1
; CHECK-NEXT:    [[ADD_PTR1_I:%.*]] = getelementptr i8, ptr [[A]], i32 8
; CHECK-NEXT:    [[ADD_PTR_I:%.*]] = getelementptr i8, ptr [[B]], i32 8
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[ADD_PTR_I]] to i32
; CHECK-NEXT:    [[TMP2:%.*]] = ptrtoint ptr [[ADD_PTR1_I]] to i32
; CHECK-NEXT:    tail call void @esp32p4MemCpySrcunalignedDst16Div48Index10(i32 [[TMP2]], i32 [[TMP1]])
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[ADD_PTR_I]], i64 96
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[ADD_PTR1_I]], i64 96
; CHECK-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[TMP3]], i32 0
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[TMP4]], i32 0
; CHECK-NEXT:    [[TMP7:%.*]] = load i32, ptr [[TMP5]], align 4
; CHECK-NEXT:    store i32 [[TMP7]], ptr [[TMP6]], align 4
; CHECK-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[TMP3]], i32 4
; CHECK-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[TMP4]], i32 4
; CHECK-NEXT:    [[TMP10:%.*]] = load i32, ptr [[TMP8]], align 4
; CHECK-NEXT:    store i32 [[TMP10]], ptr [[TMP9]], align 4
; CHECK-NEXT:    [[TMP11:%.*]] = getelementptr i8, ptr [[B]], i64 112
; CHECK-NEXT:    [[TMP12:%.*]] = getelementptr i8, ptr [[A]], i64 112
; CHECK-NEXT:    [[TMP13:%.*]] = getelementptr i8, ptr [[TMP11]], i32 0
; CHECK-NEXT:    [[TMP14:%.*]] = getelementptr i8, ptr [[TMP12]], i32 0
; CHECK-NEXT:    [[TMP15:%.*]] = load i32, ptr [[TMP13]], align 4
; CHECK-NEXT:    store i32 [[TMP15]], ptr [[TMP14]], align 4
; CHECK-NEXT:    [[TMP16:%.*]] = getelementptr i8, ptr [[TMP11]], i32 4
; CHECK-NEXT:    [[TMP17:%.*]] = getelementptr i8, ptr [[TMP12]], i32 4
; CHECK-NEXT:    [[TMP18:%.*]] = load i32, ptr [[TMP16]], align 4
; CHECK-NEXT:    store i32 [[TMP18]], ptr [[TMP17]], align 4
; CHECK-NEXT:    [[TMP19:%.*]] = getelementptr i8, ptr [[TMP11]], i32 8
; CHECK-NEXT:    [[TMP20:%.*]] = getelementptr i8, ptr [[TMP12]], i32 8
; CHECK-NEXT:    [[TMP21:%.*]] = load i32, ptr [[TMP19]], align 4
; CHECK-NEXT:    store i32 [[TMP21]], ptr [[TMP20]], align 4
; CHECK-NEXT:    [[TMP22:%.*]] = getelementptr i8, ptr [[TMP11]], i32 12
; CHECK-NEXT:    [[TMP23:%.*]] = getelementptr i8, ptr [[TMP12]], i32 12
; CHECK-NEXT:    [[TMP24:%.*]] = load i16, ptr [[TMP22]], align 2
; CHECK-NEXT:    store i16 [[TMP24]], ptr [[TMP23]], align 2
; CHECK-NEXT:    [[TMP25:%.*]] = getelementptr i8, ptr [[TMP11]], i32 14
; CHECK-NEXT:    [[TMP26:%.*]] = getelementptr i8, ptr [[TMP12]], i32 14
; CHECK-NEXT:    [[TMP27:%.*]] = load i8, ptr [[TMP25]], align 1
; CHECK-NEXT:    store i8 [[TMP27]], ptr [[TMP26]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(127) %a, ptr noundef nonnull align 1 dereferenceable(127) %b, i32 127, i1 false)
  ret void
}

define void @test_srcunalign_dst8_constant_size_128(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_srcunalign_dst8_constant_size_128(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = load i64, ptr [[B]], align 1
; CHECK-NEXT:    store i64 [[TMP0]], ptr [[A]], align 1
; CHECK-NEXT:    [[ADD_PTR1_I:%.*]] = getelementptr i8, ptr [[A]], i32 8
; CHECK-NEXT:    [[ADD_PTR_I:%.*]] = getelementptr i8, ptr [[B]], i32 8
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[ADD_PTR_I]] to i32
; CHECK-NEXT:    [[TMP2:%.*]] = ptrtoint ptr [[ADD_PTR1_I]] to i32
; CHECK-NEXT:    tail call void @esp32p4MemCpySrcunalignedDst16mod48From16to31.9(i32 [[TMP2]], i32 [[TMP1]])
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[ADD_PTR_I]], i64 112
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[ADD_PTR1_I]], i64 112
; CHECK-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[TMP3]], i32 0
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[TMP4]], i32 0
; CHECK-NEXT:    [[TMP7:%.*]] = load i32, ptr [[TMP5]], align 4
; CHECK-NEXT:    store i32 [[TMP7]], ptr [[TMP6]], align 4
; CHECK-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[TMP3]], i32 4
; CHECK-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[TMP4]], i32 4
; CHECK-NEXT:    [[TMP10:%.*]] = load i32, ptr [[TMP8]], align 4
; CHECK-NEXT:    store i32 [[TMP10]], ptr [[TMP9]], align 4
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(128) %a, ptr noundef nonnull align 1 dereferenceable(128) %b, i32 128, i1 false)
  ret void
}

define void @test_srcunalign_dst8_constant_size_129(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_srcunalign_dst8_constant_size_129(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = load i64, ptr [[B]], align 1
; CHECK-NEXT:    store i64 [[TMP0]], ptr [[A]], align 1
; CHECK-NEXT:    [[ADD_PTR1_I:%.*]] = getelementptr i8, ptr [[A]], i32 8
; CHECK-NEXT:    [[ADD_PTR_I:%.*]] = getelementptr i8, ptr [[B]], i32 8
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[ADD_PTR_I]] to i32
; CHECK-NEXT:    [[TMP2:%.*]] = ptrtoint ptr [[ADD_PTR1_I]] to i32
; CHECK-NEXT:    tail call void @esp32p4MemCpySrcunalignedDst16mod48From16to31.10(i32 [[TMP2]], i32 [[TMP1]])
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[ADD_PTR_I]], i64 112
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[ADD_PTR1_I]], i64 112
; CHECK-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[TMP3]], i32 0
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[TMP4]], i32 0
; CHECK-NEXT:    [[TMP7:%.*]] = load i32, ptr [[TMP5]], align 4
; CHECK-NEXT:    store i32 [[TMP7]], ptr [[TMP6]], align 4
; CHECK-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[TMP3]], i32 4
; CHECK-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[TMP4]], i32 4
; CHECK-NEXT:    [[TMP10:%.*]] = load i32, ptr [[TMP8]], align 4
; CHECK-NEXT:    store i32 [[TMP10]], ptr [[TMP9]], align 4
; CHECK-NEXT:    [[TMP11:%.*]] = getelementptr i8, ptr [[B]], i64 128
; CHECK-NEXT:    [[TMP12:%.*]] = getelementptr i8, ptr [[A]], i64 128
; CHECK-NEXT:    [[TMP13:%.*]] = getelementptr i8, ptr [[TMP11]], i32 0
; CHECK-NEXT:    [[TMP14:%.*]] = getelementptr i8, ptr [[TMP12]], i32 0
; CHECK-NEXT:    [[TMP15:%.*]] = load i8, ptr [[TMP13]], align 1
; CHECK-NEXT:    store i8 [[TMP15]], ptr [[TMP14]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(129) %a, ptr noundef nonnull align 1 dereferenceable(129) %b, i32 129, i1 false)
  ret void
}

define void @test_srcunalign_dst8_constant_size_255(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_srcunalign_dst8_constant_size_255(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = load i64, ptr [[B]], align 1
; CHECK-NEXT:    store i64 [[TMP0]], ptr [[A]], align 1
; CHECK-NEXT:    [[ADD_PTR1_I:%.*]] = getelementptr i8, ptr [[A]], i32 8
; CHECK-NEXT:    [[ADD_PTR_I:%.*]] = getelementptr i8, ptr [[B]], i32 8
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[ADD_PTR_I]] to i32
; CHECK-NEXT:    [[TMP2:%.*]] = ptrtoint ptr [[ADD_PTR1_I]] to i32
; CHECK-NEXT:    tail call void @esp32p4MemCpySrcunalignedDst16mod48From32To47Index7(i32 [[TMP2]], i32 [[TMP1]])
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[ADD_PTR_I]], i64 224
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[ADD_PTR1_I]], i64 224
; CHECK-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[TMP3]], i32 0
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[TMP4]], i32 0
; CHECK-NEXT:    [[TMP7:%.*]] = load i32, ptr [[TMP5]], align 4
; CHECK-NEXT:    store i32 [[TMP7]], ptr [[TMP6]], align 4
; CHECK-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[TMP3]], i32 4
; CHECK-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[TMP4]], i32 4
; CHECK-NEXT:    [[TMP10:%.*]] = load i32, ptr [[TMP8]], align 4
; CHECK-NEXT:    store i32 [[TMP10]], ptr [[TMP9]], align 4
; CHECK-NEXT:    [[TMP11:%.*]] = getelementptr i8, ptr [[B]], i64 240
; CHECK-NEXT:    [[TMP12:%.*]] = getelementptr i8, ptr [[A]], i64 240
; CHECK-NEXT:    [[TMP13:%.*]] = getelementptr i8, ptr [[TMP11]], i32 0
; CHECK-NEXT:    [[TMP14:%.*]] = getelementptr i8, ptr [[TMP12]], i32 0
; CHECK-NEXT:    [[TMP15:%.*]] = load i32, ptr [[TMP13]], align 4
; CHECK-NEXT:    store i32 [[TMP15]], ptr [[TMP14]], align 4
; CHECK-NEXT:    [[TMP16:%.*]] = getelementptr i8, ptr [[TMP11]], i32 4
; CHECK-NEXT:    [[TMP17:%.*]] = getelementptr i8, ptr [[TMP12]], i32 4
; CHECK-NEXT:    [[TMP18:%.*]] = load i32, ptr [[TMP16]], align 4
; CHECK-NEXT:    store i32 [[TMP18]], ptr [[TMP17]], align 4
; CHECK-NEXT:    [[TMP19:%.*]] = getelementptr i8, ptr [[TMP11]], i32 8
; CHECK-NEXT:    [[TMP20:%.*]] = getelementptr i8, ptr [[TMP12]], i32 8
; CHECK-NEXT:    [[TMP21:%.*]] = load i32, ptr [[TMP19]], align 4
; CHECK-NEXT:    store i32 [[TMP21]], ptr [[TMP20]], align 4
; CHECK-NEXT:    [[TMP22:%.*]] = getelementptr i8, ptr [[TMP11]], i32 12
; CHECK-NEXT:    [[TMP23:%.*]] = getelementptr i8, ptr [[TMP12]], i32 12
; CHECK-NEXT:    [[TMP24:%.*]] = load i16, ptr [[TMP22]], align 2
; CHECK-NEXT:    store i16 [[TMP24]], ptr [[TMP23]], align 2
; CHECK-NEXT:    [[TMP25:%.*]] = getelementptr i8, ptr [[TMP11]], i32 14
; CHECK-NEXT:    [[TMP26:%.*]] = getelementptr i8, ptr [[TMP12]], i32 14
; CHECK-NEXT:    [[TMP27:%.*]] = load i8, ptr [[TMP25]], align 1
; CHECK-NEXT:    store i8 [[TMP27]], ptr [[TMP26]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(255) %a, ptr noundef nonnull align 1 dereferenceable(255) %b, i32 255, i1 false)
  ret void
}

define void @test_srcunalign_dst8_constant_size_256(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_srcunalign_dst8_constant_size_256(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = load i64, ptr [[B]], align 1
; CHECK-NEXT:    store i64 [[TMP0]], ptr [[A]], align 1
; CHECK-NEXT:    [[ADD_PTR1_I:%.*]] = getelementptr i8, ptr [[A]], i32 8
; CHECK-NEXT:    [[ADD_PTR_I:%.*]] = getelementptr i8, ptr [[B]], i32 8
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[ADD_PTR_I]] to i32
; CHECK-NEXT:    [[TMP2:%.*]] = ptrtoint ptr [[ADD_PTR1_I]] to i32
; CHECK-NEXT:    tail call void @esp32p4MemCpySrcunalignedDst16Div48Index11(i32 [[TMP2]], i32 [[TMP1]])
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[ADD_PTR_I]], i64 240
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[ADD_PTR1_I]], i64 240
; CHECK-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[TMP3]], i32 0
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[TMP4]], i32 0
; CHECK-NEXT:    [[TMP7:%.*]] = load i32, ptr [[TMP5]], align 4
; CHECK-NEXT:    store i32 [[TMP7]], ptr [[TMP6]], align 4
; CHECK-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[TMP3]], i32 4
; CHECK-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[TMP4]], i32 4
; CHECK-NEXT:    [[TMP10:%.*]] = load i32, ptr [[TMP8]], align 4
; CHECK-NEXT:    store i32 [[TMP10]], ptr [[TMP9]], align 4
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(256) %a, ptr noundef nonnull align 1 dereferenceable(256) %b, i32 256, i1 false)
  ret void
}

define void @test_srcunalign_dst8_constant_size_1023(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_srcunalign_dst8_constant_size_1023(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = load i64, ptr [[B]], align 1
; CHECK-NEXT:    store i64 [[TMP0]], ptr [[A]], align 1
; CHECK-NEXT:    [[ADD_PTR1_I:%.*]] = getelementptr i8, ptr [[A]], i32 8
; CHECK-NEXT:    [[ADD_PTR_I:%.*]] = getelementptr i8, ptr [[B]], i32 8
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[ADD_PTR_I]] to i32
; CHECK-NEXT:    [[TMP2:%.*]] = ptrtoint ptr [[ADD_PTR1_I]] to i32
; CHECK-NEXT:    tail call void @esp32p4MemCpySrcunalignedDst16mod48From32To47Index8(i32 [[TMP2]], i32 [[TMP1]])
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[ADD_PTR_I]], i64 992
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[ADD_PTR1_I]], i64 992
; CHECK-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[TMP3]], i32 0
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[TMP4]], i32 0
; CHECK-NEXT:    [[TMP7:%.*]] = load i32, ptr [[TMP5]], align 4
; CHECK-NEXT:    store i32 [[TMP7]], ptr [[TMP6]], align 4
; CHECK-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[TMP3]], i32 4
; CHECK-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[TMP4]], i32 4
; CHECK-NEXT:    [[TMP10:%.*]] = load i32, ptr [[TMP8]], align 4
; CHECK-NEXT:    store i32 [[TMP10]], ptr [[TMP9]], align 4
; CHECK-NEXT:    [[TMP11:%.*]] = getelementptr i8, ptr [[B]], i64 1008
; CHECK-NEXT:    [[TMP12:%.*]] = getelementptr i8, ptr [[A]], i64 1008
; CHECK-NEXT:    [[TMP13:%.*]] = getelementptr i8, ptr [[TMP11]], i32 0
; CHECK-NEXT:    [[TMP14:%.*]] = getelementptr i8, ptr [[TMP12]], i32 0
; CHECK-NEXT:    [[TMP15:%.*]] = load i32, ptr [[TMP13]], align 4
; CHECK-NEXT:    store i32 [[TMP15]], ptr [[TMP14]], align 4
; CHECK-NEXT:    [[TMP16:%.*]] = getelementptr i8, ptr [[TMP11]], i32 4
; CHECK-NEXT:    [[TMP17:%.*]] = getelementptr i8, ptr [[TMP12]], i32 4
; CHECK-NEXT:    [[TMP18:%.*]] = load i32, ptr [[TMP16]], align 4
; CHECK-NEXT:    store i32 [[TMP18]], ptr [[TMP17]], align 4
; CHECK-NEXT:    [[TMP19:%.*]] = getelementptr i8, ptr [[TMP11]], i32 8
; CHECK-NEXT:    [[TMP20:%.*]] = getelementptr i8, ptr [[TMP12]], i32 8
; CHECK-NEXT:    [[TMP21:%.*]] = load i32, ptr [[TMP19]], align 4
; CHECK-NEXT:    store i32 [[TMP21]], ptr [[TMP20]], align 4
; CHECK-NEXT:    [[TMP22:%.*]] = getelementptr i8, ptr [[TMP11]], i32 12
; CHECK-NEXT:    [[TMP23:%.*]] = getelementptr i8, ptr [[TMP12]], i32 12
; CHECK-NEXT:    [[TMP24:%.*]] = load i16, ptr [[TMP22]], align 2
; CHECK-NEXT:    store i16 [[TMP24]], ptr [[TMP23]], align 2
; CHECK-NEXT:    [[TMP25:%.*]] = getelementptr i8, ptr [[TMP11]], i32 14
; CHECK-NEXT:    [[TMP26:%.*]] = getelementptr i8, ptr [[TMP12]], i32 14
; CHECK-NEXT:    [[TMP27:%.*]] = load i8, ptr [[TMP25]], align 1
; CHECK-NEXT:    store i8 [[TMP27]], ptr [[TMP26]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(1023) %a, ptr noundef nonnull align 1 dereferenceable(1023) %b, i32 1023, i1 false)
  ret void
}

define void @test_srcunalign_dst8_constant_size_1024(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_srcunalign_dst8_constant_size_1024(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = load i64, ptr [[B]], align 1
; CHECK-NEXT:    store i64 [[TMP0]], ptr [[A]], align 1
; CHECK-NEXT:    [[ADD_PTR1_I:%.*]] = getelementptr i8, ptr [[A]], i32 8
; CHECK-NEXT:    [[ADD_PTR_I:%.*]] = getelementptr i8, ptr [[B]], i32 8
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[ADD_PTR_I]] to i32
; CHECK-NEXT:    [[TMP2:%.*]] = ptrtoint ptr [[ADD_PTR1_I]] to i32
; CHECK-NEXT:    tail call void @esp32p4MemCpySrcunalignedDst16Div48Index12(i32 [[TMP2]], i32 [[TMP1]])
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[ADD_PTR_I]], i64 1008
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[ADD_PTR1_I]], i64 1008
; CHECK-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[TMP3]], i32 0
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[TMP4]], i32 0
; CHECK-NEXT:    [[TMP7:%.*]] = load i32, ptr [[TMP5]], align 4
; CHECK-NEXT:    store i32 [[TMP7]], ptr [[TMP6]], align 4
; CHECK-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[TMP3]], i32 4
; CHECK-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[TMP4]], i32 4
; CHECK-NEXT:    [[TMP10:%.*]] = load i32, ptr [[TMP8]], align 4
; CHECK-NEXT:    store i32 [[TMP10]], ptr [[TMP9]], align 4
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 8 dereferenceable(1024) %a, ptr noundef nonnull align 1 dereferenceable(1024) %b, i32 1024, i1 false)
  ret void
}

; srcunalign dstunalign
define void @test_srcunalign_dstunalign_constant_size_1(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_srcunalign_dstunalign_constant_size_1(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = getelementptr i8, ptr [[B]], i32 0
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[A]], i32 0
; CHECK-NEXT:    [[TMP2:%.*]] = load i8, ptr [[TMP0]], align 1
; CHECK-NEXT:    store i8 [[TMP2]], ptr [[TMP1]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(1) %a, ptr noundef nonnull align 1 dereferenceable(1) %b, i32 1, i1 false)
  ret void
}

define void @test_srcunalign_dstunalign_constant_size_2(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_srcunalign_dstunalign_constant_size_2(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = getelementptr i8, ptr [[B]], i32 0
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[A]], i32 0
; CHECK-NEXT:    [[TMP2:%.*]] = load i16, ptr [[TMP0]], align 2
; CHECK-NEXT:    store i16 [[TMP2]], ptr [[TMP1]], align 2
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(2) %a, ptr noundef nonnull align 1 dereferenceable(2) %b, i32 2, i1 false)
  ret void
}

define void @test_srcunalign_dstunalign_constant_size_3(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_srcunalign_dstunalign_constant_size_3(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = getelementptr i8, ptr [[B]], i32 0
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[A]], i32 0
; CHECK-NEXT:    [[TMP2:%.*]] = load i16, ptr [[TMP0]], align 2
; CHECK-NEXT:    store i16 [[TMP2]], ptr [[TMP1]], align 2
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[B]], i32 2
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[A]], i32 2
; CHECK-NEXT:    [[TMP5:%.*]] = load i8, ptr [[TMP3]], align 1
; CHECK-NEXT:    store i8 [[TMP5]], ptr [[TMP4]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(3) %a, ptr noundef nonnull align 1 dereferenceable(3) %b, i32 3, i1 false)
  ret void
}

define void @test_srcunalign_dstunalign_constant_size_4(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_srcunalign_dstunalign_constant_size_4(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = getelementptr i8, ptr [[B]], i32 0
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[A]], i32 0
; CHECK-NEXT:    [[TMP2:%.*]] = load i32, ptr [[TMP0]], align 4
; CHECK-NEXT:    store i32 [[TMP2]], ptr [[TMP1]], align 4
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(4) %a, ptr noundef nonnull align 1 dereferenceable(4) %b, i32 4, i1 false)
  ret void
}

define void @test_srcunalign_dstunalign_constant_size_5(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_srcunalign_dstunalign_constant_size_5(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = getelementptr i8, ptr [[B]], i32 0
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[A]], i32 0
; CHECK-NEXT:    [[TMP2:%.*]] = load i32, ptr [[TMP0]], align 4
; CHECK-NEXT:    store i32 [[TMP2]], ptr [[TMP1]], align 4
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[B]], i32 4
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[A]], i32 4
; CHECK-NEXT:    [[TMP5:%.*]] = load i8, ptr [[TMP3]], align 1
; CHECK-NEXT:    store i8 [[TMP5]], ptr [[TMP4]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(5) %a, ptr noundef nonnull align 1 dereferenceable(5) %b, i32 5, i1 false)
  ret void
}

define void @test_srcunalign_dstunalign_constant_size_6(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_srcunalign_dstunalign_constant_size_6(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = getelementptr i8, ptr [[B]], i32 0
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[A]], i32 0
; CHECK-NEXT:    [[TMP2:%.*]] = load i32, ptr [[TMP0]], align 4
; CHECK-NEXT:    store i32 [[TMP2]], ptr [[TMP1]], align 4
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[B]], i32 4
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[A]], i32 4
; CHECK-NEXT:    [[TMP5:%.*]] = load i16, ptr [[TMP3]], align 2
; CHECK-NEXT:    store i16 [[TMP5]], ptr [[TMP4]], align 2
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(6) %a, ptr noundef nonnull align 1 dereferenceable(6) %b, i32 6, i1 false)
  ret void
}

define void @test_srcunalign_dstunalign_constant_size_7(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_srcunalign_dstunalign_constant_size_7(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = getelementptr i8, ptr [[B]], i32 0
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[A]], i32 0
; CHECK-NEXT:    [[TMP2:%.*]] = load i32, ptr [[TMP0]], align 4
; CHECK-NEXT:    store i32 [[TMP2]], ptr [[TMP1]], align 4
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[B]], i32 4
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[A]], i32 4
; CHECK-NEXT:    [[TMP5:%.*]] = load i16, ptr [[TMP3]], align 2
; CHECK-NEXT:    store i16 [[TMP5]], ptr [[TMP4]], align 2
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[B]], i32 6
; CHECK-NEXT:    [[TMP7:%.*]] = getelementptr i8, ptr [[A]], i32 6
; CHECK-NEXT:    [[TMP8:%.*]] = load i8, ptr [[TMP6]], align 1
; CHECK-NEXT:    store i8 [[TMP8]], ptr [[TMP7]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(7) %a, ptr noundef nonnull align 1 dereferenceable(7) %b, i32 7, i1 false)
  ret void
}

define void @test_srcunalign_dstunalign_constant_size_8(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_srcunalign_dstunalign_constant_size_8(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = getelementptr i8, ptr [[B]], i32 0
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[A]], i32 0
; CHECK-NEXT:    [[TMP2:%.*]] = load i32, ptr [[TMP0]], align 4
; CHECK-NEXT:    store i32 [[TMP2]], ptr [[TMP1]], align 4
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[B]], i32 4
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[A]], i32 4
; CHECK-NEXT:    [[TMP5:%.*]] = load i32, ptr [[TMP3]], align 4
; CHECK-NEXT:    store i32 [[TMP5]], ptr [[TMP4]], align 4
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(8) %a, ptr noundef nonnull align 1 dereferenceable(8) %b, i32 8, i1 false)
  ret void
}

define void @test_srcunalign_dstunalign_constant_size_9(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_srcunalign_dstunalign_constant_size_9(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = getelementptr i8, ptr [[B]], i32 0
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[A]], i32 0
; CHECK-NEXT:    [[TMP2:%.*]] = load i32, ptr [[TMP0]], align 4
; CHECK-NEXT:    store i32 [[TMP2]], ptr [[TMP1]], align 4
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[B]], i32 4
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[A]], i32 4
; CHECK-NEXT:    [[TMP5:%.*]] = load i32, ptr [[TMP3]], align 4
; CHECK-NEXT:    store i32 [[TMP5]], ptr [[TMP4]], align 4
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[B]], i32 8
; CHECK-NEXT:    [[TMP7:%.*]] = getelementptr i8, ptr [[A]], i32 8
; CHECK-NEXT:    [[TMP8:%.*]] = load i8, ptr [[TMP6]], align 1
; CHECK-NEXT:    store i8 [[TMP8]], ptr [[TMP7]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(9) %a, ptr noundef nonnull align 1 dereferenceable(9) %b, i32 9, i1 false)
  ret void
}

define void @test_srcunalign_dstunalign_constant_size_10(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_srcunalign_dstunalign_constant_size_10(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = getelementptr i8, ptr [[B]], i32 0
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[A]], i32 0
; CHECK-NEXT:    [[TMP2:%.*]] = load i32, ptr [[TMP0]], align 4
; CHECK-NEXT:    store i32 [[TMP2]], ptr [[TMP1]], align 4
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[B]], i32 4
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[A]], i32 4
; CHECK-NEXT:    [[TMP5:%.*]] = load i32, ptr [[TMP3]], align 4
; CHECK-NEXT:    store i32 [[TMP5]], ptr [[TMP4]], align 4
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[B]], i32 8
; CHECK-NEXT:    [[TMP7:%.*]] = getelementptr i8, ptr [[A]], i32 8
; CHECK-NEXT:    [[TMP8:%.*]] = load i16, ptr [[TMP6]], align 2
; CHECK-NEXT:    store i16 [[TMP8]], ptr [[TMP7]], align 2
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(10) %a, ptr noundef nonnull align 1 dereferenceable(10) %b, i32 10, i1 false)
  ret void
}

define void @test_srcunalign_dstunalign_constant_size_11(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_srcunalign_dstunalign_constant_size_11(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = getelementptr i8, ptr [[B]], i32 0
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[A]], i32 0
; CHECK-NEXT:    [[TMP2:%.*]] = load i32, ptr [[TMP0]], align 4
; CHECK-NEXT:    store i32 [[TMP2]], ptr [[TMP1]], align 4
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[B]], i32 4
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[A]], i32 4
; CHECK-NEXT:    [[TMP5:%.*]] = load i32, ptr [[TMP3]], align 4
; CHECK-NEXT:    store i32 [[TMP5]], ptr [[TMP4]], align 4
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[B]], i32 8
; CHECK-NEXT:    [[TMP7:%.*]] = getelementptr i8, ptr [[A]], i32 8
; CHECK-NEXT:    [[TMP8:%.*]] = load i16, ptr [[TMP6]], align 2
; CHECK-NEXT:    store i16 [[TMP8]], ptr [[TMP7]], align 2
; CHECK-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[B]], i32 10
; CHECK-NEXT:    [[TMP10:%.*]] = getelementptr i8, ptr [[A]], i32 10
; CHECK-NEXT:    [[TMP11:%.*]] = load i8, ptr [[TMP9]], align 1
; CHECK-NEXT:    store i8 [[TMP11]], ptr [[TMP10]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(11) %a, ptr noundef nonnull align 1 dereferenceable(11) %b, i32 11, i1 false)
  ret void
}

define void @test_srcunalign_dstunalign_constant_size_12(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_srcunalign_dstunalign_constant_size_12(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = getelementptr i8, ptr [[B]], i32 0
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[A]], i32 0
; CHECK-NEXT:    [[TMP2:%.*]] = load i32, ptr [[TMP0]], align 4
; CHECK-NEXT:    store i32 [[TMP2]], ptr [[TMP1]], align 4
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[B]], i32 4
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[A]], i32 4
; CHECK-NEXT:    [[TMP5:%.*]] = load i32, ptr [[TMP3]], align 4
; CHECK-NEXT:    store i32 [[TMP5]], ptr [[TMP4]], align 4
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[B]], i32 8
; CHECK-NEXT:    [[TMP7:%.*]] = getelementptr i8, ptr [[A]], i32 8
; CHECK-NEXT:    [[TMP8:%.*]] = load i32, ptr [[TMP6]], align 4
; CHECK-NEXT:    store i32 [[TMP8]], ptr [[TMP7]], align 4
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(12) %a, ptr noundef nonnull align 1 dereferenceable(12) %b, i32 12, i1 false)
  ret void
}

define void @test_srcunalign_dstunalign_constant_size_13(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_srcunalign_dstunalign_constant_size_13(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = getelementptr i8, ptr [[B]], i32 0
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[A]], i32 0
; CHECK-NEXT:    [[TMP2:%.*]] = load i32, ptr [[TMP0]], align 4
; CHECK-NEXT:    store i32 [[TMP2]], ptr [[TMP1]], align 4
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[B]], i32 4
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[A]], i32 4
; CHECK-NEXT:    [[TMP5:%.*]] = load i32, ptr [[TMP3]], align 4
; CHECK-NEXT:    store i32 [[TMP5]], ptr [[TMP4]], align 4
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[B]], i32 8
; CHECK-NEXT:    [[TMP7:%.*]] = getelementptr i8, ptr [[A]], i32 8
; CHECK-NEXT:    [[TMP8:%.*]] = load i32, ptr [[TMP6]], align 4
; CHECK-NEXT:    store i32 [[TMP8]], ptr [[TMP7]], align 4
; CHECK-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[B]], i32 12
; CHECK-NEXT:    [[TMP10:%.*]] = getelementptr i8, ptr [[A]], i32 12
; CHECK-NEXT:    [[TMP11:%.*]] = load i8, ptr [[TMP9]], align 1
; CHECK-NEXT:    store i8 [[TMP11]], ptr [[TMP10]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(13) %a, ptr noundef nonnull align 1 dereferenceable(13) %b, i32 13, i1 false)
  ret void
}

define void @test_srcunalign_dstunalign_constant_size_14(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_srcunalign_dstunalign_constant_size_14(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = getelementptr i8, ptr [[B]], i32 0
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[A]], i32 0
; CHECK-NEXT:    [[TMP2:%.*]] = load i32, ptr [[TMP0]], align 4
; CHECK-NEXT:    store i32 [[TMP2]], ptr [[TMP1]], align 4
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[B]], i32 4
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[A]], i32 4
; CHECK-NEXT:    [[TMP5:%.*]] = load i32, ptr [[TMP3]], align 4
; CHECK-NEXT:    store i32 [[TMP5]], ptr [[TMP4]], align 4
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[B]], i32 8
; CHECK-NEXT:    [[TMP7:%.*]] = getelementptr i8, ptr [[A]], i32 8
; CHECK-NEXT:    [[TMP8:%.*]] = load i32, ptr [[TMP6]], align 4
; CHECK-NEXT:    store i32 [[TMP8]], ptr [[TMP7]], align 4
; CHECK-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[B]], i32 12
; CHECK-NEXT:    [[TMP10:%.*]] = getelementptr i8, ptr [[A]], i32 12
; CHECK-NEXT:    [[TMP11:%.*]] = load i16, ptr [[TMP9]], align 2
; CHECK-NEXT:    store i16 [[TMP11]], ptr [[TMP10]], align 2
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(14) %a, ptr noundef nonnull align 1 dereferenceable(14) %b, i32 14, i1 false)
  ret void
}

define void @test_srcunalign_dstunalign_constant_size_15(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_srcunalign_dstunalign_constant_size_15(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = getelementptr i8, ptr [[B]], i32 0
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[A]], i32 0
; CHECK-NEXT:    [[TMP2:%.*]] = load i32, ptr [[TMP0]], align 4
; CHECK-NEXT:    store i32 [[TMP2]], ptr [[TMP1]], align 4
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[B]], i32 4
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[A]], i32 4
; CHECK-NEXT:    [[TMP5:%.*]] = load i32, ptr [[TMP3]], align 4
; CHECK-NEXT:    store i32 [[TMP5]], ptr [[TMP4]], align 4
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[B]], i32 8
; CHECK-NEXT:    [[TMP7:%.*]] = getelementptr i8, ptr [[A]], i32 8
; CHECK-NEXT:    [[TMP8:%.*]] = load i32, ptr [[TMP6]], align 4
; CHECK-NEXT:    store i32 [[TMP8]], ptr [[TMP7]], align 4
; CHECK-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[B]], i32 12
; CHECK-NEXT:    [[TMP10:%.*]] = getelementptr i8, ptr [[A]], i32 12
; CHECK-NEXT:    [[TMP11:%.*]] = load i16, ptr [[TMP9]], align 2
; CHECK-NEXT:    store i16 [[TMP11]], ptr [[TMP10]], align 2
; CHECK-NEXT:    [[TMP12:%.*]] = getelementptr i8, ptr [[B]], i32 14
; CHECK-NEXT:    [[TMP13:%.*]] = getelementptr i8, ptr [[A]], i32 14
; CHECK-NEXT:    [[TMP14:%.*]] = load i8, ptr [[TMP12]], align 1
; CHECK-NEXT:    store i8 [[TMP14]], ptr [[TMP13]], align 1
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(15) %a, ptr noundef nonnull align 1 dereferenceable(15) %b, i32 15, i1 false)
  ret void
}

define void @test_srcunalign_dstunalign_constant_size_16(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_srcunalign_dstunalign_constant_size_16(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    call void @esp32p4MemCpySrc16DstunalignedVar(ptr [[A]], ptr [[B]], i32 16, i32 1)
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(16) %a, ptr noundef nonnull align 1 dereferenceable(16) %b, i32 16, i1 false)
  ret void
}

define void @test_srcunalign_dstunalign_constant_size_17(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_srcunalign_dstunalign_constant_size_17(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    call void @esp32p4MemCpySrc16DstunalignedVar(ptr [[A]], ptr [[B]], i32 17, i32 1)
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(17) %a, ptr noundef nonnull align 1 dereferenceable(17) %b, i32 17, i1 false)
  ret void
}

define void @test_srcunalign_dstunalign_constant_size_31(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_srcunalign_dstunalign_constant_size_31(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    call void @esp32p4MemCpySrc16DstunalignedVar(ptr [[A]], ptr [[B]], i32 31, i32 1)
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(31) %a, ptr noundef nonnull align 1 dereferenceable(31) %b, i32 31, i1 false)
  ret void
}

define void @test_srcunalign_dstunalign_constant_size_32(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_srcunalign_dstunalign_constant_size_32(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    call void @esp32p4MemCpySrc16DstunalignedVar(ptr [[A]], ptr [[B]], i32 32, i32 1)
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(32) %a, ptr noundef nonnull align 1 dereferenceable(32) %b, i32 32, i1 false)
  ret void
}

define void @test_srcunalign_dstunalign_constant_size_33(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_srcunalign_dstunalign_constant_size_33(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    call void @esp32p4MemCpySrc16DstunalignedVar(ptr [[A]], ptr [[B]], i32 33, i32 1)
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(33) %a, ptr noundef nonnull align 1 dereferenceable(33) %b, i32 33, i1 false)
  ret void
}

define void @test_srcunalign_dstunalign_constant_size_47(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_srcunalign_dstunalign_constant_size_47(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    call void @esp32p4MemCpySrc16DstunalignedVar(ptr [[A]], ptr [[B]], i32 47, i32 1)
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(47) %a, ptr noundef nonnull align 1 dereferenceable(47) %b, i32 47, i1 false)
  ret void
}

define void @test_srcunalign_dstunalign_constant_size_48(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_srcunalign_dstunalign_constant_size_48(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    call void @esp32p4MemCpySrc16DstunalignedVar(ptr [[A]], ptr [[B]], i32 48, i32 1)
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(48) %a, ptr noundef nonnull align 1 dereferenceable(48) %b, i32 48, i1 false)
  ret void
}

define void @test_srcunalign_dstunalign_constant_size_49(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_srcunalign_dstunalign_constant_size_49(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    call void @esp32p4MemCpySrc16DstunalignedVar(ptr [[A]], ptr [[B]], i32 49, i32 1)
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(49) %a, ptr noundef nonnull align 1 dereferenceable(49) %b, i32 49, i1 false)
  ret void
}

define void @test_srcunalign_dstunalign_constant_size_63(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_srcunalign_dstunalign_constant_size_63(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    call void @esp32p4MemCpySrc16DstunalignedVar(ptr [[A]], ptr [[B]], i32 63, i32 1)
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(63) %a, ptr noundef nonnull align 1 dereferenceable(63) %b, i32 63, i1 false)
  ret void
}

define void @test_srcunalign_dstunalign_constant_size_64(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_srcunalign_dstunalign_constant_size_64(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    call void @esp32p4MemCpySrc16DstunalignedVar(ptr [[A]], ptr [[B]], i32 64, i32 1)
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(64) %a, ptr noundef nonnull align 1 dereferenceable(64) %b, i32 64, i1 false)
  ret void
}

define void @test_srcunalign_dstunalign_constant_size_65(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_srcunalign_dstunalign_constant_size_65(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    call void @esp32p4MemCpySrc16DstunalignedVar(ptr [[A]], ptr [[B]], i32 65, i32 1)
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(65) %a, ptr noundef nonnull align 1 dereferenceable(65) %b, i32 65, i1 false)
  ret void
}

define void @test_srcunalign_dstunalign_constant_size_80(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_srcunalign_dstunalign_constant_size_80(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    call void @esp32p4MemCpySrc16DstunalignedVar(ptr [[A]], ptr [[B]], i32 80, i32 1)
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(80) %a, ptr noundef nonnull align 1 dereferenceable(80) %b, i32 80, i1 false)
  ret void
}

define void @test_srcunalign_dstunalign_constant_size_81(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_srcunalign_dstunalign_constant_size_81(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    call void @esp32p4MemCpySrc16DstunalignedVar(ptr [[A]], ptr [[B]], i32 81, i32 1)
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(81) %a, ptr noundef nonnull align 1 dereferenceable(81) %b, i32 81, i1 false)
  ret void
}

define void @test_srcunalign_dstunalign_constant_size_88(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_srcunalign_dstunalign_constant_size_88(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    call void @esp32p4MemCpySrc16DstunalignedVar(ptr [[A]], ptr [[B]], i32 88, i32 1)
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(88) %a, ptr noundef nonnull align 1 dereferenceable(88) %b, i32 88, i1 false)
  ret void
}

define void @test_srcunalign_dstunalign_constant_size_96(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_srcunalign_dstunalign_constant_size_96(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    call void @esp32p4MemCpySrc16DstunalignedVar(ptr [[A]], ptr [[B]], i32 96, i32 1)
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(96) %a, ptr noundef nonnull align 1 dereferenceable(96) %b, i32 96, i1 false)
  ret void
}

define void @test_srcunalign_dstunalign_constant_size_112(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_srcunalign_dstunalign_constant_size_112(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    call void @esp32p4MemCpySrc16DstunalignedVar(ptr [[A]], ptr [[B]], i32 112, i32 1)
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(112) %a, ptr noundef nonnull align 1 dereferenceable(112) %b, i32 112, i1 false)
  ret void
}

define void @test_srcunalign_dstunalign_constant_size_124(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_srcunalign_dstunalign_constant_size_124(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    call void @esp32p4MemCpySrc16DstunalignedVar(ptr [[A]], ptr [[B]], i32 124, i32 1)
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(124) %a, ptr noundef nonnull align 1 dereferenceable(124) %b, i32 124, i1 false)
  ret void
}

define void @test_srcunalign_dstunalign_constant_size_127(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_srcunalign_dstunalign_constant_size_127(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    call void @esp32p4MemCpySrc16DstunalignedVar(ptr [[A]], ptr [[B]], i32 127, i32 1)
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(127) %a, ptr noundef nonnull align 1 dereferenceable(127) %b, i32 127, i1 false)
  ret void
}

define void @test_srcunalign_dstunalign_constant_size_128(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_srcunalign_dstunalign_constant_size_128(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    call void @esp32p4MemCpySrc16DstunalignedVar(ptr [[A]], ptr [[B]], i32 128, i32 1)
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(128) %a, ptr noundef nonnull align 1 dereferenceable(128) %b, i32 128, i1 false)
  ret void
}

define void @test_srcunalign_dstunalign_constant_size_129(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_srcunalign_dstunalign_constant_size_129(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    call void @esp32p4MemCpySrc16DstunalignedVar(ptr [[A]], ptr [[B]], i32 129, i32 1)
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(129) %a, ptr noundef nonnull align 1 dereferenceable(129) %b, i32 129, i1 false)
  ret void
}

define void @test_srcunalign_dstunalign_constant_size_255(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_srcunalign_dstunalign_constant_size_255(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    call void @esp32p4MemCpySrc16DstunalignedVar(ptr [[A]], ptr [[B]], i32 255, i32 1)
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(255) %a, ptr noundef nonnull align 1 dereferenceable(255) %b, i32 255, i1 false)
  ret void
}

define void @test_srcunalign_dstunalign_constant_size_256(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_srcunalign_dstunalign_constant_size_256(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    call void @esp32p4MemCpySrc16DstunalignedVar(ptr [[A]], ptr [[B]], i32 256, i32 1)
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(256) %a, ptr noundef nonnull align 1 dereferenceable(256) %b, i32 256, i1 false)
  ret void
}

define void @test_srcunalign_dstunalign_constant_size_1023(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_srcunalign_dstunalign_constant_size_1023(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    call void @esp32p4MemCpySrc16DstunalignedVar(ptr [[A]], ptr [[B]], i32 1023, i32 1)
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(1023) %a, ptr noundef nonnull align 1 dereferenceable(1023) %b, i32 1023, i1 false)
  ret void
}

define void @test_srcunalign_dstunalign_constant_size_1024(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_srcunalign_dstunalign_constant_size_1024(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    call void @esp32p4MemCpySrc16DstunalignedVar(ptr [[A]], ptr [[B]], i32 1024, i32 1)
; CHECK-NEXT:    ret void
;

entry:
  tail call void @llvm.memcpy.p0.p0.i32(ptr noundef nonnull align 1 dereferenceable(1024) %a, ptr noundef nonnull align 1 dereferenceable(1024) %b, i32 1024, i1 false)
  ret void
}

; Function Attrs: noinline nounwind
define internal void @esp32p4MemCpySrc16DstunalignedVar(ptr %dst, ptr %src, i32 %size, i32 %dst_align) #12 {
; CHECK-LABEL: define internal void @esp32p4MemCpySrc16DstunalignedVar(
; CHECK-SAME: ptr [[DST:%.*]], ptr [[SRC:%.*]], i32 [[SIZE:%.*]], i32 [[DST_ALIGN:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[SUB:%.*]] = sub i32 16, [[DST_ALIGN]]
; CHECK-NEXT:    [[CMP_NOT:%.*]] = icmp ult i32 [[SUB]], [[SIZE]]
; CHECK-NEXT:    br i1 [[CMP_NOT]], label %[[IF_END:.*]], label %[[IF_THEN:.*]]
; CHECK:       [[IF_THEN]]:
; CHECK-NEXT:    call void @esp32p4MemCpySrcUnalignedDstUnalignedVarFrom0To15Opt(ptr [[DST]], ptr [[SRC]], i32 [[SIZE]])
; CHECK-NEXT:    br label %[[CLEANUP:.*]]
; CHECK:       [[IF_END]]:
; CHECK-NEXT:    call void @esp32p4MemCpySrcUnalignedDstUnalignedVarFrom0To15Opt(ptr [[DST]], ptr [[SRC]], i32 [[SUB]])
; CHECK-NEXT:    [[SUB2:%.*]] = sub i32 [[SIZE]], [[SUB]]
; CHECK-NEXT:    [[ADD_PTR1:%.*]] = getelementptr i8, ptr [[DST]], i32 [[SUB]]
; CHECK-NEXT:    [[ADD_PTR:%.*]] = getelementptr i8, ptr [[SRC]], i32 [[SUB]]
; CHECK-NEXT:    [[TMP0:%.*]] = icmp ult i32 [[SUB2]], 16
; CHECK-NEXT:    br i1 [[TMP0]], label %[[IF_SMALL:.*]], label %[[IF_LARGE:.*]]
; CHECK:       [[IF_SMALL]]:
; CHECK-NEXT:    call void @esp32p4MemCpySrcUnalignedDstUnalignedVarFrom0To15Opt(ptr [[ADD_PTR1]], ptr [[ADD_PTR]], i32 [[SUB2]])
; CHECK-NEXT:    br label %[[CLEANUP]]
; CHECK:       [[IF_LARGE]]:
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[ADD_PTR]] to i32
; CHECK-NEXT:    [[TMP2:%.*]] = ptrtoint ptr [[ADD_PTR1]] to i32
; CHECK-NEXT:    call void @esp32p4MemCpySrcunalignedDst16Var(i32 [[TMP2]], i32 [[TMP1]], i32 [[SUB2]])
; CHECK-NEXT:    br label %[[CLEANUP]]
; CHECK:       [[CLEANUP]]:
; CHECK-NEXT:    ret void
;

entry:
  %sub = sub i32 16, %dst_align
  %cmp.not = icmp ult i32 %sub, %size
  br i1 %cmp.not, label %if.end, label %if.then

if.then:                                          ; preds = %entry
  call void @esp32p4MemCpySrcUnalignedDstUnalignedVarFrom0To15Opt(ptr %dst, ptr %src, i32 %size)
  br label %cleanup

if.end:                                           ; preds = %entry
  call void @esp32p4MemCpySrcUnalignedDstUnalignedVarFrom0To15Opt(ptr %dst, ptr %src, i32 %sub)
  %sub2 = sub i32 %size, %sub
  %add.ptr1 = getelementptr i8, ptr %dst, i32 %sub
  %add.ptr = getelementptr i8, ptr %src, i32 %sub
  %0 = icmp ult i32 %sub2, 16
  br i1 %0, label %if.small, label %if.large

if.small:                                         ; preds = %if.end
  call void @esp32p4MemCpySrcUnalignedDstUnalignedVarFrom0To15Opt(ptr %add.ptr1, ptr %add.ptr, i32 %sub2)
  br label %cleanup

if.large:                                         ; preds = %if.end
  %1 = ptrtoint ptr %add.ptr to i32
  %2 = ptrtoint ptr %add.ptr1 to i32
  call void @esp32p4MemCpySrcunalignedDst16Var(i32 %2, i32 %1, i32 %sub2)
  br label %cleanup

cleanup:                                          ; preds = %if.small, %if.large, %if.then
  ret void
}

; Function Attrs: noinline nounwind
define internal void @esp32p4MemCpySrcUnalignedDstUnalignedVarFrom0To15Opt(ptr %0, ptr %1, i32 %2) {
; CHECK-LABEL: define internal void @esp32p4MemCpySrcUnalignedDstUnalignedVarFrom0To15Opt(
; CHECK-SAME: ptr [[TMP0:%.*]], ptr [[TMP1:%.*]], i32 [[TMP2:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    switch i32 [[TMP2]], label %[[RETURN:.*]] [
; CHECK-NEXT:      i32 1, label %[[SW_BB0:.*]]
; CHECK-NEXT:      i32 2, label %[[SW_BB1:.*]]
; CHECK-NEXT:      i32 3, label %[[SW_BB2:.*]]
; CHECK-NEXT:      i32 4, label %[[SW_BB3:.*]]
; CHECK-NEXT:      i32 5, label %[[SW_BB4:.*]]
; CHECK-NEXT:      i32 6, label %[[SW_BB5:.*]]
; CHECK-NEXT:      i32 7, label %[[SW_BB6:.*]]
; CHECK-NEXT:      i32 8, label %[[SW_BB7:.*]]
; CHECK-NEXT:      i32 9, label %[[SW_BB8:.*]]
; CHECK-NEXT:      i32 10, label %[[SW_BB9:.*]]
; CHECK-NEXT:      i32 11, label %[[SW_BB10:.*]]
; CHECK-NEXT:      i32 12, label %[[SW_BB11:.*]]
; CHECK-NEXT:      i32 13, label %[[SW_BB12:.*]]
; CHECK-NEXT:      i32 14, label %[[SW_BB13:.*]]
; CHECK-NEXT:      i32 15, label %[[SW_BB14:.*]]
; CHECK-NEXT:    ]
; CHECK:       [[RETURN]]:
; CHECK-NEXT:    ret void
; CHECK:       [[SW_BB0]]:
; CHECK-NEXT:    call void asm sideeffect "lb t0, 0($0)\0A\09sb t0, 0($1)\0A\09", "r,r,~{x5}"(ptr [[TMP1]], ptr [[TMP0]])
; CHECK-NEXT:    br label %[[RETURN]]
; CHECK:       [[SW_BB1]]:
; CHECK-NEXT:    call void asm sideeffect "lh t0, 0($0)\0A\09sh t0, 0($1)\0A\09", "r,r,~{x5}"(ptr [[TMP1]], ptr [[TMP0]])
; CHECK-NEXT:    br label %[[RETURN]]
; CHECK:       [[SW_BB2]]:
; CHECK-NEXT:    call void asm sideeffect "lh t0, 0($0)\0A\09sh t0, 0($1)\0A\09lb t0, 2($0)\0A\09sb t0, 2($1)\0A\09", "r,r,~{x5}"(ptr [[TMP1]], ptr [[TMP0]])
; CHECK-NEXT:    br label %[[RETURN]]
; CHECK:       [[SW_BB3]]:
; CHECK-NEXT:    call void asm sideeffect "lw t0, 0($0)\0A\09sw t0, 0($1)\0A\09", "r,r,~{x5}"(ptr [[TMP1]], ptr [[TMP0]])
; CHECK-NEXT:    br label %[[RETURN]]
; CHECK:       [[SW_BB4]]:
; CHECK-NEXT:    call void asm sideeffect "lw t0, 0($0)\0A\09sw t0, 0($1)\0A\09lb t0, 4($0)\0A\09sb t0, 4($1)\0A\09", "r,r,~{x5}"(ptr [[TMP1]], ptr [[TMP0]])
; CHECK-NEXT:    br label %[[RETURN]]
; CHECK:       [[SW_BB5]]:
; CHECK-NEXT:    call void asm sideeffect "lw t0, 0($0)\0A\09sw t0, 0($1)\0A\09lh t0, 4($0)\0A\09sh t0, 4($1)\0A\09", "r,r,~{x5}"(ptr [[TMP1]], ptr [[TMP0]])
; CHECK-NEXT:    br label %[[RETURN]]
; CHECK:       [[SW_BB6]]:
; CHECK-NEXT:    call void asm sideeffect "lw t0, 0($0)\0A\09sw t0, 0($1)\0A\09lh t0, 4($0)\0A\09sh t0, 4($1)\0A\09lb t0, 6($0)\0A\09sb t0, 6($1)\0A\09", "r,r,~{x5}"(ptr [[TMP1]], ptr [[TMP0]])
; CHECK-NEXT:    br label %[[RETURN]]
; CHECK:       [[SW_BB7]]:
; CHECK-NEXT:    call void asm sideeffect "lw t0, 0($0)\0A\09sw t0, 0($1)\0A\09lw t0, 4($0)\0A\09sw t0, 4($1)\0A\09", "r,r,~{x5}"(ptr [[TMP1]], ptr [[TMP0]])
; CHECK-NEXT:    br label %[[RETURN]]
; CHECK:       [[SW_BB8]]:
; CHECK-NEXT:    call void asm sideeffect "lw t0, 0($0)\0A\09sw t0, 0($1)\0A\09lw t0, 4($0)\0A\09sw t0, 4($1)\0A\09lb t0, 8($0)\0A\09sb t0, 8($1)\0A\09", "r,r,~{x5}"(ptr [[TMP1]], ptr [[TMP0]])
; CHECK-NEXT:    br label %[[RETURN]]
; CHECK:       [[SW_BB9]]:
; CHECK-NEXT:    call void asm sideeffect "lw t0, 0($0)\0A\09sw t0, 0($1)\0A\09lw t0, 4($0)\0A\09sw t0, 4($1)\0A\09lh t0, 8($0)\0A\09sh t0, 8($1)\0A\09", "r,r,~{x5}"(ptr [[TMP1]], ptr [[TMP0]])
; CHECK-NEXT:    br label %[[RETURN]]
; CHECK:       [[SW_BB10]]:
; CHECK-NEXT:    call void asm sideeffect "lw t0, 0($0)\0A\09sw t0, 0($1)\0A\09lw t0, 4($0)\0A\09sw t0, 4($1)\0A\09lh t0, 8($0)\0A\09sh t0, 8($1)\0A\09lb t0, 10($0)\0A\09sb t0, 10($1)\0A\09", "r,r,~{x5}"(ptr [[TMP1]], ptr [[TMP0]])
; CHECK-NEXT:    br label %[[RETURN]]
; CHECK:       [[SW_BB11]]:
; CHECK-NEXT:    call void asm sideeffect "lw t0, 0($0)\0A\09sw t0, 0($1)\0A\09lw t0, 4($0)\0A\09sw t0, 4($1)\0A\09lw t0, 8($0)\0A\09sw t0, 8($1)\0A\09", "r,r,~{x5}"(ptr [[TMP1]], ptr [[TMP0]])
; CHECK-NEXT:    br label %[[RETURN]]
; CHECK:       [[SW_BB12]]:
; CHECK-NEXT:    call void asm sideeffect "lw t0, 0($0)\0A\09sw t0, 0($1)\0A\09lw t0, 4($0)\0A\09sw t0, 4($1)\0A\09lw t0, 8($0)\0A\09sw t0, 8($1)\0A\09lb t0, 12($0)\0A\09sb t0, 12($1)\0A\09", "r,r,~{x5}"(ptr [[TMP1]], ptr [[TMP0]])
; CHECK-NEXT:    br label %[[RETURN]]
; CHECK:       [[SW_BB13]]:
; CHECK-NEXT:    call void asm sideeffect "lw t0, 0($0)\0A\09sw t0, 0($1)\0A\09lw t0, 4($0)\0A\09sw t0, 4($1)\0A\09lw t0, 8($0)\0A\09sw t0, 8($1)\0A\09lh t0, 12($0)\0A\09sh t0, 12($1)\0A\09", "r,r,~{x5}"(ptr [[TMP1]], ptr [[TMP0]])
; CHECK-NEXT:    br label %[[RETURN]]
; CHECK:       [[SW_BB14]]:
; CHECK-NEXT:    call void asm sideeffect "lw t0, 0($0)\0A\09sw t0, 0($1)\0A\09lw t0, 4($0)\0A\09sw t0, 4($1)\0A\09lw t0, 8($0)\0A\09sw t0, 8($1)\0A\09lh t0, 12($0)\0A\09sh t0, 12($1)\0A\09lb t0, 14($0)\0A\09sb t0, 14($1)\0A\09", "r,r,~{x5}"(ptr [[TMP1]], ptr [[TMP0]])
; CHECK-NEXT:    br label %[[RETURN]]
;

entry:
  switch i32 %2, label %return [
  i32 1, label %sw.bb0
  i32 2, label %sw.bb1
  i32 3, label %sw.bb2
  i32 4, label %sw.bb3
  i32 5, label %sw.bb4
  i32 6, label %sw.bb5
  i32 7, label %sw.bb6
  i32 8, label %sw.bb7
  i32 9, label %sw.bb8
  i32 10, label %sw.bb9
  i32 11, label %sw.bb10
  i32 12, label %sw.bb11
  i32 13, label %sw.bb12
  i32 14, label %sw.bb13
  i32 15, label %sw.bb14
  ]

return:                                           ; preds = %sw.bb14, %sw.bb13, %sw.bb12, %sw.bb11, %sw.bb10, %sw.bb9, %sw.bb8, %sw.bb7, %sw.bb6, %sw.bb5, %sw.bb4, %sw.bb3, %sw.bb2, %sw.bb1, %sw.bb0, %entry
  ret void

sw.bb0:                                           ; preds = %entry
  call void asm sideeffect "lb t0, 0($0)\0A\09sb t0, 0($1)\0A\09", "r,r,~{x5}"(ptr %1, ptr %0)
  br label %return

sw.bb1:                                           ; preds = %entry
  call void asm sideeffect "lh t0, 0($0)\0A\09sh t0, 0($1)\0A\09", "r,r,~{x5}"(ptr %1, ptr %0)
  br label %return

sw.bb2:                                           ; preds = %entry
  call void asm sideeffect "lh t0, 0($0)\0A\09sh t0, 0($1)\0A\09lb t0, 2($0)\0A\09sb t0, 2($1)\0A\09", "r,r,~{x5}"(ptr %1, ptr %0)
  br label %return

sw.bb3:                                           ; preds = %entry
  call void asm sideeffect "lw t0, 0($0)\0A\09sw t0, 0($1)\0A\09", "r,r,~{x5}"(ptr %1, ptr %0)
  br label %return

sw.bb4:                                           ; preds = %entry
  call void asm sideeffect "lw t0, 0($0)\0A\09sw t0, 0($1)\0A\09lb t0, 4($0)\0A\09sb t0, 4($1)\0A\09", "r,r,~{x5}"(ptr %1, ptr %0)
  br label %return

sw.bb5:                                           ; preds = %entry
  call void asm sideeffect "lw t0, 0($0)\0A\09sw t0, 0($1)\0A\09lh t0, 4($0)\0A\09sh t0, 4($1)\0A\09", "r,r,~{x5}"(ptr %1, ptr %0)
  br label %return

sw.bb6:                                           ; preds = %entry
  call void asm sideeffect "lw t0, 0($0)\0A\09sw t0, 0($1)\0A\09lh t0, 4($0)\0A\09sh t0, 4($1)\0A\09lb t0, 6($0)\0A\09sb t0, 6($1)\0A\09", "r,r,~{x5}"(ptr %1, ptr %0)
  br label %return

sw.bb7:                                           ; preds = %entry
  call void asm sideeffect "lw t0, 0($0)\0A\09sw t0, 0($1)\0A\09lw t0, 4($0)\0A\09sw t0, 4($1)\0A\09", "r,r,~{x5}"(ptr %1, ptr %0)
  br label %return

sw.bb8:                                           ; preds = %entry
  call void asm sideeffect "lw t0, 0($0)\0A\09sw t0, 0($1)\0A\09lw t0, 4($0)\0A\09sw t0, 4($1)\0A\09lb t0, 8($0)\0A\09sb t0, 8($1)\0A\09", "r,r,~{x5}"(ptr %1, ptr %0)
  br label %return

sw.bb9:                                           ; preds = %entry
  call void asm sideeffect "lw t0, 0($0)\0A\09sw t0, 0($1)\0A\09lw t0, 4($0)\0A\09sw t0, 4($1)\0A\09lh t0, 8($0)\0A\09sh t0, 8($1)\0A\09", "r,r,~{x5}"(ptr %1, ptr %0)
  br label %return

sw.bb10:                                          ; preds = %entry
  call void asm sideeffect "lw t0, 0($0)\0A\09sw t0, 0($1)\0A\09lw t0, 4($0)\0A\09sw t0, 4($1)\0A\09lh t0, 8($0)\0A\09sh t0, 8($1)\0A\09lb t0, 10($0)\0A\09sb t0, 10($1)\0A\09", "r,r,~{x5}"(ptr %1, ptr %0)
  br label %return

sw.bb11:                                          ; preds = %entry
  call void asm sideeffect "lw t0, 0($0)\0A\09sw t0, 0($1)\0A\09lw t0, 4($0)\0A\09sw t0, 4($1)\0A\09lw t0, 8($0)\0A\09sw t0, 8($1)\0A\09", "r,r,~{x5}"(ptr %1, ptr %0)
  br label %return

sw.bb12:                                          ; preds = %entry
  call void asm sideeffect "lw t0, 0($0)\0A\09sw t0, 0($1)\0A\09lw t0, 4($0)\0A\09sw t0, 4($1)\0A\09lw t0, 8($0)\0A\09sw t0, 8($1)\0A\09lb t0, 12($0)\0A\09sb t0, 12($1)\0A\09", "r,r,~{x5}"(ptr %1, ptr %0)
  br label %return

sw.bb13:                                          ; preds = %entry
  call void asm sideeffect "lw t0, 0($0)\0A\09sw t0, 0($1)\0A\09lw t0, 4($0)\0A\09sw t0, 4($1)\0A\09lw t0, 8($0)\0A\09sw t0, 8($1)\0A\09lh t0, 12($0)\0A\09sh t0, 12($1)\0A\09", "r,r,~{x5}"(ptr %1, ptr %0)
  br label %return

sw.bb14:                                          ; preds = %entry
  call void asm sideeffect "lw t0, 0($0)\0A\09sw t0, 0($1)\0A\09lw t0, 4($0)\0A\09sw t0, 4($1)\0A\09lw t0, 8($0)\0A\09sw t0, 8($1)\0A\09lh t0, 12($0)\0A\09sh t0, 12($1)\0A\09lb t0, 14($0)\0A\09sb t0, 14($1)\0A\09", "r,r,~{x5}"(ptr %1, ptr %0)
  br label %return
}

; Function Attrs: noinline nounwind
define internal void @esp32p4MemCpySrcunalignedDst16Var(i32 %dst, i32 %src, i32 %size) {
; CHECK-LABEL: define internal void @esp32p4MemCpySrcunalignedDst16Var(
; CHECK-SAME: i32 [[DST:%.*]], i32 [[SRC:%.*]], i32 [[SIZE:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*]]:
; CHECK-NEXT:    [[CMP:%.*]] = icmp ult i32 [[SIZE]], 16
; CHECK-NEXT:    br i1 [[CMP]], label %[[CLEANUP_OUT:.*]], label %[[IF_END:.*]]
; CHECK:       [[IF_END]]:
; CHECK-NEXT:    [[DIV:%.*]] = udiv i32 [[SIZE]], 48
; CHECK-NEXT:    [[TMP0:%.*]] = mul i32 [[DIV]], 48
; CHECK-NEXT:    [[REM_DECOMPOSED:%.*]] = sub i32 [[SIZE]], [[TMP0]]
; CHECK-NEXT:    call void asm sideeffect "esp.ld.128.usar.ip q0, $0, 16", "+{a1}"(i32 [[SRC]])
; CHECK-NEXT:    call void asm sideeffect "esp.ld.128.usar.ip q1, $0, 16", "+{a1}"(i32 [[SRC]])
; CHECK-NEXT:    [[CMP21_NOT:%.*]] = icmp ult i32 [[SIZE]], 48
; CHECK-NEXT:    br i1 [[CMP21_NOT]], label %[[FOR_COND_CLEANUP:.*]], label %[[FOR_BODY:.*]]
; CHECK:       [[FOR_COND_CLEANUP]]:
; CHECK-NEXT:    [[TOBOOL_NOT:%.*]] = icmp ult i32 [[REM_DECOMPOSED]], 32
; CHECK-NEXT:    br i1 [[TOBOOL_NOT]], label %[[IF_END3:.*]], label %[[IF_THEN2:.*]]
; CHECK:       [[FOR_BODY]]:
; CHECK-NEXT:    [[I_022:%.*]] = phi i32 [ 0, %[[IF_END]] ], [ [[INC:%.*]], %[[FOR_BODY]] ]
; CHECK-NEXT:    call void asm sideeffect "esp.src.q.ld.ip q2, $0, 16, q0, q1", "+{a1}"(i32 [[SRC]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q0, $0, 16", "+{a0}"(i32 [[DST]])
; CHECK-NEXT:    call void asm sideeffect "esp.src.q.ld.ip q0, $0, 16, q1, q2", "+{a1}"(i32 [[SRC]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q1, $0, 16", "+{a0}"(i32 [[DST]])
; CHECK-NEXT:    call void asm sideeffect "esp.src.q.ld.ip q1, $0, 16, q2, q0", "+{a1}"(i32 [[SRC]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q2, $0, 16", "+{a0}"(i32 [[DST]])
; CHECK-NEXT:    [[INC]] = add nuw nsw i32 [[I_022]], 1
; CHECK-NEXT:    [[EXITCOND_NOT:%.*]] = icmp eq i32 [[INC]], [[DIV]]
; CHECK-NEXT:    br i1 [[EXITCOND_NOT]], label %[[FOR_COND_CLEANUP]], label %[[FOR_BODY]]
; CHECK:       [[IF_THEN2]]:
; CHECK-NEXT:    call void asm sideeffect "esp.src.q.ld.ip q2, $0, 0, q0, q1", "+{a1}"(i32 [[SRC]])
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q0, $0, 16", "+{a0}"(i32 [[DST]])
; CHECK-NEXT:    call void asm sideeffect "esp.src.q q1, q1, q2", ""()
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q1, $0, 16", "+{a0}"(i32 [[DST]])
; CHECK-NEXT:    [[SUB1:%.*]] = add nsw i32 [[REM_DECOMPOSED]], -32
; CHECK-NEXT:    br label %[[CLEANUP_OUT]]
; CHECK:       [[IF_END3]]:
; CHECK-NEXT:    [[TOBOOL5_NOT:%.*]] = icmp ult i32 [[REM_DECOMPOSED]], 16
; CHECK-NEXT:    br i1 [[TOBOOL5_NOT]], label %[[IF_END7:.*]], label %[[IF_THEN6:.*]]
; CHECK:       [[IF_THEN6]]:
; CHECK-NEXT:    call void asm sideeffect "esp.src.q q0, q0, q1", ""()
; CHECK-NEXT:    call void asm sideeffect "esp.vst.128.ip q0, $0, 16", "+{a0}"(i32 [[DST]])
; CHECK-NEXT:    [[SUB:%.*]] = add i32 [[SRC]], -16
; CHECK-NEXT:    [[SUB9:%.*]] = add nsw i32 [[REM_DECOMPOSED]], -16
; CHECK-NEXT:    br label %[[CLEANUP_OUT]]
; CHECK:       [[IF_END7]]:
; CHECK-NEXT:    [[SUB8:%.*]] = add nsw i32 [[SRC]], -32
; CHECK-NEXT:    br label %[[CLEANUP_OUT]]
; CHECK:       [[CLEANUP_OUT]]:
; CHECK-NEXT:    [[SRC_SINK:%.*]] = phi i32 [ [[SRC]], %[[IF_THEN2]] ], [ [[SUB]], %[[IF_THEN6]] ], [ [[SRC]], %[[ENTRY]] ], [ [[SUB8]], %[[IF_END7]] ]
; CHECK-NEXT:    [[REM_SINK:%.*]] = phi i32 [ [[SIZE]], %[[ENTRY]] ], [ [[SUB1]], %[[IF_THEN2]] ], [ [[SUB9]], %[[IF_THEN6]] ], [ [[REM_DECOMPOSED]], %[[IF_END7]] ]
; CHECK-NEXT:    [[TMP1:%.*]] = inttoptr i32 [[DST]] to ptr
; CHECK-NEXT:    [[TMP2:%.*]] = inttoptr i32 [[SRC_SINK]] to ptr
; CHECK-NEXT:    call void @esp32p4MemCpySrcUnalignedDstUnalignedVarFrom0To15Opt(ptr [[TMP1]], ptr [[TMP2]], i32 [[REM_SINK]])
; CHECK-NEXT:    ret void
;

entry:
  %cmp = icmp ult i32 %size, 16
  br i1 %cmp, label %cleanup.out, label %if.end

if.end:                                           ; preds = %entry
  %div = udiv i32 %size, 48
  %0 = mul i32 %div, 48
  %rem.decomposed = sub i32 %size, %0
  call void asm sideeffect "esp.ld.128.usar.ip q0, $0, 16", "+{a1}"(i32 %src)
  call void asm sideeffect "esp.ld.128.usar.ip q1, $0, 16", "+{a1}"(i32 %src)
  %cmp21.not = icmp ult i32 %size, 48
  br i1 %cmp21.not, label %for.cond.cleanup, label %for.body

for.cond.cleanup:                                 ; preds = %for.body, %if.end
  %tobool.not = icmp ult i32 %rem.decomposed, 32
  br i1 %tobool.not, label %if.end3, label %if.then2

for.body:                                         ; preds = %for.body, %if.end
  %i.022 = phi i32 [ 0, %if.end ], [ %inc, %for.body ]
  call void asm sideeffect "esp.src.q.ld.ip q2, $0, 16, q0, q1", "+{a1}"(i32 %src)
  call void asm sideeffect "esp.vst.128.ip q0, $0, 16", "+{a0}"(i32 %dst)
  call void asm sideeffect "esp.src.q.ld.ip q0, $0, 16, q1, q2", "+{a1}"(i32 %src)
  call void asm sideeffect "esp.vst.128.ip q1, $0, 16", "+{a0}"(i32 %dst)
  call void asm sideeffect "esp.src.q.ld.ip q1, $0, 16, q2, q0", "+{a1}"(i32 %src)
  call void asm sideeffect "esp.vst.128.ip q2, $0, 16", "+{a0}"(i32 %dst)
  %inc = add nuw nsw i32 %i.022, 1
  %exitcond.not = icmp eq i32 %inc, %div
  br i1 %exitcond.not, label %for.cond.cleanup, label %for.body

if.then2:                                         ; preds = %for.cond.cleanup
  call void asm sideeffect "esp.src.q.ld.ip q2, $0, 0, q0, q1", "+{a1}"(i32 %src)
  call void asm sideeffect "esp.vst.128.ip q0, $0, 16", "+{a0}"(i32 %dst)
  call void asm sideeffect "esp.src.q q1, q1, q2", ""()
  call void asm sideeffect "esp.vst.128.ip q1, $0, 16", "+{a0}"(i32 %dst)
  %sub1 = add nsw i32 %rem.decomposed, -32
  br label %cleanup.out

if.end3:                                          ; preds = %for.cond.cleanup
  %tobool5.not = icmp ult i32 %rem.decomposed, 16
  br i1 %tobool5.not, label %if.end7, label %if.then6

if.then6:                                         ; preds = %if.end3
  call void asm sideeffect "esp.src.q q0, q0, q1", ""()
  call void asm sideeffect "esp.vst.128.ip q0, $0, 16", "+{a0}"(i32 %dst)
  %sub = add i32 %src, -16
  %sub9 = add nsw i32 %rem.decomposed, -16
  br label %cleanup.out

if.end7:                                          ; preds = %if.end3
  %sub8 = add nsw i32 %src, -32
  br label %cleanup.out

cleanup.out:                                      ; preds = %if.end7, %if.then6, %if.then2, %entry
  %src.sink = phi i32 [ %src, %if.then2 ], [ %sub, %if.then6 ], [ %src, %entry ], [ %sub8, %if.end7 ]
  %rem.sink = phi i32 [ %size, %entry ], [ %sub1, %if.then2 ], [ %sub9, %if.then6 ], [ %rem.decomposed, %if.end7 ]
  %1 = inttoptr i32 %dst to ptr
  %2 = inttoptr i32 %src.sink to ptr
  call void @esp32p4MemCpySrcUnalignedDstUnalignedVarFrom0To15Opt(ptr %1, ptr %2, i32 %rem.sink)
  ret void
}

declare void @llvm.memcpy.p0.p0.i32(ptr noalias nocapture writeonly, ptr noalias nocapture readonly, i32, i1 immarg)
