; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py UTC_ARGS: --version 5
; ModuleID = './riscv-esp32p4-load-store-1.c'
; Test ASM generation (Intrinsic -> ASM)
; RUN: llc -O2 -mcpu=esp32p4 -mtriple=riscv32 %s -o - | FileCheck %s --check-prefix=ASM

define dso_local void @test_ip(ptr noundef %src, ptr noundef %dst) local_unnamed_addr #0 {
; ASM-LABEL: test_ip:
; ASM:       # %bb.0: # %entry
; ASM-NEXT:    esp.vld.128.ip q0, a0, 16
; ASM-NEXT:    esp.vst.128.ip q0, a1, 16
; ASM-NEXT:    ret
entry:
  %0 = tail call { <16 x i8>, ptr } @llvm.riscv.esp.vld.128.ip.m(ptr %src, i32 16)
  %1 = extractvalue { <16 x i8>, ptr } %0, 0
  %2 = tail call ptr @llvm.riscv.esp.vst.128.ip.m(<16 x i8> %1, ptr %dst, i32 16)
  ret void
}

define dso_local void @test_xp(ptr noundef %src, ptr noundef %dst, i32 noundef %incr) local_unnamed_addr #0 {
; ASM-LABEL: test_xp:
; ASM:       # %bb.0: # %entry
; ASM-NEXT:    esp.vld.128.xp q0, a0, a2
; ASM-NEXT:    esp.vst.128.xp q0, a1, a2
; ASM-NEXT:    ret
entry:
  %0 = tail call { <16 x i8>, ptr } @llvm.riscv.esp.vld.128.xp.m(ptr %src, i32 %incr)
  %1 = extractvalue { <16 x i8>, ptr } %0, 0
  %2 = tail call ptr @llvm.riscv.esp.vst.128.xp.m(<16 x i8> %1, ptr %dst, i32 %incr)
  ret void
}

define dso_local ptr @test_ld_128_usar_ip(ptr noundef %src) local_unnamed_addr #1 {
; ASM-LABEL: test_ld_128_usar_ip:
; ASM:       # %bb.0: # %entry
; ASM-NEXT:    esp.ld.128.usar.ip q0, a0, 16
; ASM-NEXT:    ret
entry:
  %0 = tail call { <16 x i8>, ptr, i32 } @llvm.riscv.esp.ld.128.usar.ip.m(ptr %src, i32 16)
  %1 = extractvalue { <16 x i8>, ptr, i32 } %0, 1
  ret ptr %1
}

define dso_local ptr @test_ld_128_usar_xp(ptr noundef %src, i32 noundef %incr) local_unnamed_addr #1 {
; ASM-LABEL: test_ld_128_usar_xp:
; ASM:       # %bb.0: # %entry
; ASM-NEXT:    esp.ld.128.usar.xp q0, a0, a1
; ASM-NEXT:    ret
entry:
  %0 = tail call { <16 x i8>, ptr, i32 } @llvm.riscv.esp.ld.128.usar.xp.m(ptr %src, i32 %incr)
  %1 = extractvalue { <16 x i8>, ptr, i32 } %0, 1
  ret ptr %1
}

define dso_local void @test_vld_h_64_ip(ptr noundef %src, ptr noundef %dst) local_unnamed_addr #0 {
; ASM-LABEL: test_vld_h_64_ip:
; ASM:       # %bb.0: # %entry
; ASM-NEXT:    esp.vld.h.64.ip q0, a0, 8
; ASM-NEXT:    esp.vst.h.64.ip q0, a1, 8
; ASM-NEXT:    ret
entry:
  %0 = tail call { <8 x i8>, ptr } @llvm.riscv.esp.vld.h.64.ip.m(ptr %src, i32 8)
  %1 = extractvalue { <8 x i8>, ptr } %0, 0
  %2 = tail call ptr @llvm.riscv.esp.vst.h.64.ip.m(<8 x i8> %1, ptr %dst, i32 8)
  ret void
}

define dso_local void @test_vld_l_64_ip(ptr noundef %src, ptr noundef %dst) local_unnamed_addr #0 {
; ASM-LABEL: test_vld_l_64_ip:
; ASM:       # %bb.0: # %entry
; ASM-NEXT:    esp.vld.l.64.ip q0, a0, 8
; ASM-NEXT:    esp.vst.l.64.ip q0, a1, 8
; ASM-NEXT:    ret
entry:
  %0 = tail call { <8 x i8>, ptr } @llvm.riscv.esp.vld.l.64.ip.m(ptr %src, i32 8)
  %1 = extractvalue { <8 x i8>, ptr } %0, 0
  %2 = tail call ptr @llvm.riscv.esp.vst.l.64.ip.m(<8 x i8> %1, ptr %dst, i32 8)
  ret void
}

define dso_local void @test_vld_64_xp(ptr noundef %src, ptr noundef %dst, i32 noundef %incr) local_unnamed_addr #2 {
; ASM-LABEL: test_vld_64_xp:
; ASM:       # %bb.0: # %entry
; ASM-NEXT:    esp.vld.h.64.xp q0, a0, a2
; ASM-NEXT:    esp.vld.l.64.xp q1, a0, a2
; ASM-NEXT:    mv a0, a1
; ASM-NEXT:    esp.vst.h.64.xp q0, a0, a2
; ASM-NEXT:    esp.vst.l.64.xp q1, a1, a2
; ASM-NEXT:    ret
entry:
  %0 = tail call { <8 x i8>, ptr } @llvm.riscv.esp.vld.h.64.xp.m(ptr %src, i32 %incr)
  %1 = extractvalue { <8 x i8>, ptr } %0, 0
  %2 = extractvalue { <8 x i8>, ptr } %0, 1
  %3 = tail call { <8 x i8>, ptr } @llvm.riscv.esp.vld.l.64.xp.m(ptr %2, i32 %incr)
  %4 = extractvalue { <8 x i8>, ptr } %3, 0
  %5 = tail call ptr @llvm.riscv.esp.vst.h.64.xp.m(<8 x i8> %1, ptr %dst, i32 %incr)
  %6 = tail call ptr @llvm.riscv.esp.vst.l.64.xp.m(<8 x i8> %4, ptr %dst, i32 %incr)
  ret void
}

declare ptr @llvm.riscv.esp.vst.h.64.xp.m(<8 x i8>, ptr, i32) #3

declare ptr @llvm.riscv.esp.vst.l.64.xp.m(<8 x i8>, ptr, i32) #3

define dso_local void @test_vldbc_8_ip(ptr noundef %src, ptr noundef %dst) local_unnamed_addr #0 {
; ASM-LABEL: test_vldbc_8_ip:
; ASM:       # %bb.0: # %entry
; ASM-NEXT:    esp.vldbc.8.ip q0, a0, 1
; ASM-NEXT:    esp.vst.128.ip q0, a1, 16
; ASM-NEXT:    ret
entry:
  %0 = tail call { <16 x i8>, ptr } @llvm.riscv.esp.vldbc.8.ip.m(ptr %src, i32 1)
  %1 = extractvalue { <16 x i8>, ptr } %0, 0
  %2 = tail call ptr @llvm.riscv.esp.vst.128.ip.m(<16 x i8> %1, ptr %dst, i32 16)
  ret void
}

define dso_local void @test_vldbc_16_ip(ptr noundef %src, ptr noundef %dst) local_unnamed_addr #0 {
; ASM-LABEL: test_vldbc_16_ip:
; ASM:       # %bb.0: # %entry
; ASM-NEXT:    esp.vldbc.16.ip q0, a0, 2
; ASM-NEXT:    esp.vst.128.ip q0, a1, 16
; ASM-NEXT:    ret
entry:
  %0 = tail call { <8 x i16>, ptr } @llvm.riscv.esp.vldbc.16.ip.m(ptr %src, i32 2)
  %1 = extractvalue { <8 x i16>, ptr } %0, 0
  %2 = bitcast <8 x i16> %1 to <16 x i8>
  %3 = tail call ptr @llvm.riscv.esp.vst.128.ip.m(<16 x i8> %2, ptr %dst, i32 16)
  ret void
}

define dso_local void @test_vldbc_32_ip(ptr noundef %src, ptr noundef %dst) local_unnamed_addr #0 {
; ASM-LABEL: test_vldbc_32_ip:
; ASM:       # %bb.0: # %entry
; ASM-NEXT:    esp.vldbc.32.ip q0, a0, 4
; ASM-NEXT:    esp.vst.128.ip q0, a1, 16
; ASM-NEXT:    ret
entry:
  %0 = tail call { <4 x i32>, ptr } @llvm.riscv.esp.vldbc.32.ip.m(ptr %src, i32 4)
  %1 = extractvalue { <4 x i32>, ptr } %0, 0
  %2 = bitcast <4 x i32> %1 to <16 x i8>
  %3 = tail call ptr @llvm.riscv.esp.vst.128.ip.m(<16 x i8> %2, ptr %dst, i32 16)
  ret void
}

define dso_local void @test_vldbc_8_xp(ptr noundef %src, ptr noundef %dst, i32 noundef %incr) local_unnamed_addr #0 {
; ASM-LABEL: test_vldbc_8_xp:
; ASM:       # %bb.0: # %entry
; ASM-NEXT:    esp.vldbc.8.xp q0, a0, a2
; ASM-NEXT:    esp.vst.128.ip q0, a1, 16
; ASM-NEXT:    ret
entry:
  %0 = tail call { <16 x i8>, ptr } @llvm.riscv.esp.vldbc.8.xp.m(ptr %src, i32 %incr)
  %1 = extractvalue { <16 x i8>, ptr } %0, 0
  %2 = tail call ptr @llvm.riscv.esp.vst.128.ip.m(<16 x i8> %1, ptr %dst, i32 16)
  ret void
}

define dso_local void @test_vldbc_16_xp(ptr noundef %src, ptr noundef %dst, i32 noundef %incr) local_unnamed_addr #0 {
; ASM-LABEL: test_vldbc_16_xp:
; ASM:       # %bb.0: # %entry
; ASM-NEXT:    esp.vldbc.16.xp q0, a0, a2
; ASM-NEXT:    esp.vst.128.ip q0, a1, 16
; ASM-NEXT:    ret
entry:
  %0 = tail call { <8 x i16>, ptr } @llvm.riscv.esp.vldbc.16.xp.m(ptr %src, i32 %incr)
  %1 = extractvalue { <8 x i16>, ptr } %0, 0
  %2 = bitcast <8 x i16> %1 to <16 x i8>
  %3 = tail call ptr @llvm.riscv.esp.vst.128.ip.m(<16 x i8> %2, ptr %dst, i32 16)
  ret void
}

define dso_local void @test_vldbc_32_xp(ptr noundef %src, ptr noundef %dst, i32 noundef %incr) local_unnamed_addr #0 {
; ASM-LABEL: test_vldbc_32_xp:
; ASM:       # %bb.0: # %entry
; ASM-NEXT:    esp.vldbc.32.xp q0, a0, a2
; ASM-NEXT:    esp.vst.128.ip q0, a1, 16
; ASM-NEXT:    ret
entry:
  %0 = tail call { <4 x i32>, ptr } @llvm.riscv.esp.vldbc.32.xp.m(ptr %src, i32 %incr)
  %1 = extractvalue { <4 x i32>, ptr } %0, 0
  %2 = bitcast <4 x i32> %1 to <16 x i8>
  %3 = tail call ptr @llvm.riscv.esp.vst.128.ip.m(<16 x i8> %2, ptr %dst, i32 16)
  ret void
}

define dso_local void @test_vldext_s8_ip(ptr noundef %src, ptr noundef %dst1, ptr noundef %dst2) local_unnamed_addr #0 {
; ASM-LABEL: test_vldext_s8_ip:
; ASM:       # %bb.0: # %entry
; ASM-NEXT:    esp.vldext.s8.ip q0, q1, a0, 16
; ASM-NEXT:    esp.vst.128.ip q0, a1, 16
; ASM-NEXT:    esp.vst.128.ip q1, a2, 16
; ASM-NEXT:    ret
entry:
  %0 = tail call { <8 x i16>, <8 x i16>, ptr } @llvm.riscv.esp.vldext.s8.ip.m(ptr %src, i32 16)
  %1 = extractvalue { <8 x i16>, <8 x i16>, ptr } %0, 0
  %2 = extractvalue { <8 x i16>, <8 x i16>, ptr } %0, 1
  %3 = bitcast <8 x i16> %1 to <16 x i8>
  %4 = tail call ptr @llvm.riscv.esp.vst.128.ip.m(<16 x i8> %3, ptr %dst1, i32 16)
  %5 = bitcast <8 x i16> %2 to <16 x i8>
  %6 = tail call ptr @llvm.riscv.esp.vst.128.ip.m(<16 x i8> %5, ptr %dst2, i32 16)
  ret void
}

define dso_local void @test_vldext_s16_ip(ptr noundef %src, ptr noundef %dst1, ptr noundef %dst2) local_unnamed_addr #0 {
; ASM-LABEL: test_vldext_s16_ip:
; ASM:       # %bb.0: # %entry
; ASM-NEXT:    esp.vldext.s16.ip q0, q1, a0, 16
; ASM-NEXT:    esp.vst.128.ip q0, a1, 16
; ASM-NEXT:    esp.vst.128.ip q1, a2, 16
; ASM-NEXT:    ret
entry:
  %0 = tail call { <4 x i32>, <4 x i32>, ptr } @llvm.riscv.esp.vldext.s16.ip.m(ptr %src, i32 16)
  %1 = extractvalue { <4 x i32>, <4 x i32>, ptr } %0, 0
  %2 = extractvalue { <4 x i32>, <4 x i32>, ptr } %0, 1
  %3 = bitcast <4 x i32> %1 to <16 x i8>
  %4 = tail call ptr @llvm.riscv.esp.vst.128.ip.m(<16 x i8> %3, ptr %dst1, i32 16)
  %5 = bitcast <4 x i32> %2 to <16 x i8>
  %6 = tail call ptr @llvm.riscv.esp.vst.128.ip.m(<16 x i8> %5, ptr %dst2, i32 16)
  ret void
}

define dso_local void @test_vldext_u16_ip(ptr noundef %src, ptr noundef %dst1, ptr noundef %dst2) local_unnamed_addr #0 {
; ASM-LABEL: test_vldext_u16_ip:
; ASM:       # %bb.0: # %entry
; ASM-NEXT:    esp.vldext.u16.ip q0, q1, a0, 16
; ASM-NEXT:    esp.vst.128.ip q0, a1, 16
; ASM-NEXT:    esp.vst.128.ip q1, a2, 16
; ASM-NEXT:    ret
entry:
  %0 = tail call { <4 x i32>, <4 x i32>, ptr } @llvm.riscv.esp.vldext.u16.ip.m(ptr %src, i32 16)
  %1 = extractvalue { <4 x i32>, <4 x i32>, ptr } %0, 0
  %2 = extractvalue { <4 x i32>, <4 x i32>, ptr } %0, 1
  %3 = bitcast <4 x i32> %1 to <16 x i8>
  %4 = tail call ptr @llvm.riscv.esp.vst.128.ip.m(<16 x i8> %3, ptr %dst1, i32 16)
  %5 = bitcast <4 x i32> %2 to <16 x i8>
  %6 = tail call ptr @llvm.riscv.esp.vst.128.ip.m(<16 x i8> %5, ptr %dst2, i32 16)
  ret void
}

define dso_local void @test_vldext_s8_xp(ptr noundef %src, ptr noundef %dst1, ptr noundef %dst2, i32 noundef %incr) local_unnamed_addr #0 {
; ASM-LABEL: test_vldext_s8_xp:
; ASM:       # %bb.0: # %entry
; ASM-NEXT:    esp.vldext.s8.xp q0, q1, a0, a3
; ASM-NEXT:    esp.vst.128.ip q0, a1, 16
; ASM-NEXT:    esp.vst.128.ip q1, a2, 16
; ASM-NEXT:    ret
entry:
  %0 = tail call { <8 x i16>, <8 x i16>, ptr } @llvm.riscv.esp.vldext.s8.xp.m(ptr %src, i32 %incr)
  %1 = extractvalue { <8 x i16>, <8 x i16>, ptr } %0, 0
  %2 = extractvalue { <8 x i16>, <8 x i16>, ptr } %0, 1
  %3 = bitcast <8 x i16> %1 to <16 x i8>
  %4 = tail call ptr @llvm.riscv.esp.vst.128.ip.m(<16 x i8> %3, ptr %dst1, i32 16)
  %5 = bitcast <8 x i16> %2 to <16 x i8>
  %6 = tail call ptr @llvm.riscv.esp.vst.128.ip.m(<16 x i8> %5, ptr %dst2, i32 16)
  ret void
}

define dso_local void @test_vldext_s16_xp(ptr noundef %src, ptr noundef %dst1, ptr noundef %dst2, i32 noundef %incr) local_unnamed_addr #0 {
; ASM-LABEL: test_vldext_s16_xp:
; ASM:       # %bb.0: # %entry
; ASM-NEXT:    esp.vldext.s16.xp q0, q1, a0, a3
; ASM-NEXT:    esp.vst.128.ip q0, a1, 16
; ASM-NEXT:    esp.vst.128.ip q1, a2, 16
; ASM-NEXT:    ret
entry:
  %0 = tail call { <4 x i32>, <4 x i32>, ptr } @llvm.riscv.esp.vldext.s16.xp.m(ptr %src, i32 %incr)
  %1 = extractvalue { <4 x i32>, <4 x i32>, ptr } %0, 0
  %2 = extractvalue { <4 x i32>, <4 x i32>, ptr } %0, 1
  %3 = bitcast <4 x i32> %1 to <16 x i8>
  %4 = tail call ptr @llvm.riscv.esp.vst.128.ip.m(<16 x i8> %3, ptr %dst1, i32 16)
  %5 = bitcast <4 x i32> %2 to <16 x i8>
  %6 = tail call ptr @llvm.riscv.esp.vst.128.ip.m(<16 x i8> %5, ptr %dst2, i32 16)
  ret void
}

define dso_local void @test_vldext_u8_xp(ptr noundef %src, ptr noundef %dst1, ptr noundef %dst2, i32 noundef %incr) local_unnamed_addr #0 {
; ASM-LABEL: test_vldext_u8_xp:
; ASM:       # %bb.0: # %entry
; ASM-NEXT:    esp.vldext.u8.xp q0, q1, a0, a3
; ASM-NEXT:    esp.vst.128.ip q0, a1, 16
; ASM-NEXT:    esp.vst.128.ip q1, a2, 16
; ASM-NEXT:    ret
entry:
  %0 = tail call { <8 x i16>, <8 x i16>, ptr } @llvm.riscv.esp.vldext.u8.xp.m(ptr %src, i32 %incr)
  %1 = extractvalue { <8 x i16>, <8 x i16>, ptr } %0, 0
  %2 = extractvalue { <8 x i16>, <8 x i16>, ptr } %0, 1
  %3 = bitcast <8 x i16> %1 to <16 x i8>
  %4 = tail call ptr @llvm.riscv.esp.vst.128.ip.m(<16 x i8> %3, ptr %dst1, i32 16)
  %5 = bitcast <8 x i16> %2 to <16 x i8>
  %6 = tail call ptr @llvm.riscv.esp.vst.128.ip.m(<16 x i8> %5, ptr %dst2, i32 16)
  ret void
}

define dso_local void @test_vldext_u16_xp(ptr noundef %src, ptr noundef %dst1, ptr noundef %dst2, i32 noundef %incr) local_unnamed_addr #0 {
; ASM-LABEL: test_vldext_u16_xp:
; ASM:       # %bb.0: # %entry
; ASM-NEXT:    esp.vldext.u16.xp q0, q1, a0, a3
; ASM-NEXT:    esp.vst.128.ip q0, a1, 16
; ASM-NEXT:    esp.vst.128.ip q1, a2, 16
; ASM-NEXT:    ret
entry:
  %0 = tail call { <4 x i32>, <4 x i32>, ptr } @llvm.riscv.esp.vldext.u16.xp.m(ptr %src, i32 %incr)
  %1 = extractvalue { <4 x i32>, <4 x i32>, ptr } %0, 0
  %2 = extractvalue { <4 x i32>, <4 x i32>, ptr } %0, 1
  %3 = bitcast <4 x i32> %1 to <16 x i8>
  %4 = tail call ptr @llvm.riscv.esp.vst.128.ip.m(<16 x i8> %3, ptr %dst1, i32 16)
  %5 = bitcast <4 x i32> %2 to <16 x i8>
  %6 = tail call ptr @llvm.riscv.esp.vst.128.ip.m(<16 x i8> %5, ptr %dst2, i32 16)
  ret void
}

declare { <16 x i8>, ptr } @llvm.riscv.esp.vld.128.ip.m(ptr, i32) #4

declare ptr @llvm.riscv.esp.vst.128.ip.m(<16 x i8>, ptr, i32) #3

declare { <16 x i8>, ptr } @llvm.riscv.esp.vld.128.xp.m(ptr, i32) #4

declare ptr @llvm.riscv.esp.vst.128.xp.m(<16 x i8>, ptr, i32) #3

declare { <16 x i8>, ptr, i32 } @llvm.riscv.esp.ld.128.usar.ip.m(ptr, i32) #4

declare { <16 x i8>, ptr, i32 } @llvm.riscv.esp.ld.128.usar.xp.m(ptr, i32) #4

declare { <8 x i8>, ptr } @llvm.riscv.esp.vld.h.64.ip.m(ptr, i32) #4

declare ptr @llvm.riscv.esp.vst.h.64.ip.m(<8 x i8>, ptr, i32) #3

declare { <8 x i8>, ptr } @llvm.riscv.esp.vld.l.64.ip.m(ptr, i32) #4

declare ptr @llvm.riscv.esp.vst.l.64.ip.m(<8 x i8>, ptr, i32) #3

declare { <8 x i8>, ptr } @llvm.riscv.esp.vld.h.64.xp.m(ptr, i32) #4

declare { <8 x i8>, ptr } @llvm.riscv.esp.vld.l.64.xp.m(ptr, i32) #4

declare { <16 x i8>, ptr } @llvm.riscv.esp.vldbc.8.ip.m(ptr, i32) #4

declare { <8 x i16>, ptr } @llvm.riscv.esp.vldbc.16.ip.m(ptr, i32) #4

declare { <4 x i32>, ptr } @llvm.riscv.esp.vldbc.32.ip.m(ptr, i32) #4

declare { <16 x i8>, ptr } @llvm.riscv.esp.vldbc.8.xp.m(ptr, i32) #4

declare { <8 x i16>, ptr } @llvm.riscv.esp.vldbc.16.xp.m(ptr, i32) #4

declare { <4 x i32>, ptr } @llvm.riscv.esp.vldbc.32.xp.m(ptr, i32) #4

declare { <8 x i16>, <8 x i16>, ptr } @llvm.riscv.esp.vldext.s8.ip.m(ptr, i32) #4

declare { <4 x i32>, <4 x i32>, ptr } @llvm.riscv.esp.vldext.s16.ip.m(ptr, i32) #4

declare { <4 x i32>, <4 x i32>, ptr } @llvm.riscv.esp.vldext.u16.ip.m(ptr, i32) #4

declare { <8 x i16>, <8 x i16>, ptr } @llvm.riscv.esp.vldext.s8.xp.m(ptr, i32) #4

declare { <4 x i32>, <4 x i32>, ptr } @llvm.riscv.esp.vldext.s16.xp.m(ptr, i32) #4

declare { <8 x i16>, <8 x i16>, ptr } @llvm.riscv.esp.vldext.u8.xp.m(ptr, i32) #4

declare { <4 x i32>, <4 x i32>, ptr } @llvm.riscv.esp.vldext.u16.xp.m(ptr, i32) #4

attributes #0 = { nounwind }
attributes #1 = { nounwind }
attributes #2 = { nounwind }
attributes #3 = { nounwind }
attributes #4 = { nounwind }

