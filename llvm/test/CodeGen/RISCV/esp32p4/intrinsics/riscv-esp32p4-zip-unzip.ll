; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py UTC_ARGS: --version 5
; ModuleID = './riscv-esp32p4-zip-unzip.c'
; Test ASM generation (Intrinsic -> ASM)
; RUN: llc -O2 -mcpu=esp32p4 -mtriple=riscv32 %s -o - | FileCheck %s --check-prefix=ASM

define dso_local void @test_vzip_8(ptr noundef %src1, ptr noundef %src2, ptr noundef %dst1, ptr noundef %dst2) local_unnamed_addr #0 {
; ASM-LABEL: test_vzip_8:
; ASM:       # %bb.0: # %entry
; ASM-NEXT:    esp.vld.128.ip q0, a0, 16
; ASM-NEXT:    esp.vld.128.ip q1, a1, 16
; ASM-NEXT:    esp.vzip.8 q0, q1
; ASM-NEXT:    esp.vst.128.ip q0, a2, 16
; ASM-NEXT:    esp.vst.128.ip q1, a3, 16
; ASM-NEXT:    ret
entry:
  %0 = tail call { <16 x i8>, ptr } @llvm.riscv.esp.vld.128.ip.m(ptr %src1, i32 16)
  %1 = extractvalue { <16 x i8>, ptr } %0, 0
  %2 = tail call { <16 x i8>, ptr } @llvm.riscv.esp.vld.128.ip.m(ptr %src2, i32 16)
  %3 = extractvalue { <16 x i8>, ptr } %2, 0
  %4 = tail call { <16 x i8>, <16 x i8> } @llvm.riscv.esp.vzip.8.m(<16 x i8> %1, <16 x i8> %3)
  %5 = extractvalue { <16 x i8>, <16 x i8> } %4, 0
  %6 = extractvalue { <16 x i8>, <16 x i8> } %4, 1
  %7 = tail call ptr @llvm.riscv.esp.vst.128.ip.m(<16 x i8> %5, ptr %dst1, i32 16)
  %8 = tail call ptr @llvm.riscv.esp.vst.128.ip.m(<16 x i8> %6, ptr %dst2, i32 16)
  ret void
}

define dso_local void @test_vunzip_8(ptr noundef %src1, ptr noundef %src2, ptr noundef %dst1, ptr noundef %dst2) local_unnamed_addr #0 {
; ASM-LABEL: test_vunzip_8:
; ASM:       # %bb.0: # %entry
; ASM-NEXT:    esp.vld.128.ip q0, a0, 16
; ASM-NEXT:    esp.vld.128.ip q1, a1, 16
; ASM-NEXT:    esp.vunzip.8 q0, q1
; ASM-NEXT:    esp.vst.128.ip q0, a2, 16
; ASM-NEXT:    esp.vst.128.ip q1, a3, 16
; ASM-NEXT:    ret
entry:
  %0 = tail call { <16 x i8>, ptr } @llvm.riscv.esp.vld.128.ip.m(ptr %src1, i32 16)
  %1 = extractvalue { <16 x i8>, ptr } %0, 0
  %2 = tail call { <16 x i8>, ptr } @llvm.riscv.esp.vld.128.ip.m(ptr %src2, i32 16)
  %3 = extractvalue { <16 x i8>, ptr } %2, 0
  %4 = tail call { <16 x i8>, <16 x i8> } @llvm.riscv.esp.vunzip.8.m(<16 x i8> %1, <16 x i8> %3)
  %5 = extractvalue { <16 x i8>, <16 x i8> } %4, 0
  %6 = extractvalue { <16 x i8>, <16 x i8> } %4, 1
  %7 = tail call ptr @llvm.riscv.esp.vst.128.ip.m(<16 x i8> %5, ptr %dst1, i32 16)
  %8 = tail call ptr @llvm.riscv.esp.vst.128.ip.m(<16 x i8> %6, ptr %dst2, i32 16)
  ret void
}

define dso_local void @test_vzip_16(ptr noundef %src1, ptr noundef %src2, ptr noundef %dst1, ptr noundef %dst2) local_unnamed_addr #0 {
; ASM-LABEL: test_vzip_16:
; ASM:       # %bb.0: # %entry
; ASM-NEXT:    esp.vld.128.ip q0, a0, 16
; ASM-NEXT:    esp.vld.128.ip q1, a1, 16
; ASM-NEXT:    esp.vzip.16 q0, q1
; ASM-NEXT:    esp.vst.128.ip q0, a2, 16
; ASM-NEXT:    esp.vst.128.ip q1, a3, 16
; ASM-NEXT:    ret
entry:
  %0 = tail call { <16 x i8>, ptr } @llvm.riscv.esp.vld.128.ip.m(ptr %src1, i32 16)
  %1 = extractvalue { <16 x i8>, ptr } %0, 0
  %2 = bitcast <16 x i8> %1 to <8 x i16>
  %3 = tail call { <16 x i8>, ptr } @llvm.riscv.esp.vld.128.ip.m(ptr %src2, i32 16)
  %4 = extractvalue { <16 x i8>, ptr } %3, 0
  %5 = bitcast <16 x i8> %4 to <8 x i16>
  %6 = tail call { <8 x i16>, <8 x i16> } @llvm.riscv.esp.vzip.16.m(<8 x i16> %2, <8 x i16> %5)
  %7 = extractvalue { <8 x i16>, <8 x i16> } %6, 0
  %8 = extractvalue { <8 x i16>, <8 x i16> } %6, 1
  %9 = bitcast <8 x i16> %7 to <16 x i8>
  %10 = bitcast <8 x i16> %8 to <16 x i8>
  %11 = tail call ptr @llvm.riscv.esp.vst.128.ip.m(<16 x i8> %9, ptr %dst1, i32 16)
  %12 = tail call ptr @llvm.riscv.esp.vst.128.ip.m(<16 x i8> %10, ptr %dst2, i32 16)
  ret void
}

define dso_local void @test_vzip_32(ptr noundef %src1, ptr noundef %src2, ptr noundef %dst1, ptr noundef %dst2) local_unnamed_addr #0 {
; ASM-LABEL: test_vzip_32:
; ASM:       # %bb.0: # %entry
; ASM-NEXT:    esp.vld.128.ip q0, a0, 16
; ASM-NEXT:    esp.vld.128.ip q1, a1, 16
; ASM-NEXT:    esp.vzip.32 q0, q1
; ASM-NEXT:    esp.vst.128.ip q0, a2, 16
; ASM-NEXT:    esp.vst.128.ip q1, a3, 16
; ASM-NEXT:    ret
entry:
  %0 = tail call { <16 x i8>, ptr } @llvm.riscv.esp.vld.128.ip.m(ptr %src1, i32 16)
  %1 = extractvalue { <16 x i8>, ptr } %0, 0
  %2 = bitcast <16 x i8> %1 to <4 x i32>
  %3 = tail call { <16 x i8>, ptr } @llvm.riscv.esp.vld.128.ip.m(ptr %src2, i32 16)
  %4 = extractvalue { <16 x i8>, ptr } %3, 0
  %5 = bitcast <16 x i8> %4 to <4 x i32>
  %6 = tail call { <4 x i32>, <4 x i32> } @llvm.riscv.esp.vzip.32.m(<4 x i32> %2, <4 x i32> %5)
  %7 = extractvalue { <4 x i32>, <4 x i32> } %6, 0
  %8 = extractvalue { <4 x i32>, <4 x i32> } %6, 1
  %9 = bitcast <4 x i32> %7 to <16 x i8>
  %10 = bitcast <4 x i32> %8 to <16 x i8>
  %11 = tail call ptr @llvm.riscv.esp.vst.128.ip.m(<16 x i8> %9, ptr %dst1, i32 16)
  %12 = tail call ptr @llvm.riscv.esp.vst.128.ip.m(<16 x i8> %10, ptr %dst2, i32 16)
  ret void
}

define dso_local void @test_vzipt_8(ptr noundef %src1, ptr noundef %src2, ptr noundef %src3, ptr noundef %dst1, ptr noundef %dst2, ptr noundef %dst3) local_unnamed_addr #0 {
; ASM-LABEL: test_vzipt_8:
; ASM:       # %bb.0: # %entry
; ASM-NEXT:    esp.vld.128.ip q0, a0, 16
; ASM-NEXT:    esp.vld.128.ip q1, a1, 16
; ASM-NEXT:    esp.vld.128.ip q2, a2, 16
; ASM-NEXT:    esp.vzipt.8 q0, q1, q2
; ASM-NEXT:    esp.vst.128.ip q0, a3, 16
; ASM-NEXT:    esp.vst.128.ip q1, a4, 16
; ASM-NEXT:    esp.vst.128.ip q2, a5, 16
; ASM-NEXT:    ret
entry:
  %0 = tail call { <16 x i8>, ptr } @llvm.riscv.esp.vld.128.ip.m(ptr %src1, i32 16)
  %1 = extractvalue { <16 x i8>, ptr } %0, 0
  %2 = tail call { <16 x i8>, ptr } @llvm.riscv.esp.vld.128.ip.m(ptr %src2, i32 16)
  %3 = extractvalue { <16 x i8>, ptr } %2, 0
  %4 = tail call { <16 x i8>, ptr } @llvm.riscv.esp.vld.128.ip.m(ptr %src3, i32 16)
  %5 = extractvalue { <16 x i8>, ptr } %4, 0
  %6 = tail call { <16 x i8>, <16 x i8>, <16 x i8> } @llvm.riscv.esp.vzipt.8.m(<16 x i8> %1, <16 x i8> %3, <16 x i8> %5)
  %7 = extractvalue { <16 x i8>, <16 x i8>, <16 x i8> } %6, 0
  %8 = extractvalue { <16 x i8>, <16 x i8>, <16 x i8> } %6, 1
  %9 = extractvalue { <16 x i8>, <16 x i8>, <16 x i8> } %6, 2
  %10 = tail call ptr @llvm.riscv.esp.vst.128.ip.m(<16 x i8> %7, ptr %dst1, i32 16)
  %11 = tail call ptr @llvm.riscv.esp.vst.128.ip.m(<16 x i8> %8, ptr %dst2, i32 16)
  %12 = tail call ptr @llvm.riscv.esp.vst.128.ip.m(<16 x i8> %9, ptr %dst3, i32 16)
  ret void
}

declare { <16 x i8>, ptr } @llvm.riscv.esp.vld.128.ip.m(ptr, i32) #1

declare { <16 x i8>, <16 x i8> } @llvm.riscv.esp.vzip.8.m(<16 x i8>, <16 x i8>) #2

declare ptr @llvm.riscv.esp.vst.128.ip.m(<16 x i8>, ptr, i32) #3

declare { <16 x i8>, <16 x i8> } @llvm.riscv.esp.vunzip.8.m(<16 x i8>, <16 x i8>) #2

declare { <8 x i16>, <8 x i16> } @llvm.riscv.esp.vzip.16.m(<8 x i16>, <8 x i16>) #2

declare { <4 x i32>, <4 x i32> } @llvm.riscv.esp.vzip.32.m(<4 x i32>, <4 x i32>) #2

declare { <16 x i8>, <16 x i8>, <16 x i8> } @llvm.riscv.esp.vzipt.8.m(<16 x i8>, <16 x i8>, <16 x i8>) #2

attributes #0 = { "target-features"="+32bit,+xespv" }
attributes #1 = { nounwind }
attributes #2 = { nounwind }
attributes #3 = { nounwind }


