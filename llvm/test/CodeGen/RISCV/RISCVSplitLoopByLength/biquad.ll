; NOTE: Assertions have been autogenerated by utils/update_test_checks.py UTC_ARGS: --version 4
; RUN: opt -S -mtriple=riscv32-esp-unknown-elf -passes=riscv-split-loop-by-length -riscv-split-loop-by-length=false < %s | FileCheck %s
; Function Attrs: nofree norecurse nosync nounwind memory(argmem: readwrite)
define dso_local noundef i32 @dsps_biquad_f32_ansi(ptr nocapture noundef readonly %input, ptr nocapture noundef writeonly %output, i32 noundef %len, ptr nocapture noundef readonly %coef, ptr nocapture noundef %w) local_unnamed_addr {
; CHECK-LABEL: define dso_local noundef i32 @dsps_biquad_f32_ansi(
; CHECK-SAME: ptr nocapture noundef readonly [[INPUT:%.*]], ptr nocapture noundef writeonly [[OUTPUT:%.*]], i32 noundef [[LEN:%.*]], ptr nocapture noundef readonly [[COEF:%.*]], ptr nocapture noundef [[W:%.*]]) local_unnamed_addr {
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[CMP30:%.*]] = icmp sgt i32 [[LEN]], 0
; CHECK-NEXT:    br i1 [[CMP30]], label [[FOR_BODY_LR_PH:%.*]], label [[FOR_COND_CLEANUP:%.*]]
; CHECK:       for.body.lr.ph:
; CHECK-NEXT:    [[ARRAYIDX1:%.*]] = getelementptr inbounds float, ptr [[COEF]], i32 3
; CHECK-NEXT:    [[ARRAYIDX3:%.*]] = getelementptr inbounds float, ptr [[COEF]], i32 4
; CHECK-NEXT:    [[ARRAYIDX4:%.*]] = getelementptr inbounds float, ptr [[W]], i32 1
; CHECK-NEXT:    [[ARRAYIDX7:%.*]] = getelementptr inbounds float, ptr [[COEF]], i32 1
; CHECK-NEXT:    [[ARRAYIDX10:%.*]] = getelementptr inbounds float, ptr [[COEF]], i32 2
; CHECK-NEXT:    [[DOTPRE:%.*]] = load float, ptr [[W]], align 4
; CHECK-NEXT:    [[DOTPRE32:%.*]] = load float, ptr [[ARRAYIDX4]], align 4
; CHECK-NEXT:    br label [[FOR_BODY:%.*]]
; CHECK:       for.cond.cleanup:
; CHECK-NEXT:    ret i32 0
; CHECK:       for.body:
; CHECK-NEXT:    [[TMP0:%.*]] = phi float [ [[DOTPRE32]], [[FOR_BODY_LR_PH]] ], [ [[TMP12:%.*]], [[FOR_BODY]] ]
; CHECK-NEXT:    [[TMP1:%.*]] = phi float [ [[DOTPRE]], [[FOR_BODY_LR_PH]] ], [ [[TMP6:%.*]], [[FOR_BODY]] ]
; CHECK-NEXT:    [[I_031:%.*]] = phi i32 [ 0, [[FOR_BODY_LR_PH]] ], [ [[INC:%.*]], [[FOR_BODY]] ]
; CHECK-NEXT:    [[ARRAYIDX:%.*]] = getelementptr inbounds float, ptr [[INPUT]], i32 [[I_031]]
; CHECK-NEXT:    [[TMP2:%.*]] = load float, ptr [[ARRAYIDX]], align 4
; CHECK-NEXT:    [[TMP3:%.*]] = load float, ptr [[ARRAYIDX1]], align 4
; CHECK-NEXT:    [[NEG:%.*]] = fneg float [[TMP3]]
; CHECK-NEXT:    [[TMP4:%.*]] = tail call float @llvm.fmuladd.f32(float [[NEG]], float [[TMP1]], float [[TMP2]])
; CHECK-NEXT:    [[TMP5:%.*]] = load float, ptr [[ARRAYIDX3]], align 4
; CHECK-NEXT:    [[NEG5:%.*]] = fneg float [[TMP5]]
; CHECK-NEXT:    [[TMP6]] = tail call float @llvm.fmuladd.f32(float [[NEG5]], float [[TMP0]], float [[TMP4]])
; CHECK-NEXT:    [[TMP7:%.*]] = load float, ptr [[COEF]], align 4
; CHECK-NEXT:    [[TMP8:%.*]] = load float, ptr [[ARRAYIDX7]], align 4
; CHECK-NEXT:    [[MUL9:%.*]] = fmul float [[TMP1]], [[TMP8]]
; CHECK-NEXT:    [[TMP9:%.*]] = tail call float @llvm.fmuladd.f32(float [[TMP7]], float [[TMP6]], float [[MUL9]])
; CHECK-NEXT:    [[TMP10:%.*]] = load float, ptr [[ARRAYIDX10]], align 4
; CHECK-NEXT:    [[TMP11:%.*]] = tail call float @llvm.fmuladd.f32(float [[TMP10]], float [[TMP0]], float [[TMP9]])
; CHECK-NEXT:    [[ARRAYIDX12:%.*]] = getelementptr inbounds float, ptr [[OUTPUT]], i32 [[I_031]]
; CHECK-NEXT:    store float [[TMP11]], ptr [[ARRAYIDX12]], align 4
; CHECK-NEXT:    [[TMP12]] = load float, ptr [[W]], align 4
; CHECK-NEXT:    store float [[TMP12]], ptr [[ARRAYIDX4]], align 4
; CHECK-NEXT:    store float [[TMP6]], ptr [[W]], align 4
; CHECK-NEXT:    [[INC]] = add nuw nsw i32 [[I_031]], 1
; CHECK-NEXT:    [[EXITCOND_NOT:%.*]] = icmp eq i32 [[INC]], [[LEN]]
; CHECK-NEXT:    br i1 [[EXITCOND_NOT]], label [[FOR_COND_CLEANUP]], label [[FOR_BODY]]
;
entry:
  %cmp30 = icmp sgt i32 %len, 0
  br i1 %cmp30, label %for.body.lr.ph, label %for.cond.cleanup

for.body.lr.ph:                                   ; preds = %entry
  %arrayidx1 = getelementptr inbounds float, ptr %coef, i32 3
  %arrayidx3 = getelementptr inbounds float, ptr %coef, i32 4
  %arrayidx4 = getelementptr inbounds float, ptr %w, i32 1
  %arrayidx7 = getelementptr inbounds float, ptr %coef, i32 1
  %arrayidx10 = getelementptr inbounds float, ptr %coef, i32 2
  %.pre = load float, ptr %w, align 4
  %.pre32 = load float, ptr %arrayidx4, align 4
  br label %for.body

for.cond.cleanup:                                 ; preds = %for.body, %entry
  ret i32 0

for.body:                                         ; preds = %for.body, %for.body.lr.ph
  %0 = phi float [ %.pre32, %for.body.lr.ph ], [ %12, %for.body ]
  %1 = phi float [ %.pre, %for.body.lr.ph ], [ %6, %for.body ]
  %i.031 = phi i32 [ 0, %for.body.lr.ph ], [ %inc, %for.body ]
  %arrayidx = getelementptr inbounds float, ptr %input, i32 %i.031
  %2 = load float, ptr %arrayidx, align 4
  %3 = load float, ptr %arrayidx1, align 4
  %neg = fneg float %3
  %4 = tail call float @llvm.fmuladd.f32(float %neg, float %1, float %2)
  %5 = load float, ptr %arrayidx3, align 4
  %neg5 = fneg float %5
  %6 = tail call float @llvm.fmuladd.f32(float %neg5, float %0, float %4)
  %7 = load float, ptr %coef, align 4
  %8 = load float, ptr %arrayidx7, align 4
  %mul9 = fmul float %1, %8
  %9 = tail call float @llvm.fmuladd.f32(float %7, float %6, float %mul9)
  %10 = load float, ptr %arrayidx10, align 4
  %11 = tail call float @llvm.fmuladd.f32(float %10, float %0, float %9)
  %arrayidx12 = getelementptr inbounds float, ptr %output, i32 %i.031
  store float %11, ptr %arrayidx12, align 4
  %12 = load float, ptr %w, align 4
  store float %12, ptr %arrayidx4, align 4
  store float %6, ptr %w, align 4
  %inc = add nuw nsw i32 %i.031, 1
  %exitcond.not = icmp eq i32 %inc, %len
  br i1 %exitcond.not, label %for.cond.cleanup, label %for.body
}
